{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPYteKFdNqO0",
        "outputId": "e26db3e7-fff1-432e-ebf4-33d5fc7dc080"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting skorch\n",
            "  Downloading skorch-0.15.0-py3-none-any.whl (239 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/239.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/239.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.3/239.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from skorch) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from skorch) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from skorch) (1.11.4)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from skorch) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.10/dist-packages (from skorch) (4.66.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.0->skorch) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.0->skorch) (3.2.0)\n",
            "Installing collected packages: skorch\n",
            "Successfully installed skorch-0.15.0\n"
          ]
        }
      ],
      "source": [
        "!pip install skorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQZgn3JNuFXM",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import itertools\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import patsy\n",
        "import time\n",
        "\n",
        "import sklearn\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer, mean_squared_error\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch import optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from skorch import NeuralNet\n",
        "from skorch.helper import predefined_split, SliceDataset\n",
        "from skorch.callbacks import BatchScoring, Checkpoint, EarlyStopping, EpochScoring, LRScheduler, TensorBoard, ProgressBar\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYaQB02n1Md_",
        "outputId": "be363ad6-c321-4b4c-ddd4-7a268639e62b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "identifier = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device = torch.device(identifier)\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvYWqFf2uG9j",
        "outputId": "c2167e45-2be7-407e-90e0-ec2c02e9b01d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-01-11 02:00:56--  http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4924029 (4.7M) [application/zip]\n",
            "Saving to: ‘ml-100k.zip’\n",
            "\n",
            "ml-100k.zip         100%[===================>]   4.70M  9.92MB/s    in 0.5s    \n",
            "\n",
            "2024-01-11 02:00:57 (9.92 MB/s) - ‘ml-100k.zip’ saved [4924029/4924029]\n",
            "\n",
            "Archive:  ml-100k.zip\n",
            "   creating: ml-100k/\n",
            "  inflating: ml-100k/allbut.pl       \n",
            "  inflating: ml-100k/mku.sh          \n",
            "  inflating: ml-100k/README          \n",
            "  inflating: ml-100k/u.data          \n",
            "  inflating: ml-100k/u.genre         \n",
            "  inflating: ml-100k/u.info          \n",
            "  inflating: ml-100k/u.item          \n",
            "  inflating: ml-100k/u.occupation    \n",
            "  inflating: ml-100k/u.user          \n",
            "  inflating: ml-100k/u1.base         \n",
            "  inflating: ml-100k/u1.test         \n",
            "  inflating: ml-100k/u2.base         \n",
            "  inflating: ml-100k/u2.test         \n",
            "  inflating: ml-100k/u3.base         \n",
            "  inflating: ml-100k/u3.test         \n",
            "  inflating: ml-100k/u4.base         \n",
            "  inflating: ml-100k/u4.test         \n",
            "  inflating: ml-100k/u5.base         \n",
            "  inflating: ml-100k/u5.test         \n",
            "  inflating: ml-100k/ua.base         \n",
            "  inflating: ml-100k/ua.test         \n",
            "  inflating: ml-100k/ub.base         \n",
            "  inflating: ml-100k/ub.test         \n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists('ml-100k'):\n",
        "    !wget http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
        "    !unzip -o ml-100k.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j24pjXi6tMs6"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RrnACEq_bN3"
      },
      "outputs": [],
      "source": [
        "genre_cols = [\n",
        "    \"genre_unknown\", \"Action\", \"Adventure\", \"Animation\", \"Children\", \"Comedy\",\n",
        "    \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\", \"FilmNoir\", \"Horror\",\n",
        "    \"Musical\", \"Mystery\", \"Romance\", \"SciFi\", \"Thriller\", \"War\", \"Western\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIFR-8xl-kQ8"
      },
      "outputs": [],
      "source": [
        "class rsdataset(Dataset):\n",
        "    def __init__(self, usersfile, moviesfile, ratingsfile, nrows=None):\n",
        "\n",
        "        # Read files\n",
        "        self.movies = pd.read_csv(moviesfile, sep='|', names=['MovieID', 'Title', 'date', 'video_rl_date', 'link']+genre_cols, engine='python', encoding='latin-1')\n",
        "        self.users = pd.read_csv(usersfile, sep='|', names=['UserID', 'Age', 'Gender', 'Occupation', 'Zipcode'], engine='python', encoding='latin-1')\n",
        "        self.ratings = pd.read_csv(ratingsfile, sep='\\t', names=['UserID', 'MovieID', 'Rating', 'Timestamp'], engine='python', nrows=nrows, encoding='latin-1')\n",
        "\n",
        "        df2 = self.movies[genre_cols]\n",
        "        df2['Genre'] = df2.apply(lambda row: ', '.join(row.index[row == 1]), axis=1)\n",
        "        self.movies['Genre'] = df2['Genre']\n",
        "        self.movies = self.movies.drop(genre_cols, axis = 1)\n",
        "        # self.movies['Genre'] = self.movies['Genre'].map(genre_dict)\n",
        "        bins = [0, 18, 25, 35, 45, 50, 56, 100]\n",
        "        labels = [1, 18, 25, 35, 45, 50, 56]\n",
        "        self.users['Age'] = pd.cut(self.users['Age'], bins=bins, labels=labels, right=False)\n",
        "        assert self.users['UserID'].nunique() >= self.ratings['UserID'].nunique(), 'UserID with unknown information'\n",
        "        assert self.movies['MovieID'].nunique() >= self.ratings['MovieID'].nunique(), 'Movies with unknown information'\n",
        "\n",
        "        self.users_emb_columns = []\n",
        "        self.users_ohe_columns = []\n",
        "        self.movies_emb_columns = []\n",
        "        self.movies_ohe_columns = []\n",
        "        self.interact_columns = []\n",
        "\n",
        "        self.movies = self.movies.drop(['date', 'video_rl_date', 'link'], axis= 1)\n",
        "        self.nusers = self.ratings['UserID'].nunique()\n",
        "        self.nmovies = self.ratings['MovieID'].nunique()\n",
        "\n",
        "        self.y_range = (self.ratings['Rating'].min(), self.ratings['Rating'].max())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        return (((self.users_emb[idx])),\n",
        "                ((self.users_ohe[idx])),\n",
        "                ((self.movies_emb[idx])),\n",
        "                ((self.movies_ohe[idx])),\n",
        "                ((self.interact[idx]))), (self.y[idx])\n",
        "\n",
        "    def to_tensor(self):\n",
        "        self.users_emb = torch.from_numpy(self.ratings[self.users_emb_columns].values)\n",
        "        self.users_ohe = torch.tensor(self.ratings[self.users_ohe_columns].values, dtype=torch.float)\n",
        "        self.movies_emb = torch.from_numpy(self.ratings[self.movies_emb_columns].values)\n",
        "        self.movies_ohe = torch.tensor(self.ratings[self.movies_ohe_columns].values, dtype=torch.float)\n",
        "        self.interact = torch.from_numpy(self.ratings[self.interact_columns].values)\n",
        "        self.y = torch.tensor(self.y.values, dtype=torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uINDlkiMB_Fo",
        "outputId": "73028eb4-1c6b-4170-ac60-fd3ce37c2e9f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-6-f5a438cfccf0>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df2['Genre'] = df2.apply(lambda row: ', '.join(row.index[row == 1]), axis=1)\n"
          ]
        }
      ],
      "source": [
        "train = rsdataset('ml-100k/u.user', 'ml-100k/u.item', 'ml-100k/u.data', nrows=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "9oO_9n4sNhV5",
        "outputId": "e6211a35-26fc-4670-bf2e-32db62b574dc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-08f9f419-8f1b-4019-aa3e-5c701d118373\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserID</th>\n",
              "      <th>Age</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Occupation</th>\n",
              "      <th>Zipcode</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>M</td>\n",
              "      <td>technician</td>\n",
              "      <td>85711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>50</td>\n",
              "      <td>F</td>\n",
              "      <td>other</td>\n",
              "      <td>94043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>18</td>\n",
              "      <td>M</td>\n",
              "      <td>writer</td>\n",
              "      <td>32067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>18</td>\n",
              "      <td>M</td>\n",
              "      <td>technician</td>\n",
              "      <td>43537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>25</td>\n",
              "      <td>F</td>\n",
              "      <td>other</td>\n",
              "      <td>15213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>938</th>\n",
              "      <td>939</td>\n",
              "      <td>25</td>\n",
              "      <td>F</td>\n",
              "      <td>student</td>\n",
              "      <td>33319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>939</th>\n",
              "      <td>940</td>\n",
              "      <td>25</td>\n",
              "      <td>M</td>\n",
              "      <td>administrator</td>\n",
              "      <td>02215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>940</th>\n",
              "      <td>941</td>\n",
              "      <td>18</td>\n",
              "      <td>M</td>\n",
              "      <td>student</td>\n",
              "      <td>97229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>941</th>\n",
              "      <td>942</td>\n",
              "      <td>45</td>\n",
              "      <td>F</td>\n",
              "      <td>librarian</td>\n",
              "      <td>78209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>942</th>\n",
              "      <td>943</td>\n",
              "      <td>18</td>\n",
              "      <td>M</td>\n",
              "      <td>student</td>\n",
              "      <td>77841</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>943 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-08f9f419-8f1b-4019-aa3e-5c701d118373')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-08f9f419-8f1b-4019-aa3e-5c701d118373 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-08f9f419-8f1b-4019-aa3e-5c701d118373');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-62da4a36-e618-41e9-836b-51100bb15a10\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-62da4a36-e618-41e9-836b-51100bb15a10')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-62da4a36-e618-41e9-836b-51100bb15a10 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     UserID Age Gender     Occupation Zipcode\n",
              "0         1  18      M     technician   85711\n",
              "1         2  50      F          other   94043\n",
              "2         3  18      M         writer   32067\n",
              "3         4  18      M     technician   43537\n",
              "4         5  25      F          other   15213\n",
              "..      ...  ..    ...            ...     ...\n",
              "938     939  25      F        student   33319\n",
              "939     940  25      M  administrator   02215\n",
              "940     941  18      M        student   97229\n",
              "941     942  45      F      librarian   78209\n",
              "942     943  18      M        student   77841\n",
              "\n",
              "[943 rows x 5 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.users"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "v0XGWF6ENuFO",
        "outputId": "4a20168d-6c3b-4695-98d6-7b46c966040e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-61c386c3-2cc6-4ada-880b-60d7a5e9a0aa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MovieID</th>\n",
              "      <th>Title</th>\n",
              "      <th>Genre</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Animation, Children, Comedy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>GoldenEye (1995)</td>\n",
              "      <td>Action, Adventure, Thriller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Four Rooms (1995)</td>\n",
              "      <td>Thriller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Get Shorty (1995)</td>\n",
              "      <td>Action, Comedy, Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Copycat (1995)</td>\n",
              "      <td>Crime, Drama, Thriller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1677</th>\n",
              "      <td>1678</td>\n",
              "      <td>Mat' i syn (1997)</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1678</th>\n",
              "      <td>1679</td>\n",
              "      <td>B. Monkey (1998)</td>\n",
              "      <td>Romance, Thriller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1679</th>\n",
              "      <td>1680</td>\n",
              "      <td>Sliding Doors (1998)</td>\n",
              "      <td>Drama, Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1680</th>\n",
              "      <td>1681</td>\n",
              "      <td>You So Crazy (1994)</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1681</th>\n",
              "      <td>1682</td>\n",
              "      <td>Scream of Stone (Schrei aus Stein) (1991)</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1682 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-61c386c3-2cc6-4ada-880b-60d7a5e9a0aa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-61c386c3-2cc6-4ada-880b-60d7a5e9a0aa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-61c386c3-2cc6-4ada-880b-60d7a5e9a0aa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b013cc0b-1cfc-4ad9-84d4-1b4832539dff\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b013cc0b-1cfc-4ad9-84d4-1b4832539dff')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b013cc0b-1cfc-4ad9-84d4-1b4832539dff button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      MovieID                                      Title  \\\n",
              "0           1                           Toy Story (1995)   \n",
              "1           2                           GoldenEye (1995)   \n",
              "2           3                          Four Rooms (1995)   \n",
              "3           4                          Get Shorty (1995)   \n",
              "4           5                             Copycat (1995)   \n",
              "...       ...                                        ...   \n",
              "1677     1678                          Mat' i syn (1997)   \n",
              "1678     1679                           B. Monkey (1998)   \n",
              "1679     1680                       Sliding Doors (1998)   \n",
              "1680     1681                        You So Crazy (1994)   \n",
              "1681     1682  Scream of Stone (Schrei aus Stein) (1991)   \n",
              "\n",
              "                            Genre  \n",
              "0     Animation, Children, Comedy  \n",
              "1     Action, Adventure, Thriller  \n",
              "2                        Thriller  \n",
              "3           Action, Comedy, Drama  \n",
              "4          Crime, Drama, Thriller  \n",
              "...                           ...  \n",
              "1677                        Drama  \n",
              "1678            Romance, Thriller  \n",
              "1679               Drama, Romance  \n",
              "1680                       Comedy  \n",
              "1681                        Drama  \n",
              "\n",
              "[1682 rows x 3 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.movies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "NioNQMJCN5HB",
        "outputId": "afd5d4e8-a7cd-459e-9dfd-28127baa5b08"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-09cf95be-f121-4cfd-8697-e218c6544ff1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserID</th>\n",
              "      <th>MovieID</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>196</td>\n",
              "      <td>242</td>\n",
              "      <td>3</td>\n",
              "      <td>881250949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>186</td>\n",
              "      <td>302</td>\n",
              "      <td>3</td>\n",
              "      <td>891717742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>377</td>\n",
              "      <td>1</td>\n",
              "      <td>878887116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>244</td>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>880606923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>166</td>\n",
              "      <td>346</td>\n",
              "      <td>1</td>\n",
              "      <td>886397596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99995</th>\n",
              "      <td>880</td>\n",
              "      <td>476</td>\n",
              "      <td>3</td>\n",
              "      <td>880175444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99996</th>\n",
              "      <td>716</td>\n",
              "      <td>204</td>\n",
              "      <td>5</td>\n",
              "      <td>879795543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99997</th>\n",
              "      <td>276</td>\n",
              "      <td>1090</td>\n",
              "      <td>1</td>\n",
              "      <td>874795795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99998</th>\n",
              "      <td>13</td>\n",
              "      <td>225</td>\n",
              "      <td>2</td>\n",
              "      <td>882399156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99999</th>\n",
              "      <td>12</td>\n",
              "      <td>203</td>\n",
              "      <td>3</td>\n",
              "      <td>879959583</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100000 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-09cf95be-f121-4cfd-8697-e218c6544ff1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-09cf95be-f121-4cfd-8697-e218c6544ff1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-09cf95be-f121-4cfd-8697-e218c6544ff1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-85307f79-5ddd-446c-8e5c-a789537cdfc4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-85307f79-5ddd-446c-8e5c-a789537cdfc4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-85307f79-5ddd-446c-8e5c-a789537cdfc4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "       UserID  MovieID  Rating  Timestamp\n",
              "0         196      242       3  881250949\n",
              "1         186      302       3  891717742\n",
              "2          22      377       1  878887116\n",
              "3         244       51       2  880606923\n",
              "4         166      346       1  886397596\n",
              "...       ...      ...     ...        ...\n",
              "99995     880      476       3  880175444\n",
              "99996     716      204       5  879795543\n",
              "99997     276     1090       1  874795795\n",
              "99998      13      225       2  882399156\n",
              "99999      12      203       3  879959583\n",
              "\n",
              "[100000 rows x 4 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.ratings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZGZ8XnyNuOZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8ivFYVSM3nr"
      },
      "source": [
        "### Preprocessing of dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_w1QQER37El"
      },
      "outputs": [],
      "source": [
        "train.ratings = train.ratings.merge(train.movies, left_on='MovieID', right_on='MovieID')\n",
        "train.movies = train.ratings[train.movies.columns]\n",
        "\n",
        "train.ratings = train.ratings.merge(train.users, left_on='UserID', right_on='UserID')\n",
        "train.users = train.ratings[train.users.columns]\n",
        "\n",
        "train.y = train.ratings['Rating']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlQhqnXOYcmp"
      },
      "outputs": [],
      "source": [
        "# Label Encode users\n",
        "columns = ['UserID', 'Gender', 'Age', 'Occupation']\n",
        "train.ratings[columns] = train.ratings[columns].apply(preprocessing.LabelEncoder().fit_transform)\n",
        "train.users_emb_columns = train.users_emb_columns + columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZ3jSa_dRMLA"
      },
      "outputs": [],
      "source": [
        "# Label Encode movies\n",
        "columns = ['MovieID']\n",
        "train.ratings[columns] = train.ratings[columns].apply(preprocessing.LabelEncoder().fit_transform)\n",
        "train.movies_emb_columns = train.movies_emb_columns + columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2XcLbiz9lql",
        "outputId": "3d0cb382-5251-4f68-d828-dc486a6d398b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# One Hot Encode users\n",
        "columns = ['Gender', 'Age', 'Occupation']\n",
        "ohe = preprocessing.OneHotEncoder(categories='auto', sparse=False, dtype='uint8')\n",
        "ohe.fit(train.ratings[columns])\n",
        "train.ratings = pd.concat([train.ratings, pd.DataFrame(data=ohe.transform(train.ratings[columns]), columns=ohe.get_feature_names_out(columns))], axis=1)\n",
        "train.users_ohe_columns = ohe.get_feature_names_out(columns)\n",
        "\n",
        "assert train.ratings[train.users_ohe_columns].max().max()<=1, 'Error with ohe columns'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfVq6sd5NqiO"
      },
      "outputs": [],
      "source": [
        "# One Hot Encode movies\n",
        "genres = [\"genre_unknown\", \"Action\", \"Adventure\", \"Animation\", \"Children\", \"Comedy\",\n",
        "    \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\", \"FilmNoir\", \"Horror\",\n",
        "    \"Musical\", \"Mystery\", \"Romance\", \"SciFi\", \"Thriller\", \"War\", \"Western\"]\n",
        "\n",
        "for genre in genres:\n",
        "    genre = genre.replace('-', '')\n",
        "    column = str(genre)\n",
        "    train.ratings[column] = train.ratings['Genre'].apply(lambda x: 1 if genre in x else 0)\n",
        "    train.movies_ohe_columns.append(column)\n",
        "\n",
        "assert train.ratings[train.movies_ohe_columns].max().max()<=1, 'Error with ohe columns'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTH7wNbZp_jA"
      },
      "outputs": [],
      "source": [
        "int_genres_gender = \"\"\n",
        "for genre in train.movies_ohe_columns:\n",
        "    int_genres_gender = int_genres_gender + '+' +genre + ':Gender'\n",
        "\n",
        "int_genres_age = \"\"\n",
        "for genre in train.movies_ohe_columns:\n",
        "    int_genres_age = int_genres_age + '+' + genre + ':Age'\n",
        "\n",
        "interact = patsy.dmatrix(\"0 + Gender:Age + Gender:Occupation + Age:Occupation\"+int_genres_gender+int_genres_age, data=train.ratings.astype('object'), return_type='dataframe').astype('int8')\n",
        "interact = interact.astype('uint8')\n",
        "train.ratings = pd.concat([train.ratings, interact], axis=1)\n",
        "train.interact_columns = interact.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyWjbXGigA6u",
        "outputId": "a00554ea-c41f-40be-e69b-c8e90108b886"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Gender[1]:Age[4]', 'Gender[1]:Occupation[T.20]',\n",
              "       'Age[T.4]:Occupation[T.20]', 'Comedy[T.1]:Gender[1]',\n",
              "       'Comedy[T.1]:Age[T.4]'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "interact.columns[interact.iloc[0] == 1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRSGsdEmMlPE"
      },
      "outputs": [],
      "source": [
        "# Drop unused columns\n",
        "train.movies.drop(['Title', 'Genre'], inplace=True, axis=1)\n",
        "train.ratings.drop(['Title', 'Genre', 'Zipcode'], inplace=True, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPTkxLKQMWhI"
      },
      "outputs": [],
      "source": [
        "train.to_tensor()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hm1qo9It3zsb"
      },
      "source": [
        "### DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNXPv9DAmHBB"
      },
      "outputs": [],
      "source": [
        "# Split\n",
        "train_size = int(0.8 * len(train))\n",
        "test_size = len(train) - train_size\n",
        "train_dataset, valid_dataset = torch.utils.data.random_split(train, [train_size, test_size])\n",
        "\n",
        "# Create dataloaders\n",
        "dataloaders = {}\n",
        "dataloaders['train'] = torch.utils.data.DataLoader(train_dataset, batch_size=4096, shuffle=True)\n",
        "dataloaders['valid'] = torch.utils.data.DataLoader(valid_dataset, batch_size=4096, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oa-KNh5qkUh8"
      },
      "source": [
        "### Define Pytorch models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daekeS2zju4B",
        "outputId": "59a40833-62b8-438c-cea9-e8a745a6ec24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "deepnwide(\n",
            "  (emb_UserID): Embedding(943, 60)\n",
            "  (emb_Gender): Embedding(2, 60)\n",
            "  (emb_Age): Embedding(7, 60)\n",
            "  (emb_Occupation): Embedding(21, 60)\n",
            "  (emb_MovieID): Embedding(1682, 60)\n",
            "  (h1): Linear(in_features=300, out_features=100, bias=True)\n",
            "  (h2): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (h3): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (dropout1): Dropout(p=0.5, inplace=False)\n",
            "  (dropout2): Dropout(p=0.5, inplace=False)\n",
            "  (dropout3): Dropout(p=0.5, inplace=False)\n",
            "  (last_layer): Linear(in_features=445, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class deepnwide(nn.Module):\n",
        "\n",
        "    def __init__(self, users_emb, movies_emb, users_ohe, movies_ohe, interact, size_emb, y_range, dropout, linear_size= 500):\n",
        "        super().__init__()\n",
        "\n",
        "        self.name = 'deepnwide'\n",
        "        self.y_range = y_range\n",
        "\n",
        "        # wide part\n",
        "\n",
        "        # deep\n",
        "        self.emb_UserID = nn.Embedding(len(torch.unique(users_emb[:, 0])), size_emb)\n",
        "        self.emb_UserID.weight.data.uniform_(-.01, .01)\n",
        "        self.emb_Gender = nn.Embedding(len(torch.unique(users_emb[:, 1])), size_emb)\n",
        "        self.emb_Gender.weight.data.uniform_(-.01, .01)\n",
        "        self.emb_Age = nn.Embedding(len(torch.unique(users_emb[:, 2])), size_emb)\n",
        "        self.emb_Age.weight.data.uniform_(-.01, .01)\n",
        "        self.emb_Occupation = nn.Embedding(len(torch.unique(users_emb[:, 3])), size_emb)\n",
        "        self.emb_Occupation.weight.data.uniform_(-.01, .01)\n",
        "        self.emb_MovieID = nn.Embedding(len(torch.unique(movies_emb[:, 0])), size_emb)\n",
        "        self.emb_MovieID.weight.data.uniform_(-.01, .01)\n",
        "\n",
        "        # hidden layers\n",
        "        self.h1 = nn.Linear(5 * size_emb, linear_size)\n",
        "        self.h2 = nn.Linear(linear_size, linear_size)\n",
        "        self.h3 = nn.Linear(linear_size, linear_size)\n",
        "\n",
        "        # Dropout layers\n",
        "        self.dropout1 = nn.Dropout(p=dropout)\n",
        "        self.dropout2 = nn.Dropout(p=dropout)\n",
        "        self.dropout3 = nn.Dropout(p=dropout)\n",
        "\n",
        "        # final dense layer\n",
        "        self.last_layer = nn.Linear((interact.shape[1]) + (movies_ohe.shape[1]) + (linear_size), 1)\n",
        "\n",
        "\n",
        "    def forward(self, X):\n",
        "        # Assign data\n",
        "        user_emb = X[0]\n",
        "        user_ohe = X[1]\n",
        "        movie_emb = X[2]\n",
        "        movie_ohe = X[3]\n",
        "        interact = X[4]\n",
        "\n",
        "        UserID = user_emb[:, 0]\n",
        "        Gender = user_emb[:, 1]\n",
        "        Age = user_emb[:, 2]\n",
        "        Occupation = user_emb[:, 3]\n",
        "        MovieID = movie_emb[:, 0]\n",
        "\n",
        "        UserID = self.emb_UserID(UserID)\n",
        "        Gender = self.emb_Gender(Gender)\n",
        "        Age = self.emb_Age(Age)\n",
        "        Occupation = self.emb_Occupation(Occupation)\n",
        "        MovieID = self.emb_MovieID(MovieID)\n",
        "\n",
        "        emb = torch.cat([UserID,\n",
        "                         Age,\n",
        "                         Gender,\n",
        "                         Occupation,\n",
        "                         MovieID],\n",
        "                         dim=1)\n",
        "\n",
        "        emb = F.relu(self.dropout1(self.h1(emb)))\n",
        "        emb = F.relu(self.dropout2(self.h2(emb)))\n",
        "        emb = F.relu(self.dropout3(self.h3(emb)))\n",
        "\n",
        "        result = self.last_layer(torch.cat([interact.float(), movie_ohe.float(), emb.float()], dim=1))\n",
        "\n",
        "        return (torch.sigmoid(result) * (self.y_range[1]-self.y_range[0]) + self.y_range[0]).squeeze()\n",
        "\n",
        "\n",
        "model = deepnwide(train.users_emb, train.movies_emb, train.users_ohe, train.movies_ohe, train.interact, 60, train.y_range, 0.5, 100)\n",
        "model.to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MftgRHZB3rFd",
        "outputId": "9088890a-9132-450a-ae8d-f2c79d4d707f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "twoembeds(\n",
            "  (emb_UserID): Embedding(943, 15)\n",
            "  (emb_MovieID): Embedding(1682, 15)\n",
            "  (emb_UserID_b): Embedding(943, 1)\n",
            "  (emb_MovieID_b): Embedding(1682, 1)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class twoembeds(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, size_emb, y_range):\n",
        "        super().__init__()\n",
        "\n",
        "        # set name of model\n",
        "        self.name = 'twoembeds'\n",
        "        self.y_range = y_range\n",
        "\n",
        "        # User and movie embeddings\n",
        "        self.emb_UserID = nn.Embedding(train.nusers, size_emb)\n",
        "        self.emb_MovieID = nn.Embedding(train.nmovies, size_emb)\n",
        "        self.emb_UserID.weight.data.uniform_(-.01, .01)\n",
        "        self.emb_MovieID.weight.data.uniform_(-.01, .01)\n",
        "\n",
        "        # User and movie embeddings bía\n",
        "        self.emb_UserID_b = nn.Embedding(train.nusers, 1)\n",
        "        self.emb_MovieID_b = nn.Embedding(train.nmovies, 1)\n",
        "        self.emb_UserID_b.weight.data.uniform_(-.01, .01)\n",
        "        self.emb_MovieID_b.weight.data.uniform_(-.01, .01)\n",
        "\n",
        "\n",
        "    def forward(self, X):\n",
        "        user_emb = X[0]\n",
        "        user_ohe = X[1]\n",
        "        movie_emb = X[2]\n",
        "        movie_ohe = X[3]\n",
        "\n",
        "        UserID = user_emb[:, 0]\n",
        "        MovieID = movie_emb[:, 0]\n",
        "\n",
        "        user_emb = self.emb_UserID(UserID)\n",
        "        movie_emb = self.emb_MovieID(MovieID)\n",
        "\n",
        "        mult = (user_emb * movie_emb).sum(1)\n",
        "\n",
        "        # add bias\n",
        "        multb = mult + self.emb_UserID_b(UserID).squeeze() + self.emb_MovieID_b(MovieID).squeeze()\n",
        "\n",
        "        multb = multb.float()\n",
        "\n",
        "        return (torch.sigmoid(multb) * (self.y_range[1]-self.y_range[0]) + self.y_range[0]).squeeze()\n",
        "\n",
        "        return multb\n",
        "\n",
        "\n",
        "model = twoembeds(15, train.y_range)\n",
        "model.to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lzfGXgaNgJE",
        "outputId": "2129f051-809c-41f4-ebf8-4eb8915c2b8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ncf(\n",
            "  (gmf_embuserid): Embedding(943, 60)\n",
            "  (gmf_embgender): Embedding(2, 60)\n",
            "  (gmf_embage): Embedding(7, 60)\n",
            "  (gmf_embocc): Embedding(21, 60)\n",
            "  (gmf_embmovieid): Embedding(1682, 221)\n",
            "  (mlp_embuserid): Embedding(943, 60)\n",
            "  (mlp_embgender): Embedding(2, 60)\n",
            "  (mlp_embage): Embedding(7, 60)\n",
            "  (mlp_embocc): Embedding(21, 60)\n",
            "  (mlp_embmovieid): Embedding(1682, 60)\n",
            "  (h1): Linear(in_features=319, out_features=200, bias=True)\n",
            "  (h2): Linear(in_features=200, out_features=100, bias=True)\n",
            "  (dropout1): Dropout(p=0.5, inplace=False)\n",
            "  (dropout2): Dropout(p=0.5, inplace=False)\n",
            "  (last_layer): Linear(in_features=340, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class ncf(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, users_emb, movies_emb, users_ohe, movies_ohe, interact, size_emb, dropout, linear_size, y_range):\n",
        "        super().__init__()\n",
        "\n",
        "        # set name of model\n",
        "        self.name = 'ncf'\n",
        "        self.y_range = y_range\n",
        "\n",
        "        ### GMF part\n",
        "        # user embeddings\n",
        "        self.gmf_embuserid = nn.Embedding(len(torch.unique(users_emb[:, 0])), size_emb)\n",
        "        self.gmf_embuserid.weight.data.uniform_(-.01, .01)\n",
        "        self.gmf_embgender = nn.Embedding(len(torch.unique(users_emb[:, 1])), size_emb)\n",
        "        self.gmf_embgender.weight.data.uniform_(-.01, .01)\n",
        "        self.gmf_embage = nn.Embedding(len(torch.unique(users_emb[:, 2])), size_emb)\n",
        "        self.gmf_embage.weight.data.uniform_(-.01, .01)\n",
        "        self.gmf_embocc = nn.Embedding(len(torch.unique(users_emb[:, 3])), size_emb)\n",
        "        self.gmf_embocc.weight.data.uniform_(-.01, .01)\n",
        "        # movie embeddings\n",
        "        self.gmf_embmovieid = nn.Embedding(len(torch.unique(movies_emb[:, 0])), size_emb*4-len(train.movies_ohe_columns))\n",
        "        self.gmf_embmovieid.weight.data.uniform_(-.01, .01)\n",
        "\n",
        "\n",
        "        ### MLP part\n",
        "        # user embeddings\n",
        "        self.mlp_embuserid = nn.Embedding(len(torch.unique(users_emb[:, 0])), size_emb)\n",
        "        self.mlp_embuserid.weight.data.uniform_(-.01, .01)\n",
        "        self.mlp_embgender = nn.Embedding(len(torch.unique(users_emb[:, 1])), size_emb)\n",
        "        self.mlp_embgender.weight.data.uniform_(-.01, .01)\n",
        "        self.mlp_embage = nn.Embedding(len(torch.unique(users_emb[:, 2])), size_emb)\n",
        "        self.mlp_embage.weight.data.uniform_(-.01, .01)\n",
        "        self.mlp_embocc = nn.Embedding(len(torch.unique(users_emb[:, 3])), size_emb)\n",
        "        self.mlp_embocc.weight.data.uniform_(-.01, .01)\n",
        "        # movie embeddings\n",
        "        self.mlp_embmovieid = nn.Embedding(len(torch.unique(movies_emb[:, 0])), size_emb)\n",
        "        self.mlp_embmovieid.weight.data.uniform_(-.01, .01)\n",
        "        # hidden layers\n",
        "        self.h1 = nn.Linear(5*size_emb+len(train.movies_ohe_columns), linear_size)\n",
        "        self.h2 = nn.Linear(linear_size, int(linear_size/2))\n",
        "        #self.h3 = nn.Linear(linear_size, linear_size)\n",
        "        # Dropout layers\n",
        "        self.dropout1 = nn.Dropout(p=dropout)\n",
        "        self.dropout2 = nn.Dropout(p=dropout)\n",
        "        #self.dropout3 = nn.Dropout(p=dropout)\n",
        "\n",
        "        # final dense layer\n",
        "        self.last_layer = nn.Linear(size_emb*4+int(linear_size/2), 1)\n",
        "\n",
        "    def forward(self, X):\n",
        "        user_emb = X[0]\n",
        "        user_ohe = X[1]\n",
        "        movie_emb = X[2]\n",
        "        movie_ohe = X[3]\n",
        "\n",
        "        UserID = user_emb[:, 0]\n",
        "        Gender = user_emb[:, 1]\n",
        "        Age = user_emb[:, 2]\n",
        "        Occupation = user_emb[:, 3]\n",
        "        MovieID = movie_emb[:, 0]\n",
        "\n",
        "        # GMF part\n",
        "        gmf_embuserid = self.gmf_embuserid(UserID)\n",
        "        gmf_embgender = self.gmf_embgender(Gender)\n",
        "        gmf_embage = self.gmf_embage(Age)\n",
        "        gmf_embocc = self.gmf_embocc(Occupation)\n",
        "        gmf_embmovieid = self.gmf_embmovieid(MovieID)\n",
        "\n",
        "        gmf_user_vector = torch.cat([gmf_embuserid,\n",
        "                                    gmf_embgender,\n",
        "                                    gmf_embage,\n",
        "                                    gmf_embocc],\n",
        "                                    dim=1)\n",
        "\n",
        "        gmf_movie_vector = torch.cat([gmf_embmovieid, movie_ohe], 1)\n",
        "\n",
        "        gmf_vector = (gmf_user_vector * gmf_movie_vector)\n",
        "\n",
        "\n",
        "        # MLP part\n",
        "        mlp_embuserid = self.mlp_embuserid(UserID)\n",
        "        mlp_embgender = self.mlp_embgender(Gender)\n",
        "        mlp_embage = self.mlp_embage(Age)\n",
        "        mlp_embocc = self.mlp_embocc(Occupation)\n",
        "        mlp_movieid = self.mlp_embmovieid(MovieID)\n",
        "\n",
        "        mlp_vector = torch.cat([mlp_embuserid,\n",
        "                                mlp_embgender,\n",
        "                                mlp_embage,\n",
        "                                mlp_embocc,\n",
        "                                mlp_movieid,\n",
        "                                movie_ohe],\n",
        "                                dim=1)\n",
        "        mlp_vector = F.relu(self.dropout1(self.h1(mlp_vector)))\n",
        "        mlp_vector = F.relu(self.dropout2(self.h2(mlp_vector)))\n",
        "        #mlp_vector = F.relu(self.dropout3(self.h3(mlp_vector)))\n",
        "\n",
        "        # Fusion\n",
        "        result = torch.cat([gmf_vector, mlp_vector], dim=1)\n",
        "        result = self.last_layer(result)\n",
        "\n",
        "        #return (torch.sigmoid(result) * (5-1) + 1).squeeze\n",
        "        return (torch.sigmoid(result) * (self.y_range[1]-self.y_range[0]) + self.y_range[0]).squeeze()\n",
        "\n",
        "\n",
        "model = ncf(train.users_emb, train.movies_emb, train.users_ohe, train.movies_ohe, train.interact, 60, 0.5, 200, train.y_range)\n",
        "model.to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rBEpoBPd4w5"
      },
      "source": [
        "### Skorch callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9XsVtTYOqGq"
      },
      "outputs": [],
      "source": [
        "# Earlystopping callback\n",
        "earlystopping = EarlyStopping(monitor='valid_loss', patience=10, threshold=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ockpmqrz9KYv"
      },
      "outputs": [],
      "source": [
        "# RMSE callback\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "\n",
        "def rmseloss(y_true, y_pred):\n",
        "    #return f1_score(y_true, y_pred)\n",
        "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "def precision(y_true, y_pred):\n",
        "    y_true_binary = (y_true >= 4).astype(int)\n",
        "    y_pred_binary = (y_pred >= 4).astype(int)\n",
        "\n",
        "    # Calculate Precision and Recall\n",
        "    precision_scoree = precision_score(y_true_binary, y_pred_binary)\n",
        "    return precision_scoree\n",
        "\n",
        "def recall(y_true, y_pred):\n",
        "    y_true_binary = (y_true >= 4).astype(int)\n",
        "    y_pred_binary = (y_pred >= 4).astype(int)\n",
        "\n",
        "    # Calculate Precision and Recall\n",
        "    recall_scoree = recall_score(y_true_binary, y_pred_binary)\n",
        "    return recall_scoree\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    y_true_binary = (y_true >= 4).astype(int)\n",
        "    y_pred_binary = (y_pred >= 4).astype(int)\n",
        "\n",
        "    # Calculate F1 score\n",
        "    f1_scoree = f1_score(y_true_binary, y_pred_binary)\n",
        "    return f1_scoree\n",
        "\n",
        "rmse_scorer = make_scorer(rmseloss)\n",
        "precision_scorer = make_scorer(precision)\n",
        "recall_scorer = make_scorer(recall)\n",
        "f1_scorer = make_scorer(f1)\n",
        "\n",
        "epoch_rmse = EpochScoring(rmse_scorer, name='rmse_score', lower_is_better=True)\n",
        "epoch_precision = EpochScoring(precision_scorer, name='precision', lower_is_better= False)\n",
        "epoch_recall = EpochScoring(recall_scorer, name='recall', lower_is_better= False)\n",
        "epoch_f1 = EpochScoring(f1_scorer, name='f1', lower_is_better= False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p62gAk8FgaZS"
      },
      "outputs": [],
      "source": [
        "# Checkpoint callback\n",
        "checkpoint = Checkpoint(monitor='rmse_score_best', f_params='params.pt', f_optimizer='optimizer.pt', f_history='history.json', f_pickle='model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knAy1XQYjgze"
      },
      "outputs": [],
      "source": [
        "# Learning rate scheduler callback\n",
        "lr_scheduler = LRScheduler(policy=\"StepLR\", step_size=7, gamma=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeHN1BMLNgJF"
      },
      "source": [
        "### Neural Collaborative Filtering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WXJpYU6NgJF"
      },
      "source": [
        "#### Manually specify hyperparamers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7Lz3NnTNgJF"
      },
      "outputs": [],
      "source": [
        "#86.57\n",
        "ncfnet = NeuralNet(\n",
        "    ncf,\n",
        "    module__users_emb=train.users_emb,\n",
        "    module__movies_emb=train.movies_emb,\n",
        "    module__users_ohe=train.users_ohe,\n",
        "    module__movies_ohe=train.movies_ohe,\n",
        "    module__interact=train.interact,\n",
        "    module__size_emb=120,\n",
        "    module__dropout=0.3,\n",
        "    module__linear_size=400,\n",
        "    module__y_range=train.y_range,#### Manually specify hyperparamers\n",
        "    max_epochs=50,\n",
        "    lr=0.01,\n",
        "    optimizer=torch.optim.Adam,\n",
        "    criterion=torch.nn.MSELoss,\n",
        "    device=device,\n",
        "    iterator_train__batch_size=1024,\n",
        "    iterator_train__num_workers=0,\n",
        "    iterator_train__shuffle=True,\n",
        "    iterator_valid__batch_size=4096,\n",
        "    train_split=predefined_split(valid_dataset),\n",
        "    callbacks=[\n",
        "               earlystopping,\n",
        "               epoch_rmse,\n",
        "               epoch_precision,\n",
        "               epoch_recall,\n",
        "               epoch_f1,\n",
        "               checkpoint,\n",
        "               lr_scheduler,\n",
        "\n",
        "               ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHSbndsbNgJG",
        "outputId": "ca5198c9-2259-4fac-a76e-77bbeb108d09",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch      f1    precision    recall    rmse_score    train_loss    valid_loss    cp      lr     dur\n",
            "-------  ------  -----------  --------  ------------  ------------  ------------  ----  ------  ------\n",
            "      1  \u001b[36m0.4456\u001b[0m       \u001b[32m0.8579\u001b[0m    \u001b[35m0.3010\u001b[0m        \u001b[31m0.9324\u001b[0m        \u001b[94m1.0012\u001b[0m        \u001b[36m0.8695\u001b[0m     +  0.0100  3.6711\n",
            "      2  \u001b[36m0.5758\u001b[0m       0.7997    \u001b[35m0.4498\u001b[0m        0.9671        \u001b[94m0.6406\u001b[0m        0.9354        0.0100  2.9789\n",
            "      3  0.5740       0.7998    0.4477        0.9821        \u001b[94m0.2568\u001b[0m        0.9646        0.0100  2.7147\n",
            "      4  \u001b[36m0.6083\u001b[0m       0.7849    \u001b[35m0.4966\u001b[0m        0.9922        \u001b[94m0.1416\u001b[0m        0.9846        0.0100  2.7281\n",
            "      5  0.5872       0.7791    0.4711        1.0081        \u001b[94m0.1021\u001b[0m        1.0162        0.0100  3.7918\n",
            "      6  \u001b[36m0.6089\u001b[0m       0.7735    \u001b[35m0.5021\u001b[0m        1.0133        \u001b[94m0.0865\u001b[0m        1.0268        0.0100  2.7138\n",
            "      7  0.6048       0.7771    0.4951        1.0129        \u001b[94m0.0793\u001b[0m        1.0261        0.0100  2.7232\n",
            "      8  0.5978       0.7771    0.4858        1.0117        \u001b[94m0.0670\u001b[0m        1.0235        0.0010  2.9699\n",
            "      9  0.6029       0.7762    0.4928        1.0119        \u001b[94m0.0495\u001b[0m        1.0238        0.0010  3.5595\n",
            "     10  0.6011       0.7754    0.4908        1.0164        \u001b[94m0.0393\u001b[0m        1.0331        0.0010  2.7782\n",
            "Stopping since valid_loss has not improved in the last 10 epochs.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<class 'skorch.net.NeuralNet'>[initialized](\n",
              "  module_=ncf(\n",
              "    (gmf_embuserid): Embedding(943, 120)\n",
              "    (gmf_embgender): Embedding(2, 120)\n",
              "    (gmf_embage): Embedding(7, 120)\n",
              "    (gmf_embocc): Embedding(21, 120)\n",
              "    (gmf_embmovieid): Embedding(1682, 461)\n",
              "    (mlp_embuserid): Embedding(943, 120)\n",
              "    (mlp_embgender): Embedding(2, 120)\n",
              "    (mlp_embage): Embedding(7, 120)\n",
              "    (mlp_embocc): Embedding(21, 120)\n",
              "    (mlp_embmovieid): Embedding(1682, 120)\n",
              "    (h1): Linear(in_features=619, out_features=400, bias=True)\n",
              "    (h2): Linear(in_features=400, out_features=200, bias=True)\n",
              "    (dropout1): Dropout(p=0.3, inplace=False)\n",
              "    (dropout2): Dropout(p=0.3, inplace=False)\n",
              "    (last_layer): Linear(in_features=680, out_features=1, bias=True)\n",
              "  ),\n",
              ")"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ncfnet.fit(train_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFA1Uuo5NgJG"
      },
      "source": [
        "#### GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhK3602PNgJG",
        "outputId": "2ab94cb1-242f-40dc-e500-af8c6b7f1b50",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5; 1/1] START lr=0.01, module__dropout=0.3, module__linear_size=400, module__size_emb=120\n",
            "  epoch      f1    precision    recall    rmse_score    train_loss    valid_loss    cp      lr     dur\n",
            "-------  ------  -----------  --------  ------------  ------------  ------------  ----  ------  ------\n",
            "      1  \u001b[36m0.5496\u001b[0m       \u001b[32m0.8684\u001b[0m    \u001b[35m0.4020\u001b[0m        \u001b[31m0.8891\u001b[0m        \u001b[94m0.9943\u001b[0m        \u001b[36m0.7905\u001b[0m     +  0.0100  5.8627\n",
            "      2  \u001b[36m0.7129\u001b[0m       \u001b[32m0.9620\u001b[0m    \u001b[35m0.5662\u001b[0m        \u001b[31m0.6510\u001b[0m        \u001b[94m0.6327\u001b[0m        \u001b[36m0.4238\u001b[0m     +  0.0100  4.8760\n",
            "      3  \u001b[36m0.7997\u001b[0m       \u001b[32m0.9718\u001b[0m    \u001b[35m0.6794\u001b[0m        \u001b[31m0.5762\u001b[0m        \u001b[94m0.2678\u001b[0m        \u001b[36m0.3320\u001b[0m     +  0.0100  5.4818\n",
            "      4  \u001b[36m0.8044\u001b[0m       \u001b[32m0.9770\u001b[0m    \u001b[35m0.6837\u001b[0m        \u001b[31m0.5479\u001b[0m        \u001b[94m0.1509\u001b[0m        \u001b[36m0.3002\u001b[0m     +  0.0100  6.7898\n",
            "      5  0.7913       \u001b[32m0.9772\u001b[0m    0.6649        \u001b[31m0.5381\u001b[0m        \u001b[94m0.1090\u001b[0m        \u001b[36m0.2896\u001b[0m     +  0.0100  6.4976\n",
            "      6  0.7753       \u001b[32m0.9791\u001b[0m    0.6418        \u001b[31m0.5338\u001b[0m        \u001b[94m0.0911\u001b[0m        \u001b[36m0.2849\u001b[0m     +  0.0100  4.2912\n",
            "      7  \u001b[36m0.8243\u001b[0m       0.9751    \u001b[35m0.7140\u001b[0m        0.5341        \u001b[94m0.0832\u001b[0m        0.2852        0.0100  5.2302\n",
            "      8  0.7882       \u001b[32m0.9808\u001b[0m    0.6589        \u001b[31m0.5177\u001b[0m        \u001b[94m0.0697\u001b[0m        \u001b[36m0.2680\u001b[0m     +  0.0010  4.2936\n",
            "      9  0.7984       \u001b[32m0.9817\u001b[0m    0.6728        \u001b[31m0.5091\u001b[0m        \u001b[94m0.0523\u001b[0m        \u001b[36m0.2592\u001b[0m     +  0.0010  4.3249\n",
            "     10  0.8005       \u001b[32m0.9819\u001b[0m    0.6757        \u001b[31m0.5040\u001b[0m        \u001b[94m0.0419\u001b[0m        \u001b[36m0.2540\u001b[0m     +  0.0010  9.9491\n",
            "     11  0.8133       \u001b[32m0.9823\u001b[0m    0.6940        \u001b[31m0.5004\u001b[0m        \u001b[94m0.0354\u001b[0m        \u001b[36m0.2504\u001b[0m     +  0.0010  6.3149\n",
            "     12  0.8218       0.9821    0.7064        \u001b[31m0.4982\u001b[0m        \u001b[94m0.0310\u001b[0m        \u001b[36m0.2482\u001b[0m     +  0.0010  4.4732\n",
            "     13  \u001b[36m0.8375\u001b[0m       0.9816    \u001b[35m0.7303\u001b[0m        \u001b[31m0.4966\u001b[0m        \u001b[94m0.0277\u001b[0m        \u001b[36m0.2466\u001b[0m     +  0.0010  10.7582\n",
            "     14  0.8300       0.9815    0.7191        \u001b[31m0.4951\u001b[0m        \u001b[94m0.0254\u001b[0m        \u001b[36m0.2452\u001b[0m     +  0.0010  5.5748\n",
            "     15  0.8334       0.9811    0.7244        \u001b[31m0.4951\u001b[0m        \u001b[94m0.0234\u001b[0m        \u001b[36m0.2451\u001b[0m     +  0.0001  4.3396\n",
            "     16  \u001b[36m0.8378\u001b[0m       0.9812    \u001b[35m0.7310\u001b[0m        \u001b[31m0.4949\u001b[0m        \u001b[94m0.0232\u001b[0m        \u001b[36m0.2450\u001b[0m     +  0.0001  4.9390\n",
            "     17  \u001b[36m0.8382\u001b[0m       0.9812    \u001b[35m0.7316\u001b[0m        \u001b[31m0.4948\u001b[0m        \u001b[94m0.0230\u001b[0m        \u001b[36m0.2449\u001b[0m     +  0.0001  7.4420\n",
            "     18  0.8374       0.9812    0.7304        \u001b[31m0.4948\u001b[0m        \u001b[94m0.0228\u001b[0m        \u001b[36m0.2448\u001b[0m     +  0.0001  4.7892\n",
            "     19  \u001b[36m0.8394\u001b[0m       0.9812    \u001b[35m0.7334\u001b[0m        \u001b[31m0.4946\u001b[0m        \u001b[94m0.0226\u001b[0m        \u001b[36m0.2447\u001b[0m     +  0.0001  4.4460\n",
            "     20  \u001b[36m0.8441\u001b[0m       0.9811    \u001b[35m0.7407\u001b[0m        \u001b[31m0.4945\u001b[0m        \u001b[94m0.0225\u001b[0m        \u001b[36m0.2446\u001b[0m     +  0.0001  4.9944\n",
            "     21  0.8397       0.9811    0.7339        \u001b[31m0.4944\u001b[0m        \u001b[94m0.0223\u001b[0m        \u001b[36m0.2444\u001b[0m     +  0.0001  5.0013\n",
            "     22  0.8383       0.9810    0.7318        \u001b[31m0.4943\u001b[0m        \u001b[94m0.0220\u001b[0m        \u001b[36m0.2444\u001b[0m     +  0.0000  4.3084\n",
            "     23  0.8389       0.9810    0.7328        \u001b[31m0.4943\u001b[0m        \u001b[94m0.0220\u001b[0m        \u001b[36m0.2444\u001b[0m     +  0.0000  5.2685\n",
            "     24  0.8392       0.9810    0.7332        \u001b[31m0.4943\u001b[0m        \u001b[94m0.0220\u001b[0m        \u001b[36m0.2444\u001b[0m     +  0.0000  4.2845\n",
            "     25  0.8392       0.9809    0.7333        \u001b[31m0.4943\u001b[0m        \u001b[94m0.0219\u001b[0m        \u001b[36m0.2443\u001b[0m     +  0.0000  4.7082\n",
            "     26  0.8396       0.9809    0.7339        \u001b[31m0.4943\u001b[0m        0.0220        \u001b[36m0.2443\u001b[0m     +  0.0000  4.4982\n",
            "     27  0.8400       0.9810    0.7344        \u001b[31m0.4943\u001b[0m        \u001b[94m0.0219\u001b[0m        \u001b[36m0.2443\u001b[0m     +  0.0000  4.8299\n",
            "     28  0.8406       0.9810    0.7354        \u001b[31m0.4943\u001b[0m        0.0219        \u001b[36m0.2443\u001b[0m     +  0.0000  5.0052\n",
            "     29  0.8406       0.9810    0.7354        \u001b[31m0.4943\u001b[0m        \u001b[94m0.0219\u001b[0m        \u001b[36m0.2443\u001b[0m     +  0.0000  4.3543\n",
            "Stopping since valid_loss has not improved in the last 10 epochs.\n",
            "[CV 1/5; 1/1] END lr=0.01, module__dropout=0.3, module__linear_size=400, module__size_emb=120;, score=-1.143 total time= 3.2min\n",
            "[CV 2/5; 1/1] START lr=0.01, module__dropout=0.3, module__linear_size=400, module__size_emb=120\n",
            "  epoch      f1    precision    recall    rmse_score    train_loss    valid_loss    cp      lr     dur\n",
            "-------  ------  -----------  --------  ------------  ------------  ------------  ----  ------  ------\n",
            "      1  \u001b[36m0.5030\u001b[0m       \u001b[32m0.8910\u001b[0m    \u001b[35m0.3504\u001b[0m        \u001b[31m0.8845\u001b[0m        \u001b[94m0.9929\u001b[0m        \u001b[36m0.7823\u001b[0m     +  0.0100  4.6387\n",
            "      2  \u001b[36m0.7902\u001b[0m       \u001b[32m0.9351\u001b[0m    \u001b[35m0.6842\u001b[0m        \u001b[31m0.6464\u001b[0m        \u001b[94m0.6172\u001b[0m        \u001b[36m0.4179\u001b[0m     +  0.0100  4.7918\n",
            "      3  \u001b[36m0.8040\u001b[0m       \u001b[32m0.9600\u001b[0m    \u001b[35m0.6916\u001b[0m        \u001b[31m0.5715\u001b[0m        \u001b[94m0.2602\u001b[0m        \u001b[36m0.3266\u001b[0m     +  0.0100  4.4192\n",
            "      4  0.7683       \u001b[32m0.9709\u001b[0m    0.6357        \u001b[31m0.5443\u001b[0m        \u001b[94m0.1474\u001b[0m        \u001b[36m0.2962\u001b[0m     +  0.0100  4.3372\n",
            "      5  0.7935       0.9680    0.6723        \u001b[31m0.5337\u001b[0m        \u001b[94m0.1072\u001b[0m        \u001b[36m0.2848\u001b[0m     +  0.0100  5.1842\n",
            "      6  \u001b[36m0.8044\u001b[0m       0.9661    0.6890        \u001b[31m0.5304\u001b[0m        \u001b[94m0.0915\u001b[0m        \u001b[36m0.2813\u001b[0m     +  0.0100  4.3085\n",
            "      7  0.7874       0.9661    0.6645        \u001b[31m0.5300\u001b[0m        \u001b[94m0.0836\u001b[0m        \u001b[36m0.2809\u001b[0m     +  0.0100  5.3031\n",
            "      8  0.7856       \u001b[32m0.9711\u001b[0m    0.6596        \u001b[31m0.5129\u001b[0m        \u001b[94m0.0703\u001b[0m        \u001b[36m0.2631\u001b[0m     +  0.0010  4.0984\n",
            "      9  0.7939       \u001b[32m0.9725\u001b[0m    0.6707        \u001b[31m0.5035\u001b[0m        \u001b[94m0.0523\u001b[0m        \u001b[36m0.2535\u001b[0m     +  0.0010  4.4697\n",
            "     10  \u001b[36m0.8046\u001b[0m       \u001b[32m0.9731\u001b[0m    0.6858        \u001b[31m0.4977\u001b[0m        \u001b[94m0.0419\u001b[0m        \u001b[36m0.2477\u001b[0m     +  0.0010  4.8509\n",
            "     11  \u001b[36m0.8145\u001b[0m       \u001b[32m0.9732\u001b[0m    \u001b[35m0.7003\u001b[0m        \u001b[31m0.4940\u001b[0m        \u001b[94m0.0351\u001b[0m        \u001b[36m0.2440\u001b[0m     +  0.0010  4.4342\n",
            "     12  \u001b[36m0.8214\u001b[0m       0.9727    \u001b[35m0.7109\u001b[0m        \u001b[31m0.4915\u001b[0m        \u001b[94m0.0306\u001b[0m        \u001b[36m0.2416\u001b[0m     +  0.0010  5.1284\n",
            "     13  0.8176       0.9732    0.7049        \u001b[31m0.4896\u001b[0m        \u001b[94m0.0276\u001b[0m        \u001b[36m0.2397\u001b[0m     +  0.0010  4.7551\n",
            "     14  \u001b[36m0.8344\u001b[0m       0.9728    \u001b[35m0.7304\u001b[0m        \u001b[31m0.4885\u001b[0m        \u001b[94m0.0252\u001b[0m        \u001b[36m0.2386\u001b[0m     +  0.0010  5.2410\n",
            "     15  \u001b[36m0.8369\u001b[0m       0.9727    \u001b[35m0.7344\u001b[0m        \u001b[31m0.4884\u001b[0m        \u001b[94m0.0231\u001b[0m        \u001b[36m0.2385\u001b[0m     +  0.0001  4.3200\n",
            "     16  0.8367       0.9727    0.7341        \u001b[31m0.4883\u001b[0m        \u001b[94m0.0229\u001b[0m        \u001b[36m0.2384\u001b[0m     +  0.0001  4.9888\n",
            "     17  0.8363       0.9727    0.7334        \u001b[31m0.4882\u001b[0m        \u001b[94m0.0227\u001b[0m        \u001b[36m0.2383\u001b[0m     +  0.0001  4.6672\n",
            "     18  \u001b[36m0.8375\u001b[0m       0.9727    \u001b[35m0.7353\u001b[0m        \u001b[31m0.4880\u001b[0m        \u001b[94m0.0225\u001b[0m        \u001b[36m0.2382\u001b[0m     +  0.0001  4.3576\n",
            "     19  \u001b[36m0.8383\u001b[0m       0.9728    \u001b[35m0.7364\u001b[0m        \u001b[31m0.4879\u001b[0m        \u001b[94m0.0223\u001b[0m        \u001b[36m0.2381\u001b[0m     +  0.0001  5.2449\n",
            "     20  \u001b[36m0.8395\u001b[0m       0.9728    \u001b[35m0.7383\u001b[0m        \u001b[31m0.4878\u001b[0m        \u001b[94m0.0221\u001b[0m        \u001b[36m0.2380\u001b[0m     +  0.0001  4.3434\n",
            "     21  0.8375       0.9727    0.7352        \u001b[31m0.4877\u001b[0m        \u001b[94m0.0219\u001b[0m        \u001b[36m0.2378\u001b[0m     +  0.0001  4.5971\n",
            "     22  0.8390       0.9728    0.7376        0.4877        \u001b[94m0.0217\u001b[0m        0.2378        0.0000  4.2951\n",
            "     23  0.8393       0.9727    0.7381        \u001b[31m0.4877\u001b[0m        0.0218        \u001b[36m0.2378\u001b[0m     +  0.0000  4.3595\n",
            "     24  0.8387       0.9727    0.7371        \u001b[31m0.4876\u001b[0m        \u001b[94m0.0217\u001b[0m        \u001b[36m0.2378\u001b[0m     +  0.0000  5.1183\n",
            "     25  \u001b[36m0.8398\u001b[0m       0.9727    \u001b[35m0.7388\u001b[0m        \u001b[31m0.4876\u001b[0m        \u001b[94m0.0217\u001b[0m        \u001b[36m0.2378\u001b[0m     +  0.0000  4.3143\n",
            "     26  0.8396       0.9727    0.7385        \u001b[31m0.4876\u001b[0m        0.0217        \u001b[36m0.2378\u001b[0m     +  0.0000  5.1509\n",
            "     27  \u001b[36m0.8399\u001b[0m       0.9727    \u001b[35m0.7391\u001b[0m        \u001b[31m0.4876\u001b[0m        \u001b[94m0.0217\u001b[0m        \u001b[36m0.2378\u001b[0m     +  0.0000  4.3627\n",
            "     28  \u001b[36m0.8406\u001b[0m       0.9728    \u001b[35m0.7401\u001b[0m        \u001b[31m0.4876\u001b[0m        \u001b[94m0.0216\u001b[0m        \u001b[36m0.2378\u001b[0m     +  0.0000  4.3578\n",
            "     29  0.8405       0.9728    0.7399        \u001b[31m0.4876\u001b[0m        0.0216        \u001b[36m0.2378\u001b[0m     +  0.0000  5.0179\n",
            "     30  0.8405       0.9728    0.7400        \u001b[31m0.4876\u001b[0m        0.0216        \u001b[36m0.2378\u001b[0m     +  0.0000  4.4689\n",
            "Stopping since valid_loss has not improved in the last 10 epochs.\n",
            "[CV 2/5; 1/1] END lr=0.01, module__dropout=0.3, module__linear_size=400, module__size_emb=120;, score=-1.119 total time= 2.8min\n",
            "[CV 3/5; 1/1] START lr=0.01, module__dropout=0.3, module__linear_size=400, module__size_emb=120\n",
            "  epoch      f1    precision    recall    rmse_score    train_loss    valid_loss    cp      lr     dur\n",
            "-------  ------  -----------  --------  ------------  ------------  ------------  ----  ------  ------\n",
            "      1  \u001b[36m0.4765\u001b[0m       \u001b[32m0.8994\u001b[0m    \u001b[35m0.3241\u001b[0m        \u001b[31m0.8739\u001b[0m        \u001b[94m0.9952\u001b[0m        \u001b[36m0.7638\u001b[0m     +  0.0100  4.2638\n",
            "      2  \u001b[36m0.7422\u001b[0m       \u001b[32m0.9530\u001b[0m    \u001b[35m0.6077\u001b[0m        \u001b[31m0.6349\u001b[0m        \u001b[94m0.6269\u001b[0m        \u001b[36m0.4031\u001b[0m     +  0.0100  5.4152\n",
            "      3  \u001b[36m0.7550\u001b[0m       \u001b[32m0.9720\u001b[0m    \u001b[35m0.6172\u001b[0m        \u001b[31m0.5610\u001b[0m        \u001b[94m0.2583\u001b[0m        \u001b[36m0.3147\u001b[0m     +  0.0100  4.4201\n",
            "      4  \u001b[36m0.7833\u001b[0m       \u001b[32m0.9765\u001b[0m    \u001b[35m0.6539\u001b[0m        \u001b[31m0.5341\u001b[0m        \u001b[94m0.1438\u001b[0m        \u001b[36m0.2853\u001b[0m     +  0.0100  4.3854\n",
            "      5  0.7758       0.9746    0.6443        \u001b[31m0.5265\u001b[0m        \u001b[94m0.1053\u001b[0m        \u001b[36m0.2772\u001b[0m     +  0.0100  5.1425\n",
            "      6  0.7768       0.9737    0.6461        \u001b[31m0.5237\u001b[0m        \u001b[94m0.0908\u001b[0m        \u001b[36m0.2743\u001b[0m     +  0.0100  4.4398\n",
            "      7  0.7726       0.9749    0.6398        \u001b[31m0.5189\u001b[0m        \u001b[94m0.0830\u001b[0m        \u001b[36m0.2693\u001b[0m     +  0.0100  5.2449\n",
            "      8  0.7824       \u001b[32m0.9786\u001b[0m    0.6518        \u001b[31m0.5031\u001b[0m        \u001b[94m0.0688\u001b[0m        \u001b[36m0.2531\u001b[0m     +  0.0010  4.3485\n",
            "      9  0.7745       \u001b[32m0.9797\u001b[0m    0.6404        \u001b[31m0.4948\u001b[0m        \u001b[94m0.0515\u001b[0m        \u001b[36m0.2448\u001b[0m     +  0.0010  5.4448\n",
            "     10  \u001b[36m0.7941\u001b[0m       0.9796    \u001b[35m0.6677\u001b[0m        \u001b[31m0.4893\u001b[0m        \u001b[94m0.0412\u001b[0m        \u001b[36m0.2394\u001b[0m     +  0.0010  4.9366\n",
            "     11  \u001b[36m0.8106\u001b[0m       0.9797    \u001b[35m0.6914\u001b[0m        \u001b[31m0.4856\u001b[0m        \u001b[94m0.0346\u001b[0m        \u001b[36m0.2358\u001b[0m     +  0.0010  4.3950\n",
            "     12  \u001b[36m0.8222\u001b[0m       \u001b[32m0.9803\u001b[0m    \u001b[35m0.7081\u001b[0m        \u001b[31m0.4834\u001b[0m        \u001b[94m0.0302\u001b[0m        \u001b[36m0.2337\u001b[0m     +  0.0010  5.2023\n",
            "     13  0.8133       0.9800    0.6950        \u001b[31m0.4820\u001b[0m        \u001b[94m0.0271\u001b[0m        \u001b[36m0.2324\u001b[0m     +  0.0010  4.3595\n",
            "     14  0.8113       0.9799    0.6922        \u001b[31m0.4809\u001b[0m        \u001b[94m0.0248\u001b[0m        \u001b[36m0.2312\u001b[0m     +  0.0010  4.5518\n",
            "     15  0.8216       0.9799    0.7074        \u001b[31m0.4805\u001b[0m        \u001b[94m0.0228\u001b[0m        \u001b[36m0.2309\u001b[0m     +  0.0001  4.5975\n",
            "     16  0.8222       0.9799    \u001b[35m0.7083\u001b[0m        \u001b[31m0.4804\u001b[0m        \u001b[94m0.0226\u001b[0m        \u001b[36m0.2308\u001b[0m     +  0.0001  4.3642\n",
            "     17  \u001b[36m0.8228\u001b[0m       0.9799    \u001b[35m0.7091\u001b[0m        \u001b[31m0.4803\u001b[0m        \u001b[94m0.0224\u001b[0m        \u001b[36m0.2307\u001b[0m     +  0.0001  5.1922\n",
            "     18  \u001b[36m0.8230\u001b[0m       0.9799    \u001b[35m0.7094\u001b[0m        \u001b[31m0.4802\u001b[0m        \u001b[94m0.0222\u001b[0m        \u001b[36m0.2306\u001b[0m     +  0.0001  4.3685\n",
            "     19  \u001b[36m0.8257\u001b[0m       0.9799    \u001b[35m0.7134\u001b[0m        \u001b[31m0.4801\u001b[0m        \u001b[94m0.0220\u001b[0m        \u001b[36m0.2305\u001b[0m     +  0.0001  4.9936\n",
            "     20  0.8241       0.9798    0.7111        \u001b[31m0.4800\u001b[0m        \u001b[94m0.0219\u001b[0m        \u001b[36m0.2304\u001b[0m     +  0.0001  4.4056\n",
            "     21  \u001b[36m0.8292\u001b[0m       0.9801    \u001b[35m0.7185\u001b[0m        \u001b[31m0.4798\u001b[0m        \u001b[94m0.0217\u001b[0m        \u001b[36m0.2302\u001b[0m     +  0.0001  4.3542\n",
            "     22  0.8270       0.9800    0.7153        0.4799        \u001b[94m0.0214\u001b[0m        0.2303        0.0000  5.2001\n",
            "     23  0.8260       0.9799    0.7139        0.4799        \u001b[94m0.0214\u001b[0m        0.2303        0.0000  4.3875\n",
            "     24  0.8273       0.9800    0.7157        0.4798        0.0215        0.2302        0.0000  4.8425\n",
            "     25  0.8268       0.9800    0.7151        0.4798        \u001b[94m0.0214\u001b[0m        0.2302        0.0000  4.7559\n",
            "     26  0.8262       0.9799    0.7142        \u001b[31m0.4798\u001b[0m        0.0214        \u001b[36m0.2302\u001b[0m     +  0.0000  4.1114\n",
            "     27  0.8277       0.9800    0.7163        \u001b[31m0.4798\u001b[0m        \u001b[94m0.0213\u001b[0m        \u001b[36m0.2302\u001b[0m     +  0.0000  5.1532\n",
            "     28  0.8263       0.9799    0.7143        0.4798        0.0214        0.2302        0.0000  4.3684\n",
            "     29  0.8263       0.9799    0.7143        0.4798        \u001b[94m0.0213\u001b[0m        0.2302        0.0000  4.4787\n",
            "Stopping since valid_loss has not improved in the last 10 epochs.\n",
            "[CV 3/5; 1/1] END lr=0.01, module__dropout=0.3, module__linear_size=400, module__size_emb=120;, score=-1.054 total time= 2.6min\n",
            "[CV 4/5; 1/1] START lr=0.01, module__dropout=0.3, module__linear_size=400, module__size_emb=120\n",
            "  epoch      f1    precision    recall    rmse_score    train_loss    valid_loss    cp      lr     dur\n",
            "-------  ------  -----------  --------  ------------  ------------  ------------  ----  ------  ------\n",
            "      1  \u001b[36m0.6677\u001b[0m       \u001b[32m0.8186\u001b[0m    \u001b[35m0.5639\u001b[0m        \u001b[31m0.8874\u001b[0m        \u001b[94m1.0133\u001b[0m        \u001b[36m0.7875\u001b[0m     +  0.0100  4.3891\n",
            "      2  \u001b[36m0.7145\u001b[0m       \u001b[32m0.9539\u001b[0m    \u001b[35m0.5712\u001b[0m        \u001b[31m0.6195\u001b[0m        \u001b[94m0.6361\u001b[0m        \u001b[36m0.3837\u001b[0m     +  0.0100  5.1785\n",
            "      3  \u001b[36m0.7848\u001b[0m       \u001b[32m0.9604\u001b[0m    \u001b[35m0.6635\u001b[0m        \u001b[31m0.5409\u001b[0m        \u001b[94m0.2594\u001b[0m        \u001b[36m0.2926\u001b[0m     +  0.0100  4.3309\n",
            "      4  \u001b[36m0.7888\u001b[0m       \u001b[32m0.9668\u001b[0m    \u001b[35m0.6662\u001b[0m        \u001b[31m0.5160\u001b[0m        \u001b[94m0.1451\u001b[0m        \u001b[36m0.2663\u001b[0m     +  0.0100  4.7883\n",
            "      5  \u001b[36m0.8201\u001b[0m       0.9623    \u001b[35m0.7145\u001b[0m        \u001b[31m0.5071\u001b[0m        \u001b[94m0.1064\u001b[0m        \u001b[36m0.2572\u001b[0m     +  0.0100  4.2916\n",
            "      6  0.7657       \u001b[32m0.9686\u001b[0m    0.6332        \u001b[31m0.5013\u001b[0m        \u001b[94m0.0900\u001b[0m        \u001b[36m0.2513\u001b[0m     +  0.0100  4.3265\n",
            "      7  0.7884       0.9646    0.6667        \u001b[31m0.4986\u001b[0m        \u001b[94m0.0833\u001b[0m        \u001b[36m0.2486\u001b[0m     +  0.0100  5.1006\n",
            "      8  0.7876       0.9682    0.6638        \u001b[31m0.4830\u001b[0m        \u001b[94m0.0689\u001b[0m        \u001b[36m0.2333\u001b[0m     +  0.0010  4.4053\n",
            "      9  0.7948       \u001b[32m0.9697\u001b[0m    0.6734        \u001b[31m0.4738\u001b[0m        \u001b[94m0.0515\u001b[0m        \u001b[36m0.2245\u001b[0m     +  0.0010  4.9567\n",
            "     10  0.7935       0.9695    0.6716        \u001b[31m0.4681\u001b[0m        \u001b[94m0.0414\u001b[0m        \u001b[36m0.2192\u001b[0m     +  0.0010  4.4824\n",
            "     11  0.8092       \u001b[32m0.9699\u001b[0m    0.6942        \u001b[31m0.4645\u001b[0m        \u001b[94m0.0346\u001b[0m        \u001b[36m0.2158\u001b[0m     +  0.0010  4.3596\n",
            "     12  0.8153       \u001b[32m0.9701\u001b[0m    0.7031        \u001b[31m0.4620\u001b[0m        \u001b[94m0.0301\u001b[0m        \u001b[36m0.2135\u001b[0m     +  0.0010  5.2181\n",
            "     13  \u001b[36m0.8252\u001b[0m       \u001b[32m0.9703\u001b[0m    \u001b[35m0.7178\u001b[0m        \u001b[31m0.4603\u001b[0m        \u001b[94m0.0269\u001b[0m        \u001b[36m0.2118\u001b[0m     +  0.0010  4.4351\n",
            "     14  \u001b[36m0.8353\u001b[0m       0.9700    \u001b[35m0.7335\u001b[0m        \u001b[31m0.4590\u001b[0m        \u001b[94m0.0247\u001b[0m        \u001b[36m0.2107\u001b[0m     +  0.0010  5.2486\n",
            "     15  0.8331       0.9696    0.7302        \u001b[31m0.4589\u001b[0m        \u001b[94m0.0226\u001b[0m        \u001b[36m0.2106\u001b[0m     +  0.0001  4.4438\n",
            "     16  0.8308       0.9696    0.7268        \u001b[31m0.4587\u001b[0m        \u001b[94m0.0224\u001b[0m        \u001b[36m0.2104\u001b[0m     +  0.0001  4.4103\n",
            "     17  0.8296       0.9695    0.7250        \u001b[31m0.4586\u001b[0m        \u001b[94m0.0222\u001b[0m        \u001b[36m0.2104\u001b[0m     +  0.0001  4.8724\n",
            "     18  0.8304       0.9696    0.7262        \u001b[31m0.4585\u001b[0m        \u001b[94m0.0221\u001b[0m        \u001b[36m0.2102\u001b[0m     +  0.0001  4.3910\n",
            "     19  \u001b[36m0.8363\u001b[0m       0.9696    \u001b[35m0.7352\u001b[0m        \u001b[31m0.4584\u001b[0m        \u001b[94m0.0218\u001b[0m        \u001b[36m0.2101\u001b[0m     +  0.0001  4.9136\n",
            "     20  0.8312       0.9695    0.7274        \u001b[31m0.4583\u001b[0m        \u001b[94m0.0216\u001b[0m        \u001b[36m0.2100\u001b[0m     +  0.0001  4.2936\n",
            "     21  0.8359       0.9696    0.7347        \u001b[31m0.4582\u001b[0m        \u001b[94m0.0214\u001b[0m        \u001b[36m0.2099\u001b[0m     +  0.0001  4.5050\n",
            "     22  0.8339       0.9695    0.7315        \u001b[31m0.4581\u001b[0m        \u001b[94m0.0212\u001b[0m        \u001b[36m0.2099\u001b[0m     +  0.0000  4.7134\n",
            "     23  0.8336       0.9696    0.7311        \u001b[31m0.4581\u001b[0m        \u001b[94m0.0212\u001b[0m        \u001b[36m0.2099\u001b[0m     +  0.0000  4.3143\n",
            "     24  0.8336       0.9696    0.7311        \u001b[31m0.4581\u001b[0m        0.0212        \u001b[36m0.2099\u001b[0m     +  0.0000  5.1670\n",
            "     25  0.8330       0.9696    0.7302        \u001b[31m0.4581\u001b[0m        \u001b[94m0.0211\u001b[0m        \u001b[36m0.2099\u001b[0m     +  0.0000  4.3474\n",
            "     26  0.8331       0.9696    0.7302        \u001b[31m0.4581\u001b[0m        0.0211        \u001b[36m0.2099\u001b[0m     +  0.0000  4.8244\n",
            "     27  0.8331       0.9696    0.7303        \u001b[31m0.4581\u001b[0m        \u001b[94m0.0211\u001b[0m        \u001b[36m0.2098\u001b[0m     +  0.0000  4.4607\n",
            "     28  0.8336       0.9696    0.7310        \u001b[31m0.4581\u001b[0m        \u001b[94m0.0211\u001b[0m        \u001b[36m0.2098\u001b[0m     +  0.0000  4.3907\n",
            "     29  0.8336       0.9696    0.7310        \u001b[31m0.4581\u001b[0m        \u001b[94m0.0211\u001b[0m        \u001b[36m0.2098\u001b[0m     +  0.0000  5.1446\n",
            "     30  0.8336       0.9696    0.7310        \u001b[31m0.4581\u001b[0m        \u001b[94m0.0210\u001b[0m        \u001b[36m0.2098\u001b[0m     +  0.0000  4.3094\n",
            "Stopping since valid_loss has not improved in the last 10 epochs.\n",
            "[CV 4/5; 1/1] END lr=0.01, module__dropout=0.3, module__linear_size=400, module__size_emb=120;, score=-0.968 total time= 2.8min\n",
            "[CV 5/5; 1/1] START lr=0.01, module__dropout=0.3, module__linear_size=400, module__size_emb=120\n",
            "  epoch      f1    precision    recall    rmse_score    train_loss    valid_loss    cp      lr     dur\n",
            "-------  ------  -----------  --------  ------------  ------------  ------------  ----  ------  ------\n",
            "      1  \u001b[36m0.5998\u001b[0m       \u001b[32m0.8529\u001b[0m    \u001b[35m0.4625\u001b[0m        \u001b[31m0.8857\u001b[0m        \u001b[94m0.9720\u001b[0m        \u001b[36m0.7845\u001b[0m     +  0.0100  4.2349\n",
            "      2  \u001b[36m0.7240\u001b[0m       \u001b[32m0.9562\u001b[0m    \u001b[35m0.5826\u001b[0m        \u001b[31m0.6530\u001b[0m        \u001b[94m0.6224\u001b[0m        \u001b[36m0.4265\u001b[0m     +  0.0100  4.3032\n",
            "      3  \u001b[36m0.7876\u001b[0m       \u001b[32m0.9749\u001b[0m    \u001b[35m0.6607\u001b[0m        \u001b[31m0.5782\u001b[0m        \u001b[94m0.2692\u001b[0m        \u001b[36m0.3343\u001b[0m     +  0.0100  5.0291\n",
            "      4  0.7720       \u001b[32m0.9788\u001b[0m    0.6373        \u001b[31m0.5503\u001b[0m        \u001b[94m0.1520\u001b[0m        \u001b[36m0.3029\u001b[0m     +  0.0100  4.3676\n",
            "      5  0.7860       0.9764    0.6578        \u001b[31m0.5405\u001b[0m        \u001b[94m0.1110\u001b[0m        \u001b[36m0.2922\u001b[0m     +  0.0100  5.1176\n",
            "      6  0.7838       0.9771    0.6543        \u001b[31m0.5376\u001b[0m        \u001b[94m0.0944\u001b[0m        \u001b[36m0.2890\u001b[0m     +  0.0100  4.2995\n",
            "      7  \u001b[36m0.8181\u001b[0m       0.9748    \u001b[35m0.7048\u001b[0m        \u001b[31m0.5375\u001b[0m        \u001b[94m0.0841\u001b[0m        \u001b[36m0.2889\u001b[0m     +  0.0100  4.4245\n",
            "      8  0.7825       \u001b[32m0.9810\u001b[0m    0.6508        \u001b[31m0.5198\u001b[0m        \u001b[94m0.0695\u001b[0m        \u001b[36m0.2701\u001b[0m     +  0.0010  4.8249\n",
            "      9  0.7920       \u001b[32m0.9813\u001b[0m    0.6639        \u001b[31m0.5116\u001b[0m        \u001b[94m0.0519\u001b[0m        \u001b[36m0.2617\u001b[0m     +  0.0010  4.3356\n",
            "     10  0.7926       \u001b[32m0.9816\u001b[0m    0.6647        \u001b[31m0.5064\u001b[0m        \u001b[94m0.0422\u001b[0m        \u001b[36m0.2565\u001b[0m     +  0.0010  5.2263\n",
            "     11  0.7955       \u001b[32m0.9820\u001b[0m    0.6686        \u001b[31m0.5032\u001b[0m        \u001b[94m0.0359\u001b[0m        \u001b[36m0.2532\u001b[0m     +  0.0010  4.3940\n",
            "     12  \u001b[36m0.8205\u001b[0m       \u001b[32m0.9824\u001b[0m    0.7044        \u001b[31m0.5007\u001b[0m        \u001b[94m0.0317\u001b[0m        \u001b[36m0.2507\u001b[0m     +  0.0010  4.5536\n",
            "     13  \u001b[36m0.8217\u001b[0m       0.9823    \u001b[35m0.7062\u001b[0m        \u001b[31m0.4991\u001b[0m        \u001b[94m0.0285\u001b[0m        \u001b[36m0.2491\u001b[0m     +  0.0010  4.6902\n",
            "     14  \u001b[36m0.8285\u001b[0m       0.9820    \u001b[35m0.7165\u001b[0m        \u001b[31m0.4979\u001b[0m        \u001b[94m0.0263\u001b[0m        \u001b[36m0.2479\u001b[0m     +  0.0010  4.0402\n",
            "     15  0.8253       0.9821    0.7117        \u001b[31m0.4978\u001b[0m        \u001b[94m0.0241\u001b[0m        \u001b[36m0.2478\u001b[0m     +  0.0001  5.1407\n",
            "     16  0.8210       0.9819    0.7054        \u001b[31m0.4977\u001b[0m        \u001b[94m0.0239\u001b[0m        \u001b[36m0.2477\u001b[0m     +  0.0001  4.2607\n",
            "     17  0.8219       0.9820    0.7067        \u001b[31m0.4977\u001b[0m        \u001b[94m0.0237\u001b[0m        \u001b[36m0.2477\u001b[0m     +  0.0001  4.9342\n",
            "     18  0.8224       0.9820    0.7074        \u001b[31m0.4976\u001b[0m        \u001b[94m0.0235\u001b[0m        \u001b[36m0.2476\u001b[0m     +  0.0001  4.5007\n",
            "     19  0.8250       0.9819    0.7114        \u001b[31m0.4974\u001b[0m        \u001b[94m0.0234\u001b[0m        \u001b[36m0.2474\u001b[0m     +  0.0001  4.3576\n",
            "     20  0.8201       0.9819    0.7041        \u001b[31m0.4974\u001b[0m        \u001b[94m0.0232\u001b[0m        \u001b[36m0.2474\u001b[0m     +  0.0001  5.2012\n",
            "     21  0.8229       0.9819    0.7082        \u001b[31m0.4973\u001b[0m        \u001b[94m0.0231\u001b[0m        \u001b[36m0.2473\u001b[0m     +  0.0001  4.2181\n",
            "     22  0.8242       0.9819    0.7102        \u001b[31m0.4972\u001b[0m        \u001b[94m0.0228\u001b[0m        \u001b[36m0.2472\u001b[0m     +  0.0000  4.9713\n",
            "     23  0.8252       0.9820    0.7116        \u001b[31m0.4972\u001b[0m        \u001b[94m0.0228\u001b[0m        \u001b[36m0.2472\u001b[0m     +  0.0000  4.3584\n",
            "     24  0.8247       0.9819    0.7108        \u001b[31m0.4972\u001b[0m        \u001b[94m0.0227\u001b[0m        \u001b[36m0.2472\u001b[0m     +  0.0000  4.1747\n",
            "     25  0.8250       0.9819    0.7113        \u001b[31m0.4972\u001b[0m        0.0228        \u001b[36m0.2472\u001b[0m     +  0.0000  5.1102\n",
            "     26  0.8253       0.9820    0.7118        \u001b[31m0.4972\u001b[0m        \u001b[94m0.0227\u001b[0m        \u001b[36m0.2472\u001b[0m     +  0.0000  4.0192\n",
            "     27  0.8254       0.9820    0.7119        \u001b[31m0.4972\u001b[0m        0.0227        \u001b[36m0.2472\u001b[0m     +  0.0000  5.1238\n",
            "     28  0.8250       0.9819    0.7114        \u001b[31m0.4972\u001b[0m        0.0227        \u001b[36m0.2472\u001b[0m     +  0.0000  4.2875\n",
            "Stopping since valid_loss has not improved in the last 10 epochs.\n",
            "[CV 5/5; 1/1] END lr=0.01, module__dropout=0.3, module__linear_size=400, module__size_emb=120;, score=-1.182 total time= 2.5min\n",
            "  epoch      f1    precision    recall    rmse_score    train_loss    valid_loss    cp      lr     dur\n",
            "-------  ------  -----------  --------  ------------  ------------  ------------  ----  ------  ------\n",
            "      1  \u001b[36m0.6234\u001b[0m       \u001b[32m0.8914\u001b[0m    \u001b[35m0.4793\u001b[0m        \u001b[31m0.8153\u001b[0m        \u001b[94m0.9727\u001b[0m        \u001b[36m0.6648\u001b[0m     +  0.0100  5.7486\n",
            "      2  \u001b[36m0.8119\u001b[0m       \u001b[32m0.9655\u001b[0m    \u001b[35m0.7005\u001b[0m        \u001b[31m0.4906\u001b[0m        \u001b[94m0.5987\u001b[0m        \u001b[36m0.2406\u001b[0m     +  0.0100  5.3507\n",
            "      3  \u001b[36m0.8576\u001b[0m       \u001b[32m0.9878\u001b[0m    \u001b[35m0.7578\u001b[0m        \u001b[31m0.3705\u001b[0m        \u001b[94m0.2582\u001b[0m        \u001b[36m0.1373\u001b[0m     +  0.0100  5.8363\n",
            "      4  0.8427       \u001b[32m0.9940\u001b[0m    0.7314        \u001b[31m0.3116\u001b[0m        \u001b[94m0.1512\u001b[0m        \u001b[36m0.0971\u001b[0m     +  0.0100  5.1381\n",
            "      5  \u001b[36m0.8649\u001b[0m       0.9929    \u001b[35m0.7661\u001b[0m        \u001b[31m0.2896\u001b[0m        \u001b[94m0.1097\u001b[0m        \u001b[36m0.0839\u001b[0m     +  0.0100  6.0593\n",
            "      6  \u001b[36m0.8691\u001b[0m       0.9923    \u001b[35m0.7731\u001b[0m        \u001b[31m0.2823\u001b[0m        \u001b[94m0.0941\u001b[0m        \u001b[36m0.0797\u001b[0m     +  0.0100  5.0699\n",
            "      7  0.8613       0.9914    0.7614        \u001b[31m0.2784\u001b[0m        \u001b[94m0.0863\u001b[0m        \u001b[36m0.0775\u001b[0m     +  0.0100  6.1222\n",
            "      8  0.8586       \u001b[32m0.9983\u001b[0m    0.7532        \u001b[31m0.2351\u001b[0m        \u001b[94m0.0744\u001b[0m        \u001b[36m0.0553\u001b[0m     +  0.0010  5.2009\n",
            "      9  0.8658       \u001b[32m0.9999\u001b[0m    0.7634        \u001b[31m0.2069\u001b[0m        \u001b[94m0.0549\u001b[0m        \u001b[36m0.0428\u001b[0m     +  0.0010  6.2785\n",
            "     10  0.8674       \u001b[32m0.9999\u001b[0m    0.7659        \u001b[31m0.1876\u001b[0m        \u001b[94m0.0437\u001b[0m        \u001b[36m0.0352\u001b[0m     +  0.0010  5.1474\n",
            "     11  \u001b[36m0.8697\u001b[0m       \u001b[32m0.9999\u001b[0m    0.7695        \u001b[31m0.1741\u001b[0m        \u001b[94m0.0366\u001b[0m        \u001b[36m0.0303\u001b[0m     +  0.0010  6.1317\n",
            "     12  \u001b[36m0.8948\u001b[0m       \u001b[32m0.9999\u001b[0m    \u001b[35m0.8097\u001b[0m        \u001b[31m0.1633\u001b[0m        \u001b[94m0.0317\u001b[0m        \u001b[36m0.0267\u001b[0m     +  0.0010  5.0115\n",
            "     13  \u001b[36m0.9041\u001b[0m       \u001b[32m0.9999\u001b[0m    \u001b[35m0.8250\u001b[0m        \u001b[31m0.1560\u001b[0m        \u001b[94m0.0285\u001b[0m        \u001b[36m0.0243\u001b[0m     +  0.0010  6.1851\n",
            "     14  0.8906       0.9999    0.8029        \u001b[31m0.1498\u001b[0m        \u001b[94m0.0260\u001b[0m        \u001b[36m0.0224\u001b[0m     +  0.0010  5.0322\n",
            "     15  0.9026       0.9999    0.8226        \u001b[31m0.1491\u001b[0m        \u001b[94m0.0237\u001b[0m        \u001b[36m0.0222\u001b[0m     +  0.0001  6.2772\n",
            "     16  0.8992       0.9999    0.8169        \u001b[31m0.1484\u001b[0m        \u001b[94m0.0235\u001b[0m        \u001b[36m0.0220\u001b[0m     +  0.0001  5.0167\n",
            "     17  0.9006       0.9999    0.8193        \u001b[31m0.1478\u001b[0m        \u001b[94m0.0233\u001b[0m        \u001b[36m0.0218\u001b[0m     +  0.0001  6.0712\n",
            "     18  0.9026       0.9999    0.8226        \u001b[31m0.1472\u001b[0m        \u001b[94m0.0231\u001b[0m        \u001b[36m0.0217\u001b[0m     +  0.0001  5.5839\n",
            "     19  \u001b[36m0.9066\u001b[0m       \u001b[32m0.9999\u001b[0m    \u001b[35m0.8292\u001b[0m        \u001b[31m0.1465\u001b[0m        \u001b[94m0.0229\u001b[0m        \u001b[36m0.0215\u001b[0m     +  0.0001  6.5031\n",
            "     20  0.8996       0.9999    0.8175        \u001b[31m0.1458\u001b[0m        \u001b[94m0.0227\u001b[0m        \u001b[36m0.0212\u001b[0m     +  0.0001  5.0759\n",
            "     21  0.9022       0.9999    0.8219        \u001b[31m0.1453\u001b[0m        \u001b[94m0.0225\u001b[0m        \u001b[36m0.0211\u001b[0m     +  0.0001  6.2142\n",
            "     22  0.9025       0.9999    0.8224        \u001b[31m0.1451\u001b[0m        \u001b[94m0.0223\u001b[0m        \u001b[36m0.0211\u001b[0m     +  0.0000  5.0495\n",
            "     23  0.9031       0.9999    0.8234        \u001b[31m0.1450\u001b[0m        \u001b[94m0.0222\u001b[0m        \u001b[36m0.0210\u001b[0m     +  0.0000  6.2160\n",
            "     24  0.9022       0.9999    0.8220        \u001b[31m0.1450\u001b[0m        0.0223        \u001b[36m0.0210\u001b[0m     +  0.0000  5.0711\n",
            "     25  0.9020       0.9999    0.8215        \u001b[31m0.1449\u001b[0m        0.0222        \u001b[36m0.0210\u001b[0m     +  0.0000  6.0537\n",
            "     26  0.9036       0.9999    0.8242        \u001b[31m0.1448\u001b[0m        \u001b[94m0.0222\u001b[0m        \u001b[36m0.0210\u001b[0m     +  0.0000  4.9671\n",
            "     27  0.9024       0.9999    0.8222        \u001b[31m0.1447\u001b[0m        \u001b[94m0.0221\u001b[0m        \u001b[36m0.0209\u001b[0m     +  0.0000  6.0282\n",
            "     28  0.9022       0.9999    0.8220        \u001b[31m0.1446\u001b[0m        \u001b[94m0.0221\u001b[0m        \u001b[36m0.0209\u001b[0m     +  0.0000  4.9325\n",
            "     29  0.9025       0.9999    0.8223        \u001b[31m0.1446\u001b[0m        \u001b[94m0.0221\u001b[0m        \u001b[36m0.0209\u001b[0m     +  0.0000  6.1866\n",
            "     30  0.9025       0.9999    0.8224        \u001b[31m0.1446\u001b[0m        0.0221        \u001b[36m0.0209\u001b[0m     +  0.0000  4.9236\n",
            "     31  0.9026       0.9999    0.8225        \u001b[31m0.1446\u001b[0m        0.0221        \u001b[36m0.0209\u001b[0m     +  0.0000  5.8797\n",
            "     32  0.9026       0.9999    0.8225        \u001b[31m0.1446\u001b[0m        \u001b[94m0.0221\u001b[0m        \u001b[36m0.0209\u001b[0m     +  0.0000  5.0464\n",
            "     33  0.9029       0.9999    0.8231        \u001b[31m0.1446\u001b[0m        0.0221        \u001b[36m0.0209\u001b[0m     +  0.0000  5.7559\n",
            "     34  0.9027       0.9999    0.8227        \u001b[31m0.1446\u001b[0m        \u001b[94m0.0220\u001b[0m        \u001b[36m0.0209\u001b[0m     +  0.0000  5.1701\n",
            "     35  0.9028       0.9999    0.8229        \u001b[31m0.1446\u001b[0m        0.0221        \u001b[36m0.0209\u001b[0m     +  0.0000  5.5622\n",
            "     36  0.9028       0.9999    0.8229        \u001b[31m0.1446\u001b[0m        0.0220        \u001b[36m0.0209\u001b[0m     +  0.0000  5.4367\n",
            "     37  0.9028       0.9999    0.8229        \u001b[31m0.1446\u001b[0m        0.0221        \u001b[36m0.0209\u001b[0m     +  0.0000  5.4340\n",
            "     38  0.9028       0.9999    0.8229        \u001b[31m0.1446\u001b[0m        0.0221        \u001b[36m0.0209\u001b[0m     +  0.0000  5.4307\n",
            "     39  0.9028       0.9999    0.8230        \u001b[31m0.1446\u001b[0m        0.0221        \u001b[36m0.0209\u001b[0m     +  0.0000  5.2809\n",
            "     40  0.9028       0.9999    0.8230        \u001b[31m0.1446\u001b[0m        0.0220        \u001b[36m0.0209\u001b[0m     +  0.0000  5.8090\n",
            "Stopping since valid_loss has not improved in the last 10 epochs.\n",
            "-1.0931230783462524 {'lr': 0.01, 'module__dropout': 0.3, 'module__linear_size': 400, 'module__size_emb': 120}\n"
          ]
        }
      ],
      "source": [
        "params = {\n",
        "    'lr': [0.01],\n",
        "    'module__size_emb': [120],\n",
        "    'module__dropout': [0.3],\n",
        "    'module__linear_size': [400]\n",
        "}\n",
        "gs = GridSearchCV(ncfnet,\n",
        "                  params,\n",
        "                  verbose=50,\n",
        "                  refit=True,\n",
        "                  pre_dispatch=2,\n",
        "                  n_jobs=1,\n",
        "                  cv=5,\n",
        "                  scoring='neg_mean_squared_error')\n",
        "\n",
        "X_ds = SliceDataset(train, idx=0)\n",
        "y_ds = SliceDataset(train, idx=1)\n",
        "gs.fit(X_ds, y_ds)\n",
        "\n",
        "print(gs.best_score_, gs.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdnyJS4HuewR",
        "outputId": "e19f145a-b092-40c4-8739-f0c5d808f481"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Re-initializing module because the following parameters were re-set: dropout, interact, linear_size, movies_emb, movies_ohe, size_emb, users_emb, users_ohe, y_range.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch      f1    precision    recall    rmse_score    train_loss    valid_loss    cp      lr     dur\n",
            "-------  ------  -----------  --------  ------------  ------------  ------------  ----  ------  ------\n",
            "      1  \u001b[36m0.4265\u001b[0m       \u001b[32m0.8679\u001b[0m    \u001b[35m0.2827\u001b[0m        \u001b[31m0.9295\u001b[0m        \u001b[94m0.9991\u001b[0m        \u001b[36m0.8639\u001b[0m     +  0.0100  3.8039\n",
            "      2  \u001b[36m0.6672\u001b[0m       0.7917    \u001b[35m0.5765\u001b[0m        0.9653        \u001b[94m0.6396\u001b[0m        0.9319        0.0100  3.0519\n",
            "      3  0.6050       0.7948    0.4884        0.9748        \u001b[94m0.2639\u001b[0m        0.9502        0.0100  2.9263\n",
            "      4  0.6203       0.7937    0.5091        0.9864        \u001b[94m0.1437\u001b[0m        0.9730        0.0100  2.7757\n",
            "      5  0.6333       0.7850    0.5308        0.9986        \u001b[94m0.1035\u001b[0m        0.9971        0.0100  3.8970\n",
            "      6  0.6020       0.7855    0.4880        1.0102        \u001b[94m0.0872\u001b[0m        1.0206        0.0100  3.0896\n",
            "      7  0.6376       0.7803    0.5390        1.0107        \u001b[94m0.0814\u001b[0m        1.0215        0.0100  3.0322\n",
            "      8  0.6083       0.7838    0.4970        1.0091        \u001b[94m0.0681\u001b[0m        1.0183        0.0010  3.1826\n",
            "      9  0.6116       0.7846    0.5012        1.0098        \u001b[94m0.0507\u001b[0m        1.0198        0.0010  3.6100\n",
            "     10  0.6169       0.7830    0.5090        1.0126        \u001b[94m0.0403\u001b[0m        1.0253        0.0010  5.6917\n",
            "Stopping since valid_loss has not improved in the last 10 epochs.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<class 'skorch.net.NeuralNet'>[initialized](\n",
              "  module_=ncf(\n",
              "    (gmf_embuserid): Embedding(943, 120)\n",
              "    (gmf_embgender): Embedding(2, 120)\n",
              "    (gmf_embage): Embedding(7, 120)\n",
              "    (gmf_embocc): Embedding(21, 120)\n",
              "    (gmf_embmovieid): Embedding(1682, 461)\n",
              "    (mlp_embuserid): Embedding(943, 120)\n",
              "    (mlp_embgender): Embedding(2, 120)\n",
              "    (mlp_embage): Embedding(7, 120)\n",
              "    (mlp_embocc): Embedding(21, 120)\n",
              "    (mlp_embmovieid): Embedding(1682, 120)\n",
              "    (h1): Linear(in_features=619, out_features=400, bias=True)\n",
              "    (h2): Linear(in_features=400, out_features=200, bias=True)\n",
              "    (dropout1): Dropout(p=0.3, inplace=False)\n",
              "    (dropout2): Dropout(p=0.3, inplace=False)\n",
              "    (last_layer): Linear(in_features=680, out_features=1, bias=True)\n",
              "  ),\n",
              ")"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model = gs.best_estimator_\n",
        "best_model.fit(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4_BeanXKuCa"
      },
      "outputs": [],
      "source": [
        "#rating_predict = best_model.predict(valid_dataset)\n",
        "rating_predict = ncfnet.predict(valid_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "haXvSJPyLJyN"
      },
      "outputs": [],
      "source": [
        "valid_users = valid_dataset[:][0][0][:,0].numpy()\n",
        "valid_movie = valid_dataset[:][0][0][:,3].numpy()\n",
        "valid_rating = valid_dataset[:][1].numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-e3PKcRGVYKW"
      },
      "outputs": [],
      "source": [
        "dct= {}\n",
        "for i in range(20000):\n",
        "    if valid_users[i] not in dct.keys():\n",
        "        dct[valid_users[i]]  = [(i, valid_movie[i], rating_predict[i], valid_rating[i])]\n",
        "    else:\n",
        "        dct[valid_users[i]].append((i, valid_movie[i], rating_predict[i], valid_rating[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1056sEwJWgjp",
        "outputId": "23f552cc-68fc-488a-b3f5-da87feae0865"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9092495636998255 0.7560052037481741\n"
          ]
        }
      ],
      "source": [
        "#calculate HR@10\n",
        "from sklearn.metrics import ndcg_score\n",
        "import math\n",
        "cnt_user = 0\n",
        "sum = 0\n",
        "ndcg = 0\n",
        "for key, value in dct.items():\n",
        "    if len(value) >= 10:\n",
        "        cnt_user += 1\n",
        "        cnt_movie = 0\n",
        "        value_rank_by_pred = sorted(value, reverse = True , key=lambda x: x[2]) # sort by pred\n",
        "        value_rank_by_label = sorted(value, reverse = True , key=lambda x: x[3]) # sort by label\n",
        "        ranked_label = [[item[3] for item in value_rank_by_label]]\n",
        "        ranked_pred = [[item[3] for item in value_rank_by_pred]]\n",
        "        dcg = 0\n",
        "        idcg = 0\n",
        "        for j in range(10):\n",
        "            if value_rank_by_pred[j][3] == 5:\n",
        "                sum += 1\n",
        "                break\n",
        "        for j in range(10):\n",
        "            dcg += (2**ranked_pred[0][j]-1)/(math.log2(j+2))\n",
        "            idcg += (2**ranked_label[0][j]-1)/(math.log2(j+2))\n",
        "        ndcg += dcg/idcg\n",
        "        #ndcg += ndcg_score(ranked_label, ranked_pred, k=10)\n",
        "        #ndcg += ndcg_at_k(ranked_pred, ranked_label, 10)\n",
        "hr = sum/cnt_user\n",
        "ndcg = ndcg/cnt_user\n",
        "print(hr, ndcg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OnQcRC5Gc6y"
      },
      "outputs": [],
      "source": [
        "torch.save(best_model.module_.state_dict(), 'best_model.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeHOCM-gNgJG"
      },
      "source": [
        "### Deep and Wide"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FirOYkr9NgJG"
      },
      "source": [
        "#### Manually specify hyperparamers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59XxqCO3zPXC"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgVTuwedriTI"
      },
      "outputs": [],
      "source": [
        "deepnwidenet = NeuralNet(\n",
        "    deepnwide,\n",
        "    module__users_emb=train.users_emb,\n",
        "    module__movies_emb=train.movies_emb,\n",
        "    module__users_ohe=train.users_ohe,\n",
        "    module__movies_ohe=train.movies_ohe,\n",
        "    #### Manually specify hyperparamers e=train.movies_ohe,\n",
        "    module__interact=train.interact,\n",
        "    module__size_emb=120,\n",
        "    module__y_range=train.y_range,\n",
        "    module__dropout=0.2,\n",
        "    max_epochs=30,\n",
        "    lr=0.01,\n",
        "    optimizer=torch.optim.Adam,\n",
        "    criterion=torch.nn.MSELoss,\n",
        "    device=device,\n",
        "    iterator_train__batch_size=1024,\n",
        "    iterator_train__num_workers=0,\n",
        "    iterator_train__shuffle=True,\n",
        "    iterator_valid__batch_size=4096,\n",
        "    train_split=predefined_split(valid_dataset),\n",
        "    callbacks=[\n",
        "               earlystopping,\n",
        "               epoch_rmse,\n",
        "               epoch_precision,\n",
        "               epoch_recall,\n",
        "               epoch_f1,\n",
        "               #checkpoint,\n",
        "               lr_scheduler,\n",
        "               #TensorBoard(writer),\n",
        "               #progressbar\n",
        "               ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "e6qm5_snshUi",
        "outputId": "5f8445aa-4fc1-41d2-f462-0a9f2ed50895"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch      f1    precision    recall    rmse_score    train_loss    valid_loss      lr     dur\n",
            "-------  ------  -----------  --------  ------------  ------------  ------------  ------  ------\n",
            "      1  \u001b[36m0.4080\u001b[0m       \u001b[32m0.8612\u001b[0m    \u001b[35m0.2673\u001b[0m        \u001b[31m0.9489\u001b[0m        \u001b[94m0.9904\u001b[0m        \u001b[36m0.9005\u001b[0m  0.0100  2.9244\n",
            "      2  0.3391       \u001b[32m0.8828\u001b[0m    0.2099        \u001b[31m0.9444\u001b[0m        \u001b[94m0.8754\u001b[0m        \u001b[36m0.8919\u001b[0m  0.0100  2.7907\n",
            "      3  \u001b[36m0.5046\u001b[0m       0.8392    \u001b[35m0.3608\u001b[0m        \u001b[31m0.9349\u001b[0m        \u001b[94m0.8563\u001b[0m        \u001b[36m0.8741\u001b[0m  0.0100  3.0387\n",
            "      4  \u001b[36m0.5105\u001b[0m       0.8395    \u001b[35m0.3668\u001b[0m        0.9383        \u001b[94m0.8406\u001b[0m        0.8804  0.0100  3.3135\n",
            "      5  0.4705       0.8484    0.3255        \u001b[31m0.9342\u001b[0m        \u001b[94m0.8244\u001b[0m        \u001b[36m0.8728\u001b[0m  0.0100  3.2297\n",
            "      6  0.5033       0.8464    0.3582        \u001b[31m0.9335\u001b[0m        \u001b[94m0.8125\u001b[0m        \u001b[36m0.8713\u001b[0m  0.0100  2.9621\n",
            "      7  \u001b[36m0.5712\u001b[0m       0.8295    \u001b[35m0.4356\u001b[0m        0.9467        \u001b[94m0.7965\u001b[0m        0.8962  0.0100  3.4203\n",
            "      8  0.5513       0.8404    0.4102        \u001b[31m0.9275\u001b[0m        \u001b[94m0.7385\u001b[0m        \u001b[36m0.8602\u001b[0m  0.0010  3.8236\n",
            "      9  0.5654       0.8372    0.4268        0.9277        \u001b[94m0.7188\u001b[0m        0.8606  0.0010  2.7665\n",
            "     10  0.5639       0.8343    0.4259        0.9312        \u001b[94m0.7089\u001b[0m        0.8671  0.0010  3.3486\n",
            "     11  0.5320       0.8448    0.3883        0.9279        \u001b[94m0.7007\u001b[0m        0.8611  0.0010  3.3056\n",
            "     12  0.5647       0.8338    0.4269        0.9307        \u001b[94m0.6941\u001b[0m        0.8661  0.0010  3.6710\n",
            "     13  0.5503       0.8364    0.4101        0.9315        \u001b[94m0.6879\u001b[0m        0.8676  0.0010  2.7714\n",
            "     14  0.5450       0.8390    0.4036        0.9320        \u001b[94m0.6807\u001b[0m        0.8687  0.0010  3.0047\n",
            "     15  0.5661       0.8348    0.4283        0.9354        \u001b[94m0.6667\u001b[0m        0.8750  0.0001  2.7722\n",
            "     16  0.5647       0.8345    0.4268        0.9354        \u001b[94m0.6648\u001b[0m        0.8749  0.0001  3.5987\n",
            "     17  0.5631       0.8349    0.4248        0.9353        0.6651        0.8748  0.0001  3.0202\n",
            "Stopping since valid_loss has not improved in the last 10 epochs.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<class 'skorch.net.NeuralNet'>[initialized](\n",
              "  module_=deepnwide(\n",
              "    (emb_UserID): Embedding(943, 120)\n",
              "    (emb_Gender): Embedding(2, 120)\n",
              "    (emb_Age): Embedding(7, 120)\n",
              "    (emb_Occupation): Embedding(21, 120)\n",
              "    (emb_MovieID): Embedding(1682, 120)\n",
              "    (h1): Linear(in_features=600, out_features=500, bias=True)\n",
              "    (h2): Linear(in_features=500, out_features=500, bias=True)\n",
              "    (h3): Linear(in_features=500, out_features=500, bias=True)\n",
              "    (dropout1): Dropout(p=0.2, inplace=False)\n",
              "    (dropout2): Dropout(p=0.2, inplace=False)\n",
              "    (dropout3): Dropout(p=0.2, inplace=False)\n",
              "    (last_layer): Linear(in_features=845, out_features=1, bias=True)\n",
              "  ),\n",
              ")"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "deepnwidenet.fit(train_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9pokwLlNgJH"
      },
      "source": [
        "#### GridsearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4Ecaxc4euD1",
        "outputId": "e280dfd8-fde9-47c2-eb0e-5520a970aa58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
            "[CV 1/3; 1/6] START lr=0.01, module__dropout=0.3, module__linear_size=500, module__size_emb=60\n",
            "  epoch      f1    precision    recall    rmse_score    train_loss    valid_loss      lr     dur\n",
            "-------  ------  -----------  --------  ------------  ------------  ------------  ------  ------\n",
            "      1  \u001b[36m0.3490\u001b[0m       \u001b[32m0.8462\u001b[0m    \u001b[35m0.2198\u001b[0m        \u001b[31m0.9818\u001b[0m        \u001b[94m1.0217\u001b[0m        \u001b[36m0.9640\u001b[0m  0.0100  5.5711\n",
            "      2  \u001b[36m0.5170\u001b[0m       0.8149    \u001b[35m0.3786\u001b[0m        \u001b[31m0.9667\u001b[0m        \u001b[94m0.8876\u001b[0m        \u001b[36m0.9345\u001b[0m  0.0100  4.9588\n",
            "      3  0.3983       0.8361    0.2614        \u001b[31m0.9621\u001b[0m        \u001b[94m0.8652\u001b[0m        \u001b[36m0.9257\u001b[0m  0.0100  4.4296\n",
            "      4  0.3291       \u001b[32m0.8498\u001b[0m    0.2041        0.9646        \u001b[94m0.8502\u001b[0m        0.9305  0.0100  3.9035\n",
            "      5  0.3477       0.8433    0.2190        0.9743        \u001b[94m0.8441\u001b[0m        0.9492  0.0100  3.7193\n",
            "      6  0.4528       0.8334    0.3108        \u001b[31m0.9453\u001b[0m        \u001b[94m0.8312\u001b[0m        \u001b[36m0.8935\u001b[0m  0.0100  3.9781\n",
            "      7  0.3009       \u001b[32m0.8653\u001b[0m    0.1821        0.9542        \u001b[94m0.8180\u001b[0m        0.9105  0.0100  4.1843\n",
            "      8  0.4483       0.8426    0.3054        \u001b[31m0.9345\u001b[0m        \u001b[94m0.7665\u001b[0m        \u001b[36m0.8732\u001b[0m  0.0010  3.7053\n",
            "      9  0.4354       0.8467    0.2930        \u001b[31m0.9308\u001b[0m        \u001b[94m0.7480\u001b[0m        \u001b[36m0.8664\u001b[0m  0.0010  3.8612\n",
            "     10  0.4835       0.8358    0.3401        \u001b[31m0.9270\u001b[0m        \u001b[94m0.7384\u001b[0m        \u001b[36m0.8593\u001b[0m  0.0010  4.3813\n",
            "     11  0.4743       0.8409    0.3303        \u001b[31m0.9228\u001b[0m        \u001b[94m0.7317\u001b[0m        \u001b[36m0.8516\u001b[0m  0.0010  3.6186\n",
            "     12  0.4694       0.8421    0.3254        \u001b[31m0.9214\u001b[0m        \u001b[94m0.7238\u001b[0m        \u001b[36m0.8490\u001b[0m  0.0010  3.7557\n",
            "     13  0.4609       0.8459    0.3167        \u001b[31m0.9191\u001b[0m        \u001b[94m0.7152\u001b[0m        \u001b[36m0.8448\u001b[0m  0.0010  4.3567\n",
            "     14  0.4761       0.8452    0.3313        \u001b[31m0.9157\u001b[0m        \u001b[94m0.7105\u001b[0m        \u001b[36m0.8385\u001b[0m  0.0010  3.7212\n",
            "     15  0.4876       0.8443    0.3428        \u001b[31m0.9147\u001b[0m        \u001b[94m0.6989\u001b[0m        \u001b[36m0.8366\u001b[0m  0.0001  3.8481\n",
            "     16  0.4791       0.8456    0.3342        \u001b[31m0.9146\u001b[0m        \u001b[94m0.6980\u001b[0m        \u001b[36m0.8365\u001b[0m  0.0001  4.6430\n",
            "     17  0.4832       0.8443    0.3384        \u001b[31m0.9142\u001b[0m        \u001b[94m0.6973\u001b[0m        \u001b[36m0.8357\u001b[0m  0.0001  3.7579\n",
            "     18  0.4855       0.8442    0.3407        \u001b[31m0.9137\u001b[0m        \u001b[94m0.6943\u001b[0m        \u001b[36m0.8349\u001b[0m  0.0001  3.8421\n",
            "     19  0.4870       0.8446    0.3421        \u001b[31m0.9133\u001b[0m        0.6951        \u001b[36m0.8341\u001b[0m  0.0001  4.4792\n",
            "     20  0.4788       0.8466    0.3338        \u001b[31m0.9132\u001b[0m        0.6946        \u001b[36m0.8339\u001b[0m  0.0001  3.3364\n",
            "     21  0.4871       0.8448    0.3422        \u001b[31m0.9129\u001b[0m        \u001b[94m0.6940\u001b[0m        \u001b[36m0.8333\u001b[0m  0.0001  3.8414\n",
            "     22  0.4859       0.8453    0.3410        \u001b[31m0.9128\u001b[0m        \u001b[94m0.6930\u001b[0m        \u001b[36m0.8333\u001b[0m  0.0000  4.1874\n",
            "     23  0.4859       0.8458    0.3409        \u001b[31m0.9128\u001b[0m        \u001b[94m0.6913\u001b[0m        \u001b[36m0.8332\u001b[0m  0.0000  3.9909\n",
            "     24  0.4868       0.8453    0.3419        \u001b[31m0.9127\u001b[0m        \u001b[94m0.6901\u001b[0m        \u001b[36m0.8331\u001b[0m  0.0000  3.9688\n",
            "     25  0.4852       0.8461    0.3401        \u001b[31m0.9127\u001b[0m        0.6918        \u001b[36m0.8330\u001b[0m  0.0000  4.2241\n",
            "     26  0.4852       0.8461    0.3401        \u001b[31m0.9127\u001b[0m        0.6917        \u001b[36m0.8329\u001b[0m  0.0000  4.0518\n",
            "     27  0.4851       0.8457    0.3401        \u001b[31m0.9126\u001b[0m        0.6908        \u001b[36m0.8329\u001b[0m  0.0000  3.7227\n",
            "     28  0.4855       0.8459    0.3404        \u001b[31m0.9126\u001b[0m        \u001b[94m0.6896\u001b[0m        \u001b[36m0.8328\u001b[0m  0.0000  3.7452\n",
            "     29  0.4857       0.8459    0.3406        \u001b[31m0.9126\u001b[0m        0.6911        \u001b[36m0.8328\u001b[0m  0.0000  4.4013\n",
            "     30  0.4858       0.8460    0.3407        \u001b[31m0.9125\u001b[0m        0.6905        \u001b[36m0.8327\u001b[0m  0.0000  3.5002\n",
            "[CV 1/3; 1/6] END lr=0.01, module__dropout=0.3, module__linear_size=500, module__size_emb=60;, score=-1.170 total time= 2.1min\n",
            "[CV 2/3; 1/6] START lr=0.01, module__dropout=0.3, module__linear_size=500, module__size_emb=60\n",
            "  epoch      f1    precision    recall    rmse_score    train_loss    valid_loss      lr     dur\n",
            "-------  ------  -----------  --------  ------------  ------------  ------------  ------  ------\n",
            "      1  \u001b[36m0.2333\u001b[0m       \u001b[32m0.8872\u001b[0m    \u001b[35m0.1343\u001b[0m        \u001b[31m0.9637\u001b[0m        \u001b[94m1.0319\u001b[0m        \u001b[36m0.9287\u001b[0m  0.0100  4.1437\n",
            "      2  \u001b[36m0.5712\u001b[0m       0.8148    \u001b[35m0.4397\u001b[0m        \u001b[31m0.9321\u001b[0m        \u001b[94m0.8847\u001b[0m        \u001b[36m0.8688\u001b[0m  0.0100  3.8994\n",
            "      3  0.5325       0.8285    0.3923        \u001b[31m0.9306\u001b[0m        \u001b[94m0.8614\u001b[0m        \u001b[36m0.8660\u001b[0m  0.0100  3.6972\n",
            "      4  0.5667       0.8241    0.4319        \u001b[31m0.9218\u001b[0m        \u001b[94m0.8464\u001b[0m        \u001b[36m0.8497\u001b[0m  0.0100  3.8102\n",
            "      5  0.5030       0.8516    0.3569        \u001b[31m0.9119\u001b[0m        \u001b[94m0.8278\u001b[0m        \u001b[36m0.8315\u001b[0m  0.0100  4.3724\n",
            "      6  0.5179       0.8521    0.3720        \u001b[31m0.9067\u001b[0m        \u001b[94m0.8076\u001b[0m        \u001b[36m0.8221\u001b[0m  0.0100  4.5970\n",
            "      7  0.4669       0.8710    0.3189        \u001b[31m0.8965\u001b[0m        \u001b[94m0.7897\u001b[0m        \u001b[36m0.8037\u001b[0m  0.0100  4.1653\n",
            "      8  0.5185       0.8647    0.3703        \u001b[31m0.8854\u001b[0m        \u001b[94m0.7278\u001b[0m        \u001b[36m0.7839\u001b[0m  0.0010  4.1931\n",
            "      9  0.5344       0.8634    0.3869        \u001b[31m0.8827\u001b[0m        \u001b[94m0.7129\u001b[0m        \u001b[36m0.7792\u001b[0m  0.0010  3.8166\n",
            "     10  0.5293       0.8660    0.3811        \u001b[31m0.8793\u001b[0m        \u001b[94m0.7024\u001b[0m        \u001b[36m0.7732\u001b[0m  0.0010  3.5493\n",
            "     11  0.5170       0.8702    0.3678        0.8812        \u001b[94m0.6951\u001b[0m        0.7765  0.0010  4.6032\n",
            "     12  0.5274       0.8655    0.3793        \u001b[31m0.8760\u001b[0m        \u001b[94m0.6902\u001b[0m        \u001b[36m0.7674\u001b[0m  0.0010  3.7142\n",
            "     13  0.5308       0.8655    0.3827        \u001b[31m0.8740\u001b[0m        \u001b[94m0.6828\u001b[0m        \u001b[36m0.7639\u001b[0m  0.0010  3.6307\n",
            "     14  0.5330       0.8645    0.3853        \u001b[31m0.8719\u001b[0m        \u001b[94m0.6773\u001b[0m        \u001b[36m0.7603\u001b[0m  0.0010  4.5133\n",
            "     15  0.5395       0.8638    0.3923        \u001b[31m0.8712\u001b[0m        \u001b[94m0.6667\u001b[0m        \u001b[36m0.7590\u001b[0m  0.0001  3.6773\n",
            "     16  0.5404       0.8639    0.3932        \u001b[31m0.8709\u001b[0m        \u001b[94m0.6654\u001b[0m        \u001b[36m0.7584\u001b[0m  0.0001  3.7530\n",
            "     17  0.5440       0.8641    0.3969        \u001b[31m0.8705\u001b[0m        0.6671        \u001b[36m0.7578\u001b[0m  0.0001  4.5225\n",
            "     18  0.5413       0.8650    0.3939        \u001b[31m0.8702\u001b[0m        \u001b[94m0.6639\u001b[0m        \u001b[36m0.7573\u001b[0m  0.0001  3.6962\n",
            "     19  0.5399       0.8660    0.3922        0.8702        0.6643        0.7573  0.0001  3.6854\n",
            "     20  0.5384       0.8662    0.3906        \u001b[31m0.8700\u001b[0m        \u001b[94m0.6635\u001b[0m        \u001b[36m0.7569\u001b[0m  0.0001  3.9239\n",
            "     21  0.5392       0.8670    0.3913        \u001b[31m0.8698\u001b[0m        \u001b[94m0.6621\u001b[0m        \u001b[36m0.7565\u001b[0m  0.0001  4.0334\n",
            "     22  0.5394       0.8664    0.3916        \u001b[31m0.8698\u001b[0m        \u001b[94m0.6606\u001b[0m        \u001b[36m0.7565\u001b[0m  0.0000  3.7638\n",
            "     23  0.5396       0.8664    0.3918        \u001b[31m0.8697\u001b[0m        0.6615        \u001b[36m0.7565\u001b[0m  0.0000  4.3185\n",
            "     24  0.5413       0.8660    0.3937        \u001b[31m0.8697\u001b[0m        \u001b[94m0.6605\u001b[0m        \u001b[36m0.7564\u001b[0m  0.0000  4.0900\n",
            "     25  0.5420       0.8657    0.3945        0.8697        \u001b[94m0.6603\u001b[0m        0.7564  0.0000  3.6828\n",
            "     26  0.5420       0.8660    0.3945        \u001b[31m0.8697\u001b[0m        \u001b[94m0.6602\u001b[0m        \u001b[36m0.7563\u001b[0m  0.0000  3.7574\n",
            "     27  0.5424       0.8661    0.3948        \u001b[31m0.8697\u001b[0m        0.6603        \u001b[36m0.7563\u001b[0m  0.0000  4.4770\n",
            "     28  0.5415       0.8662    0.3939        \u001b[31m0.8696\u001b[0m        0.6604        \u001b[36m0.7563\u001b[0m  0.0000  3.6987\n",
            "     29  0.5418       0.8661    0.3942        \u001b[31m0.8696\u001b[0m        0.6604        \u001b[36m0.7562\u001b[0m  0.0000  3.6426\n",
            "Stopping since valid_loss has not improved in the last 10 epochs.\n",
            "[CV 2/3; 1/6] END lr=0.01, module__dropout=0.3, module__linear_size=500, module__size_emb=60;, score=-1.035 total time= 2.0min\n",
            "[CV 3/3; 1/6] START lr=0.01, module__dropout=0.3, module__linear_size=500, module__size_emb=60\n",
            "  epoch      f1    precision    recall    rmse_score    train_loss    valid_loss      lr     dur\n",
            "-------  ------  -----------  --------  ------------  ------------  ------------  ------  ------\n",
            "      1  \u001b[36m0.5455\u001b[0m       \u001b[32m0.8171\u001b[0m    \u001b[35m0.4094\u001b[0m        \u001b[31m0.9516\u001b[0m        \u001b[94m1.0046\u001b[0m        \u001b[36m0.9056\u001b[0m  0.0100  3.6777\n",
            "      2  0.4306       \u001b[32m0.8564\u001b[0m    0.2876        \u001b[31m0.9450\u001b[0m        \u001b[94m0.8690\u001b[0m        \u001b[36m0.8930\u001b[0m  0.0100  3.8268\n",
            "      3  0.4871       0.8484    0.3416        \u001b[31m0.9334\u001b[0m        \u001b[94m0.8475\u001b[0m        \u001b[36m0.8713\u001b[0m  0.0100  4.3969\n",
            "      4  0.4745       0.8488    0.3293        \u001b[31m0.9282\u001b[0m        \u001b[94m0.8277\u001b[0m        \u001b[36m0.8616\u001b[0m  0.0100  3.7978\n",
            "      5  0.3189       \u001b[32m0.8926\u001b[0m    0.1941        0.9381        \u001b[94m0.8072\u001b[0m        0.8801  0.0100  3.7525\n",
            "      6  \u001b[36m0.5855\u001b[0m       0.8291    \u001b[35m0.4525\u001b[0m        \u001b[31m0.9205\u001b[0m        \u001b[94m0.7970\u001b[0m        \u001b[36m0.8473\u001b[0m  0.0100  4.6464\n",
            "      7  0.4807       0.8632    0.3331        \u001b[31m0.9118\u001b[0m        \u001b[94m0.7806\u001b[0m        \u001b[36m0.8314\u001b[0m  0.0100  3.8000\n",
            "      8  0.4733       0.8752    0.3243        \u001b[31m0.9071\u001b[0m        \u001b[94m0.7239\u001b[0m        \u001b[36m0.8228\u001b[0m  0.0010  3.4344\n",
            "      9  0.4651       0.8771    0.3164        \u001b[31m0.9021\u001b[0m        \u001b[94m0.7065\u001b[0m        \u001b[36m0.8137\u001b[0m  0.0010  4.4741\n",
            "     10  0.5216       0.8632    0.3738        \u001b[31m0.9003\u001b[0m        \u001b[94m0.6932\u001b[0m        \u001b[36m0.8105\u001b[0m  0.0010  3.8006\n",
            "     11  0.4982       0.8704    0.3490        \u001b[31m0.8976\u001b[0m        \u001b[94m0.6894\u001b[0m        \u001b[36m0.8056\u001b[0m  0.0010  3.7201\n",
            "     12  0.4919       0.8717    0.3426        \u001b[31m0.8956\u001b[0m        \u001b[94m0.6818\u001b[0m        \u001b[36m0.8021\u001b[0m  0.0010  4.5628\n",
            "     13  0.5055       0.8698    0.3563        \u001b[31m0.8950\u001b[0m        \u001b[94m0.6762\u001b[0m        \u001b[36m0.8011\u001b[0m  0.0010  3.8507\n",
            "     14  0.4813       0.8799    0.3312        \u001b[31m0.8931\u001b[0m        \u001b[94m0.6693\u001b[0m        \u001b[36m0.7976\u001b[0m  0.0010  3.7893\n",
            "     15  0.5055       0.8719    0.3559        \u001b[31m0.8927\u001b[0m        \u001b[94m0.6604\u001b[0m        \u001b[36m0.7970\u001b[0m  0.0001  4.2089\n",
            "     16  0.5094       0.8712    0.3599        \u001b[31m0.8922\u001b[0m        \u001b[94m0.6590\u001b[0m        \u001b[36m0.7960\u001b[0m  0.0001  3.7960\n",
            "     17  0.5021       0.8740    0.3522        \u001b[31m0.8920\u001b[0m        \u001b[94m0.6581\u001b[0m        \u001b[36m0.7956\u001b[0m  0.0001  3.7301\n",
            "     18  0.5087       0.8706    0.3593        \u001b[31m0.8914\u001b[0m        \u001b[94m0.6578\u001b[0m        \u001b[36m0.7945\u001b[0m  0.0001  4.0632\n",
            "     19  0.5025       0.8734    0.3527        0.8914        \u001b[94m0.6575\u001b[0m        0.7946  0.0001  4.1317\n",
            "     20  0.4960       0.8747    0.3461        0.8918        \u001b[94m0.6555\u001b[0m        0.7953  0.0001  3.7363\n",
            "     21  0.5042       0.8739    0.3543        0.8917        \u001b[94m0.6540\u001b[0m        0.7951  0.0001  4.0130\n",
            "     22  0.5035       0.8737    0.3537        0.8917        \u001b[94m0.6526\u001b[0m        0.7951  0.0000  4.3419\n",
            "     23  0.5040       0.8738    0.3541        0.8915        0.6533        0.7948  0.0000  3.7183\n",
            "     24  0.5044       0.8739    0.3545        0.8914        0.6538        0.7946  0.0000  3.6950\n",
            "     25  0.5045       0.8740    0.3546        \u001b[31m0.8913\u001b[0m        0.6530        \u001b[36m0.7943\u001b[0m  0.0000  4.6109\n",
            "     26  0.5045       0.8740    0.3546        \u001b[31m0.8911\u001b[0m        0.6530        \u001b[36m0.7941\u001b[0m  0.0000  3.6974\n",
            "     27  0.5047       0.8737    0.3549        \u001b[31m0.8910\u001b[0m        0.6533        \u001b[36m0.7939\u001b[0m  0.0000  3.4259\n",
            "Stopping since valid_loss has not improved in the last 10 epochs.\n",
            "[CV 3/3; 1/6] END lr=0.01, module__dropout=0.3, module__linear_size=500, module__size_emb=60;, score=-1.140 total time= 1.9min\n",
            "[CV 1/3; 2/6] START lr=0.01, module__dropout=0.3, module__linear_size=500, module__size_emb=120\n",
            "  epoch      f1    precision    recall    rmse_score    train_loss    valid_loss      lr     dur\n",
            "-------  ------  -----------  --------  ------------  ------------  ------------  ------  ------\n",
            "      1  \u001b[36m0.4114\u001b[0m       \u001b[32m0.8405\u001b[0m    \u001b[35m0.2724\u001b[0m        \u001b[31m0.9818\u001b[0m        \u001b[94m0.9976\u001b[0m        \u001b[36m0.9640\u001b[0m  0.0100  3.7018\n",
            "      2  0.3721       \u001b[32m0.8502\u001b[0m    0.2381        \u001b[31m0.9725\u001b[0m        \u001b[94m0.8859\u001b[0m        \u001b[36m0.9457\u001b[0m  0.0100  3.8682\n",
            "      3  \u001b[36m0.4853\u001b[0m       0.8267    \u001b[35m0.3435\u001b[0m        \u001b[31m0.9610\u001b[0m        \u001b[94m0.8666\u001b[0m        \u001b[36m0.9236\u001b[0m  0.0100  4.5127\n",
            "      4  \u001b[36m0.5617\u001b[0m       0.8022    \u001b[35m0.4322\u001b[0m        0.9612        \u001b[94m0.8569\u001b[0m        0.9240  0.0100  3.7747\n",
            "      5  0.4597       0.8303    0.3178        \u001b[31m0.9536\u001b[0m        \u001b[94m0.8450\u001b[0m        \u001b[36m0.9094\u001b[0m  0.0100  3.7458\n",
            "      6  \u001b[36m0.5738\u001b[0m       0.8016    \u001b[35m0.4469\u001b[0m        0.9607        \u001b[94m0.8384\u001b[0m        0.9229  0.0100  4.5822\n",
            "      7  0.5104       0.8133    0.3719        0.9545        \u001b[94m0.8302\u001b[0m        0.9110  0.0100  3.8423\n",
            "      8  0.5108       0.8295    0.3690        \u001b[31m0.9379\u001b[0m        \u001b[94m0.7797\u001b[0m        \u001b[36m0.8797\u001b[0m  0.0010  3.7518\n",
            "      9  0.4908       0.8359    0.3474        \u001b[31m0.9354\u001b[0m        \u001b[94m0.7615\u001b[0m        \u001b[36m0.8751\u001b[0m  0.0010  4.6955\n",
            "     10  0.5021       0.8345    0.3590        \u001b[31m0.9324\u001b[0m        \u001b[94m0.7527\u001b[0m        \u001b[36m0.8694\u001b[0m  0.0010  3.8536\n",
            "     11  0.5314       0.8303    0.3907        \u001b[31m0.9295\u001b[0m        \u001b[94m0.7426\u001b[0m        \u001b[36m0.8640\u001b[0m  0.0010  4.7849\n",
            "     12  0.5004       0.8407    0.3562        \u001b[31m0.9260\u001b[0m        \u001b[94m0.7364\u001b[0m        \u001b[36m0.8575\u001b[0m  0.0010  5.7464\n",
            "     13  0.5173       0.8357    0.3746        \u001b[31m0.9254\u001b[0m        \u001b[94m0.7298\u001b[0m        \u001b[36m0.8564\u001b[0m  0.0010  3.9689\n",
            "     14  0.5007       0.8430    0.3561        \u001b[31m0.9213\u001b[0m        \u001b[94m0.7226\u001b[0m        \u001b[36m0.8488\u001b[0m  0.0010  4.1456\n",
            "     15  0.5186       0.8382    0.3755        \u001b[31m0.9209\u001b[0m        \u001b[94m0.7137\u001b[0m        \u001b[36m0.8481\u001b[0m  0.0001  4.9694\n",
            "     16  0.5244       0.8385    0.3815        \u001b[31m0.9205\u001b[0m        \u001b[94m0.7116\u001b[0m        \u001b[36m0.8474\u001b[0m  0.0001  4.1381\n",
            "     17  0.5238       0.8380    0.3809        \u001b[31m0.9203\u001b[0m        \u001b[94m0.7077\u001b[0m        \u001b[36m0.8469\u001b[0m  0.0001  3.8221\n",
            "     18  0.5217       0.8385    0.3787        \u001b[31m0.9199\u001b[0m        0.7101        \u001b[36m0.8462\u001b[0m  0.0001  4.7762\n",
            "     19  0.5258       0.8384    0.3830        \u001b[31m0.9198\u001b[0m        0.7080        \u001b[36m0.8460\u001b[0m  0.0001  3.7859\n",
            "     20  0.5269       0.8383    0.3842        \u001b[31m0.9194\u001b[0m        \u001b[94m0.7061\u001b[0m        \u001b[36m0.8454\u001b[0m  0.0001  3.5042\n",
            "     21  0.5243       0.8391    0.3813        \u001b[31m0.9193\u001b[0m        0.7080        \u001b[36m0.8450\u001b[0m  0.0001  4.6905\n",
            "     22  0.5237       0.8392    0.3806        \u001b[31m0.9192\u001b[0m        \u001b[94m0.7044\u001b[0m        \u001b[36m0.8449\u001b[0m  0.0000  3.8088\n",
            "     23  0.5233       0.8392    0.3802        \u001b[31m0.9192\u001b[0m        0.7045        \u001b[36m0.8449\u001b[0m  0.0000  3.7814\n",
            "     24  0.5246       0.8390    0.3816        \u001b[31m0.9191\u001b[0m        \u001b[94m0.7034\u001b[0m        \u001b[36m0.8448\u001b[0m  0.0000  4.6794\n",
            "     25  0.5235       0.8394    0.3804        \u001b[31m0.9191\u001b[0m        0.7051        \u001b[36m0.8448\u001b[0m  0.0000  3.8648\n",
            "     26  0.5231       0.8393    0.3799        \u001b[31m0.9191\u001b[0m        0.7049        \u001b[36m0.8447\u001b[0m  0.0000  3.6247\n",
            "     27  0.5241       0.8386    0.3812        \u001b[31m0.9190\u001b[0m        0.7044        \u001b[36m0.8446\u001b[0m  0.0000  4.5721\n",
            "     28  0.5241       0.8386    0.3812        0.9190        0.7045        0.8446  0.0000  3.6818\n",
            "     29  0.5240       0.8388    0.3810        \u001b[31m0.9190\u001b[0m        \u001b[94m0.7031\u001b[0m        \u001b[36m0.8446\u001b[0m  0.0000  3.7883\n",
            "Stopping since valid_loss has not improved in the last 10 epochs.\n",
            "[CV 1/3; 2/6] END lr=0.01, module__dropout=0.3, module__linear_size=500, module__size_emb=120;, score=-1.181 total time= 2.1min\n",
            "[CV 2/3; 2/6] START lr=0.01, module__dropout=0.3, module__linear_size=500, module__size_emb=120\n",
            "  epoch      f1    precision    recall    rmse_score    train_loss    valid_loss      lr     dur\n",
            "-------  ------  -----------  --------  ------------  ------------  ------------  ------  ------\n",
            "      1  \u001b[36m0.2210\u001b[0m       \u001b[32m0.8771\u001b[0m    \u001b[35m0.1264\u001b[0m        \u001b[31m0.9690\u001b[0m        \u001b[94m1.0218\u001b[0m        \u001b[36m0.9389\u001b[0m  0.0100  3.7336\n",
            "      2  0.2055       \u001b[32m0.8962\u001b[0m    0.1161        \u001b[31m0.9596\u001b[0m        \u001b[94m0.8880\u001b[0m        \u001b[36m0.9208\u001b[0m  0.0100  3.6934\n",
            "      3  \u001b[36m0.4908\u001b[0m       0.8379    \u001b[35m0.3470\u001b[0m        \u001b[31m0.9457\u001b[0m        \u001b[94m0.8678\u001b[0m        \u001b[36m0.8943\u001b[0m  0.0100  4.5590\n",
            "      4  0.2319       \u001b[32m0.9065\u001b[0m    0.1330        0.9493        \u001b[94m0.8520\u001b[0m        0.9011  0.0100  3.8051\n",
            "      5  0.4612       0.8595    0.3152        \u001b[31m0.9149\u001b[0m        \u001b[94m0.8372\u001b[0m        \u001b[36m0.8371\u001b[0m  0.0100  3.7678\n",
            "      6  \u001b[36m0.5014\u001b[0m       0.8561    \u001b[35m0.3545\u001b[0m        0.9228        \u001b[94m0.8223\u001b[0m        0.8515  0.0100  4.3840\n",
            "      7  \u001b[36m0.5402\u001b[0m       0.8398    \u001b[35m0.3982\u001b[0m        \u001b[31m0.9042\u001b[0m        \u001b[94m0.8102\u001b[0m        \u001b[36m0.8176\u001b[0m  0.0100  3.7849\n",
            "      8  0.5011       0.8569    0.3540        \u001b[31m0.8947\u001b[0m        \u001b[94m0.7517\u001b[0m        \u001b[36m0.8005\u001b[0m  0.0010  3.7210\n",
            "      9  0.5076       0.8587    0.3603        \u001b[31m0.8896\u001b[0m        \u001b[94m0.7311\u001b[0m        \u001b[36m0.7913\u001b[0m  0.0010  4.3957\n",
            "     10  0.4883       0.8643    0.3402        \u001b[31m0.8873\u001b[0m        \u001b[94m0.7213\u001b[0m        \u001b[36m0.7873\u001b[0m  0.0010  3.8183\n",
            "     11  0.5116       0.8608    0.3639        \u001b[31m0.8834\u001b[0m        \u001b[94m0.7118\u001b[0m        \u001b[36m0.7804\u001b[0m  0.0010  3.6934\n",
            "     12  0.5162       0.8624    0.3683        \u001b[31m0.8817\u001b[0m        \u001b[94m0.7060\u001b[0m        \u001b[36m0.7774\u001b[0m  0.0010  4.1184\n",
            "     13  0.5264       0.8601    0.3793        \u001b[31m0.8804\u001b[0m        \u001b[94m0.7002\u001b[0m        \u001b[36m0.7751\u001b[0m  0.0010  4.2044\n",
            "     14  0.4879       0.8694    0.3391        \u001b[31m0.8793\u001b[0m        \u001b[94m0.6913\u001b[0m        \u001b[36m0.7732\u001b[0m  0.0010  3.6668\n",
            "     15  0.5191       0.8635    0.3711        \u001b[31m0.8770\u001b[0m        \u001b[94m0.6800\u001b[0m        \u001b[36m0.7692\u001b[0m  0.0001  3.7403\n",
            "     16  0.5144       0.8634    0.3663        \u001b[31m0.8769\u001b[0m        0.6800        \u001b[36m0.7690\u001b[0m  0.0001  4.2143\n",
            "     17  0.5146       0.8640    0.3664        \u001b[31m0.8763\u001b[0m        \u001b[94m0.6778\u001b[0m        \u001b[36m0.7680\u001b[0m  0.0001  3.7474\n",
            "     18  0.5081       0.8657    0.3596        \u001b[31m0.8760\u001b[0m        \u001b[94m0.6768\u001b[0m        \u001b[36m0.7674\u001b[0m  0.0001  3.6774\n",
            "     19  0.5180       0.8630    0.3700        \u001b[31m0.8756\u001b[0m        0.6769        \u001b[36m0.7666\u001b[0m  0.0001  4.5041\n",
            "     20  0.5101       0.8653    0.3617        \u001b[31m0.8755\u001b[0m        0.6775        \u001b[36m0.7666\u001b[0m  0.0001  3.5890\n",
            "     21  0.5134       0.8649    0.3650        \u001b[31m0.8752\u001b[0m        \u001b[94m0.6751\u001b[0m        \u001b[36m0.7659\u001b[0m  0.0001  3.6345\n",
            "     22  0.5146       0.8638    0.3665        \u001b[31m0.8751\u001b[0m        \u001b[94m0.6741\u001b[0m        \u001b[36m0.7657\u001b[0m  0.0000  4.6661\n",
            "     23  0.5155       0.8634    0.3675        \u001b[31m0.8750\u001b[0m        \u001b[94m0.6726\u001b[0m        \u001b[36m0.7656\u001b[0m  0.0000  3.3777\n",
            "     24  0.5161       0.8634    0.3680        \u001b[31m0.8749\u001b[0m        0.6748        \u001b[36m0.7655\u001b[0m  0.0000  3.7144\n",
            "     25  0.5162       0.8633    0.3682        \u001b[31m0.8749\u001b[0m        0.6731        \u001b[36m0.7655\u001b[0m  0.0000  4.2004\n",
            "     26  0.5163       0.8633    0.3683        \u001b[31m0.8749\u001b[0m        0.6742        \u001b[36m0.7654\u001b[0m  0.0000  4.0759\n",
            "     27  0.5175       0.8633    0.3695        \u001b[31m0.8748\u001b[0m        \u001b[94m0.6723\u001b[0m        \u001b[36m0.7653\u001b[0m  0.0000  3.6300\n",
            "     28  0.5181       0.8635    0.3700        \u001b[31m0.8748\u001b[0m        0.6738        \u001b[36m0.7652\u001b[0m  0.0000  3.8678\n",
            "     29  0.5180       0.8637    0.3699        \u001b[31m0.8748\u001b[0m        0.6739        \u001b[36m0.7652\u001b[0m  0.0000  4.3797\n",
            "     30  0.5180       0.8637    0.3699        \u001b[31m0.8748\u001b[0m        0.6726        \u001b[36m0.7652\u001b[0m  0.0000  3.3874\n",
            "[CV 2/3; 2/6] END lr=0.01, module__dropout=0.3, module__linear_size=500, module__size_emb=120;, score=-1.035 total time= 2.0min\n",
            "[CV 3/3; 2/6] START lr=0.01, module__dropout=0.3, module__linear_size=500, module__size_emb=120\n",
            "  epoch      f1    precision    recall    rmse_score    train_loss    valid_loss      lr     dur\n",
            "-------  ------  -----------  --------  ------------  ------------  ------------  ------  ------\n",
            "      1  \u001b[36m0.5693\u001b[0m       \u001b[32m0.8118\u001b[0m    \u001b[35m0.4383\u001b[0m        \u001b[31m0.9524\u001b[0m        \u001b[94m0.9938\u001b[0m        \u001b[36m0.9072\u001b[0m  0.0100  4.2581\n",
            "      2  0.4103       \u001b[32m0.8677\u001b[0m    0.2687        \u001b[31m0.9440\u001b[0m        \u001b[94m0.8702\u001b[0m        \u001b[36m0.8911\u001b[0m  0.0100  3.9531\n",
            "      3  0.4848       0.8491    0.3392        \u001b[31m0.9348\u001b[0m        \u001b[94m0.8451\u001b[0m        \u001b[36m0.8739\u001b[0m  0.0100  3.6504\n",
            "      4  0.4375       0.8615    0.2932        \u001b[31m0.9315\u001b[0m        \u001b[94m0.8272\u001b[0m        \u001b[36m0.8677\u001b[0m  0.0100  3.8835\n",
            "      5  0.4188       \u001b[32m0.8697\u001b[0m    0.2758        \u001b[31m0.9283\u001b[0m        \u001b[94m0.8194\u001b[0m        \u001b[36m0.8618\u001b[0m  0.0100  4.2467\n",
            "      6  0.5461       0.8466    0.4031        \u001b[31m0.9221\u001b[0m        \u001b[94m0.7964\u001b[0m        \u001b[36m0.8503\u001b[0m  0.0100  3.6094\n",
            "      7  0.4891       0.8640    0.3411        0.9381        \u001b[94m0.7843\u001b[0m        0.8801  0.0100  3.7515\n",
            "      8  0.5054       0.8678    0.3565        \u001b[31m0.9035\u001b[0m        \u001b[94m0.7212\u001b[0m        \u001b[36m0.8162\u001b[0m  0.0010  4.5406\n",
            "      9  0.5074       \u001b[32m0.8709\u001b[0m    0.3579        \u001b[31m0.8979\u001b[0m        \u001b[94m0.6990\u001b[0m        \u001b[36m0.8063\u001b[0m  0.0010  3.6169\n",
            "     10  0.5132       \u001b[32m0.8728\u001b[0m    0.3635        \u001b[31m0.8961\u001b[0m        \u001b[94m0.6903\u001b[0m        \u001b[36m0.8030\u001b[0m  0.0010  3.3585\n",
            "     11  0.5367       0.8672    0.3886        \u001b[31m0.8917\u001b[0m        \u001b[94m0.6831\u001b[0m        \u001b[36m0.7951\u001b[0m  0.0010  4.5584\n",
            "     12  0.5302       0.8711    0.3811        \u001b[31m0.8877\u001b[0m        \u001b[94m0.6790\u001b[0m        \u001b[36m0.7880\u001b[0m  0.0010  3.6744\n",
            "     13  0.5204       0.8724    0.3708        \u001b[31m0.8867\u001b[0m        \u001b[94m0.6720\u001b[0m        \u001b[36m0.7862\u001b[0m  0.0010  3.6333\n",
            "     14  0.5143       \u001b[32m0.8773\u001b[0m    0.3638        \u001b[31m0.8834\u001b[0m        \u001b[94m0.6670\u001b[0m        \u001b[36m0.7803\u001b[0m  0.0010  5.5699\n",
            "     15  0.5211       0.8737    0.3713        0.8845        \u001b[94m0.6533\u001b[0m        0.7823  0.0001  3.8161\n",
            "     16  0.5213       0.8748    0.3713        0.8846        0.6533        0.7824  0.0001  3.7559\n",
            "     17  0.5236       0.8725    0.3740        0.8842        \u001b[94m0.6532\u001b[0m        0.7818  0.0001  3.9289\n",
            "     18  0.5179       0.8749    0.3678        0.8841        \u001b[94m0.6512\u001b[0m        0.7815  0.0001  4.1922\n",
            "     19  0.5174       0.8757    0.3672        0.8840        0.6518        0.7814  0.0001  3.6596\n",
            "     20  0.5197       0.8754    0.3696        0.8841        \u001b[94m0.6494\u001b[0m        0.7816  0.0001  3.9249\n",
            "     21  0.5194       0.8746    0.3694        0.8837        0.6496        0.7809  0.0001  4.3595\n",
            "     22  0.5202       0.8741    0.3703        0.8835        \u001b[94m0.6479\u001b[0m        0.7807  0.0000  3.8599\n",
            "     23  0.5205       0.8742    0.3706        0.8834        0.6487        0.7804  0.0000  3.9499\n",
            "Stopping since valid_loss has not improved in the last 10 epochs.\n",
            "[CV 3/3; 2/6] END lr=0.01, module__dropout=0.3, module__linear_size=500, module__size_emb=120;, score=-1.124 total time= 1.7min\n",
            "[CV 1/3; 3/6] START lr=0.01, module__dropout=0.3, module__linear_size=1000, module__size_emb=60\n",
            "  epoch      f1    precision    recall    rmse_score    train_loss    valid_loss      lr     dur\n",
            "-------  ------  -----------  --------  ------------  ------------  ------------  ------  ------\n",
            "      1  \u001b[36m0.2936\u001b[0m       \u001b[32m0.8605\u001b[0m    \u001b[35m0.1770\u001b[0m        \u001b[31m0.9824\u001b[0m        \u001b[94m1.0736\u001b[0m        \u001b[36m0.9651\u001b[0m  0.0100  4.1250\n",
            "      2  \u001b[36m0.3288\u001b[0m       0.8566    \u001b[35m0.2035\u001b[0m        \u001b[31m0.9701\u001b[0m        \u001b[94m0.8881\u001b[0m        \u001b[36m0.9411\u001b[0m  0.0100  4.7583\n",
            "      3  \u001b[36m0.5220\u001b[0m       0.8124    \u001b[35m0.3846\u001b[0m        0.9747        \u001b[94m0.8670\u001b[0m        0.9499  0.0100  3.9206\n",
            "      4  \u001b[36m0.6273\u001b[0m       0.7740    \u001b[35m0.5273\u001b[0m        0.9832        \u001b[94m0.8541\u001b[0m        0.9667  0.0100  4.0595\n",
            "      5  0.4617       0.8237    0.3207        \u001b[31m0.9642\u001b[0m        \u001b[94m0.8472\u001b[0m        \u001b[36m0.9296\u001b[0m  0.0100  4.7550\n",
            "      6  0.4397       0.8313    0.2989        \u001b[31m0.9521\u001b[0m        \u001b[94m0.8366\u001b[0m        \u001b[36m0.9065\u001b[0m  0.0100  3.9635\n",
            "      7  0.5037       0.8238    0.3628        \u001b[31m0.9502\u001b[0m        \u001b[94m0.8284\u001b[0m        \u001b[36m0.9030\u001b[0m  0.0100  3.7579\n",
            "      8  0.4914       0.8298    0.3490        \u001b[31m0.9416\u001b[0m        \u001b[94m0.7829\u001b[0m        \u001b[36m0.8865\u001b[0m  0.0010  4.7847\n",
            "      9  0.5307       0.8213    0.3920        \u001b[31m0.9386\u001b[0m        \u001b[94m0.7703\u001b[0m        \u001b[36m0.8809\u001b[0m  0.0010  3.9383\n",
            "     10  0.5030       0.8308    0.3607        \u001b[31m0.9344\u001b[0m        \u001b[94m0.7601\u001b[0m        \u001b[36m0.8731\u001b[0m  0.0010  4.0116\n",
            "     11  0.5392       0.8200    0.4016        0.9345        \u001b[94m0.7528\u001b[0m        0.8734  0.0010  4.7745\n",
            "     12  0.5294       0.8244    0.3898        \u001b[31m0.9313\u001b[0m        \u001b[94m0.7464\u001b[0m        \u001b[36m0.8673\u001b[0m  0.0010  4.0196\n",
            "     13  0.5039       0.8306    0.3617        \u001b[31m0.9289\u001b[0m        \u001b[94m0.7399\u001b[0m        \u001b[36m0.8628\u001b[0m  0.0010  3.9829\n",
            "     14  0.5198       0.8293    0.3786        \u001b[31m0.9266\u001b[0m        \u001b[94m0.7362\u001b[0m        \u001b[36m0.8586\u001b[0m  0.0010  4.8255\n",
            "     15  0.5212       0.8290    0.3801        \u001b[31m0.9260\u001b[0m        \u001b[94m0.7220\u001b[0m        \u001b[36m0.8576\u001b[0m  0.0001  3.7375\n",
            "     16  0.5248       0.8281    0.3841        \u001b[31m0.9256\u001b[0m        \u001b[94m0.7203\u001b[0m        \u001b[36m0.8568\u001b[0m  0.0001  3.9723\n",
            "     17  0.5268       0.8272    0.3865        \u001b[31m0.9255\u001b[0m        \u001b[94m0.7194\u001b[0m        \u001b[36m0.8566\u001b[0m  0.0001  4.7140\n",
            "     18  0.5279       0.8274    0.3876        \u001b[31m0.9247\u001b[0m        \u001b[94m0.7182\u001b[0m        \u001b[36m0.8551\u001b[0m  0.0001  3.9445\n",
            "     19  0.5318       0.8253    0.3923        \u001b[31m0.9247\u001b[0m        \u001b[94m0.7157\u001b[0m        \u001b[36m0.8550\u001b[0m  0.0001  4.0587\n",
            "     20  0.5275       0.8261    0.3875        \u001b[31m0.9244\u001b[0m        0.7166        \u001b[36m0.8544\u001b[0m  0.0001  4.7583\n",
            "     21  0.5343       0.8260    0.3949        \u001b[31m0.9244\u001b[0m        \u001b[94m0.7153\u001b[0m        \u001b[36m0.8544\u001b[0m  0.0001  3.9732\n",
            "     22  0.5311       0.8258    0.3914        \u001b[31m0.9242\u001b[0m        \u001b[94m0.7145\u001b[0m        \u001b[36m0.8542\u001b[0m  0.0000  4.0852\n",
            "     23  0.5313       0.8260    0.3916        \u001b[31m0.9241\u001b[0m        \u001b[94m0.7143\u001b[0m        \u001b[36m0.8541\u001b[0m  0.0000  4.8685\n",
            "     24  0.5297       0.8265    0.3897        \u001b[31m0.9240\u001b[0m        \u001b[94m0.7138\u001b[0m        \u001b[36m0.8539\u001b[0m  0.0000  4.0625\n",
            "     25  0.5294       0.8265    0.3895        \u001b[31m0.9240\u001b[0m        \u001b[94m0.7132\u001b[0m        \u001b[36m0.8538\u001b[0m  0.0000  3.8549\n",
            "     26  0.5298       0.8264    0.3899        \u001b[31m0.9240\u001b[0m        \u001b[94m0.7130\u001b[0m        \u001b[36m0.8537\u001b[0m  0.0000  4.8572\n",
            "     27  0.5296       0.8261    0.3897        \u001b[31m0.9240\u001b[0m        \u001b[94m0.7118\u001b[0m        \u001b[36m0.8537\u001b[0m  0.0000  3.9622\n",
            "     28  0.5295       0.8264    0.3896        \u001b[31m0.9239\u001b[0m        0.7128        \u001b[36m0.8536\u001b[0m  0.0000  4.0401\n",
            "     29  0.5296       0.8264    0.3896        \u001b[31m0.9239\u001b[0m        0.7131        \u001b[36m0.8536\u001b[0m  0.0000  4.7088\n",
            "     30  0.5296       0.8264    0.3896        \u001b[31m0.9239\u001b[0m        0.7130        \u001b[36m0.8536\u001b[0m  0.0000  3.9763\n",
            "[CV 1/3; 3/6] END lr=0.01, module__dropout=0.3, module__linear_size=1000, module__size_emb=60;, score=-1.187 total time= 2.2min\n",
            "[CV 2/3; 3/6] START lr=0.01, module__dropout=0.3, module__linear_size=1000, module__size_emb=60\n",
            "  epoch      f1    precision    recall    rmse_score    train_loss    valid_loss      lr     dur\n",
            "-------  ------  -----------  --------  ------------  ------------  ------------  ------  ------\n",
            "      1  \u001b[36m0.5049\u001b[0m       \u001b[32m0.8235\u001b[0m    \u001b[35m0.3640\u001b[0m        \u001b[31m0.9497\u001b[0m        \u001b[94m1.1038\u001b[0m        \u001b[36m0.9020\u001b[0m  0.0100  4.3776\n",
            "      2  0.4597       \u001b[32m0.8394\u001b[0m    0.3165        \u001b[31m0.9350\u001b[0m        \u001b[94m0.8878\u001b[0m        \u001b[36m0.8742\u001b[0m  0.0100  4.3936\n",
            "      3  \u001b[36m0.5188\u001b[0m       0.8282    \u001b[35m0.3777\u001b[0m        \u001b[31m0.9289\u001b[0m        \u001b[94m0.8669\u001b[0m        \u001b[36m0.8629\u001b[0m  0.0100  3.7697\n",
            "      4  0.4736       \u001b[32m0.8431\u001b[0m    0.3293        \u001b[31m0.9253\u001b[0m        \u001b[94m0.8492\u001b[0m        \u001b[36m0.8562\u001b[0m  0.0100  4.7583\n",
            "      5  \u001b[36m0.5528\u001b[0m       0.8299    \u001b[35m0.4144\u001b[0m        \u001b[31m0.9203\u001b[0m        \u001b[94m0.8347\u001b[0m        \u001b[36m0.8469\u001b[0m  0.0100  3.9936\n",
            "      6  0.2154       \u001b[32m0.9186\u001b[0m    0.1220        0.9450        \u001b[94m0.8279\u001b[0m        0.8930  0.0100  4.0026\n",
            "      7  \u001b[36m0.5997\u001b[0m       0.8203    \u001b[35m0.4727\u001b[0m        \u001b[31m0.9188\u001b[0m        \u001b[94m0.8236\u001b[0m        \u001b[36m0.8441\u001b[0m  0.0100  4.5029\n",
            "      8  0.5249       0.8519    0.3793        \u001b[31m0.9026\u001b[0m        \u001b[94m0.7661\u001b[0m        \u001b[36m0.8146\u001b[0m  0.0010  4.2467\n",
            "      9  0.5115       0.8571    0.3645        \u001b[31m0.8987\u001b[0m        \u001b[94m0.7445\u001b[0m        \u001b[36m0.8077\u001b[0m  0.0010  4.0367\n",
            "     10  0.5189       0.8585    0.3718        \u001b[31m0.8951\u001b[0m        \u001b[94m0.7350\u001b[0m        \u001b[36m0.8013\u001b[0m  0.0010  4.6521\n",
            "     11  0.5066       0.8619    0.3588        \u001b[31m0.8927\u001b[0m        \u001b[94m0.7253\u001b[0m        \u001b[36m0.7970\u001b[0m  0.0010  4.2840\n",
            "     12  0.5113       0.8635    0.3632        \u001b[31m0.8895\u001b[0m        \u001b[94m0.7183\u001b[0m        \u001b[36m0.7912\u001b[0m  0.0010  4.2110\n",
            "     13  0.5089       0.8624    0.3609        \u001b[31m0.8881\u001b[0m        \u001b[94m0.7102\u001b[0m        \u001b[36m0.7888\u001b[0m  0.0010  4.9690\n",
            "     14  0.5176       0.8609    0.3700        \u001b[31m0.8840\u001b[0m        \u001b[94m0.7023\u001b[0m        \u001b[36m0.7815\u001b[0m  0.0010  3.8786\n",
            "     15  0.5343       0.8577    0.3880        \u001b[31m0.8835\u001b[0m        \u001b[94m0.6904\u001b[0m        \u001b[36m0.7805\u001b[0m  0.0001  4.4825\n",
            "     16  0.5361       0.8582    0.3898        \u001b[31m0.8830\u001b[0m        \u001b[94m0.6899\u001b[0m        \u001b[36m0.7797\u001b[0m  0.0001  4.7429\n",
            "     17  0.5325       0.8595    0.3857        \u001b[31m0.8828\u001b[0m        \u001b[94m0.6881\u001b[0m        \u001b[36m0.7792\u001b[0m  0.0001  3.9853\n",
            "     18  0.5424       0.8570    0.3967        \u001b[31m0.8823\u001b[0m        \u001b[94m0.6851\u001b[0m        \u001b[36m0.7784\u001b[0m  0.0001  4.4565\n",
            "     19  0.5369       0.8597    0.3903        \u001b[31m0.8822\u001b[0m        0.6871        \u001b[36m0.7783\u001b[0m  0.0001  5.1443\n",
            "     20  0.5379       0.8591    0.3916        \u001b[31m0.8820\u001b[0m        \u001b[94m0.6847\u001b[0m        \u001b[36m0.7779\u001b[0m  0.0001  4.0301\n",
            "     21  0.5401       0.8591    0.3938        \u001b[31m0.8816\u001b[0m        \u001b[94m0.6827\u001b[0m        \u001b[36m0.7772\u001b[0m  0.0001  3.9586\n",
            "     22  0.5404       0.8592    0.3942        0.8816        \u001b[94m0.6826\u001b[0m        0.7772  0.0000  4.7633\n",
            "     23  0.5386       0.8598    0.3921        \u001b[31m0.8816\u001b[0m        \u001b[94m0.6821\u001b[0m        \u001b[36m0.7772\u001b[0m  0.0000  4.2114\n",
            "     24  0.5401       0.8594    0.3937        \u001b[31m0.8815\u001b[0m        \u001b[94m0.6798\u001b[0m        \u001b[36m0.7771\u001b[0m  0.0000  4.1256\n",
            "     25  0.5397       0.8593    0.3934        \u001b[31m0.8815\u001b[0m        \u001b[94m0.6791\u001b[0m        \u001b[36m0.7770\u001b[0m  0.0000  4.6068\n",
            "     26  0.5396       0.8591    0.3933        \u001b[31m0.8815\u001b[0m        0.6823        \u001b[36m0.7770\u001b[0m  0.0000  4.1298\n",
            "     27  0.5389       0.8599    0.3925        \u001b[31m0.8814\u001b[0m        0.6806        \u001b[36m0.7769\u001b[0m  0.0000  4.0121\n",
            "     28  0.5386       0.8598    0.3921        \u001b[31m0.8814\u001b[0m        0.6820        \u001b[36m0.7768\u001b[0m  0.0000  4.7232\n",
            "     29  0.5385       0.8598    0.3920        \u001b[31m0.8814\u001b[0m        0.6802        \u001b[36m0.7768\u001b[0m  0.0000  4.0156\n",
            "     30  0.5385       0.8598    0.3920        \u001b[31m0.8814\u001b[0m        0.6801        \u001b[36m0.7768\u001b[0m  0.0000  4.0524\n",
            "[CV 2/3; 3/6] END lr=0.01, module__dropout=0.3, module__linear_size=1000, module__size_emb=60;, score=-1.045 total time= 2.2min\n",
            "[CV 3/3; 3/6] START lr=0.01, module__dropout=0.3, module__linear_size=1000, module__size_emb=60\n",
            "  epoch      f1    precision    recall    rmse_score    train_loss    valid_loss      lr     dur\n",
            "-------  ------  -----------  --------  ------------  ------------  ------------  ------  ------\n",
            "      1  \u001b[36m0.4518\u001b[0m       \u001b[32m0.8422\u001b[0m    \u001b[35m0.3087\u001b[0m        \u001b[31m0.9544\u001b[0m        \u001b[94m1.1014\u001b[0m        \u001b[36m0.9110\u001b[0m  0.0100  4.0532\n",
            "      2  0.3852       \u001b[32m0.8587\u001b[0m    0.2483        \u001b[31m0.9491\u001b[0m        \u001b[94m0.8690\u001b[0m        \u001b[36m0.9008\u001b[0m  0.0100  3.8495\n",
            "      3  \u001b[36m0.5421\u001b[0m       0.8281    \u001b[35m0.4029\u001b[0m        \u001b[31m0.9407\u001b[0m        \u001b[94m0.8502\u001b[0m        \u001b[36m0.8850\u001b[0m  0.0100  4.8202\n",
            "      4  0.5036       0.8372    0.3601        \u001b[31m0.9368\u001b[0m        \u001b[94m0.8331\u001b[0m        \u001b[36m0.8776\u001b[0m  0.0100  4.0547\n",
            "      5  \u001b[36m0.5437\u001b[0m       0.8315    \u001b[35m0.4039\u001b[0m        \u001b[31m0.9303\u001b[0m        \u001b[94m0.8237\u001b[0m        \u001b[36m0.8654\u001b[0m  0.0100  3.9859\n",
            "      6  0.4593       0.8569    0.3137        0.9316        \u001b[94m0.8118\u001b[0m        0.8680  0.0100  4.7950\n",
            "      7  0.4318       \u001b[32m0.8722\u001b[0m    0.2869        \u001b[31m0.9245\u001b[0m        \u001b[94m0.7971\u001b[0m        \u001b[36m0.8546\u001b[0m  0.0100  4.0154\n",
            "      8  0.4843       0.8638    0.3365        \u001b[31m0.9140\u001b[0m        \u001b[94m0.7403\u001b[0m        \u001b[36m0.8353\u001b[0m  0.0010  4.0186\n",
            "      9  0.5177       0.8534    0.3716        \u001b[31m0.9095\u001b[0m        \u001b[94m0.7243\u001b[0m        \u001b[36m0.8273\u001b[0m  0.0010  4.8194\n",
            "     10  0.4880       0.8673    0.3395        \u001b[31m0.9079\u001b[0m        \u001b[94m0.7133\u001b[0m        \u001b[36m0.8243\u001b[0m  0.0010  3.7785\n",
            "     11  0.5037       0.8636    0.3555        \u001b[31m0.9058\u001b[0m        \u001b[94m0.7060\u001b[0m        \u001b[36m0.8205\u001b[0m  0.0010  4.3016\n",
            "     12  0.5168       0.8612    0.3692        \u001b[31m0.9052\u001b[0m        \u001b[94m0.6992\u001b[0m        \u001b[36m0.8194\u001b[0m  0.0010  4.5380\n",
            "     13  0.4828       \u001b[32m0.8723\u001b[0m    0.3338        \u001b[31m0.9037\u001b[0m        \u001b[94m0.6956\u001b[0m        \u001b[36m0.8166\u001b[0m  0.0010  4.1168\n",
            "     14  0.4762       \u001b[32m0.8757\u001b[0m    0.3270        \u001b[31m0.9015\u001b[0m        \u001b[94m0.6885\u001b[0m        \u001b[36m0.8126\u001b[0m  0.0010  4.2447\n",
            "     15  0.5051       0.8668    0.3564        \u001b[31m0.8997\u001b[0m        \u001b[94m0.6785\u001b[0m        \u001b[36m0.8095\u001b[0m  0.0001  4.8319\n",
            "     16  0.5017       0.8680    0.3529        \u001b[31m0.8995\u001b[0m        \u001b[94m0.6763\u001b[0m        \u001b[36m0.8092\u001b[0m  0.0001  4.0841\n",
            "     17  0.5054       0.8669    0.3567        \u001b[31m0.8991\u001b[0m        \u001b[94m0.6752\u001b[0m        \u001b[36m0.8084\u001b[0m  0.0001  4.0034\n",
            "     18  0.5046       0.8676    0.3558        0.8993        \u001b[94m0.6740\u001b[0m        0.8088  0.0001  4.9239\n",
            "     19  0.5119       0.8658    0.3634        \u001b[31m0.8982\u001b[0m        \u001b[94m0.6723\u001b[0m        \u001b[36m0.8068\u001b[0m  0.0001  4.1728\n",
            "     20  0.5090       0.8667    0.3603        \u001b[31m0.8981\u001b[0m        \u001b[94m0.6721\u001b[0m        \u001b[36m0.8066\u001b[0m  0.0001  4.1193\n",
            "     21  0.5061       0.8678    0.3572        \u001b[31m0.8979\u001b[0m        \u001b[94m0.6713\u001b[0m        \u001b[36m0.8062\u001b[0m  0.0001  4.6148\n",
            "     22  0.5063       0.8677    0.3574        \u001b[31m0.8979\u001b[0m        \u001b[94m0.6699\u001b[0m        \u001b[36m0.8062\u001b[0m  0.0000  4.4782\n",
            "     23  0.5063       0.8679    0.3574        \u001b[31m0.8978\u001b[0m        0.6706        \u001b[36m0.8061\u001b[0m  0.0000  4.0493\n",
            "     24  0.5067       0.8677    0.3579        \u001b[31m0.8978\u001b[0m        0.6701        \u001b[36m0.8061\u001b[0m  0.0000  4.7307\n",
            "     25  0.5059       0.8679    0.3569        0.8978        \u001b[94m0.6689\u001b[0m        0.8061  0.0000  4.1281\n",
            "     26  0.5050       0.8679    0.3561        \u001b[31m0.8978\u001b[0m        0.6693        \u001b[36m0.8060\u001b[0m  0.0000  4.4799\n",
            "     27  0.5053       0.8678    0.3564        \u001b[31m0.8977\u001b[0m        0.6706        \u001b[36m0.8059\u001b[0m  0.0000  4.5881\n",
            "     28  0.5060       0.8678    0.3571        0.8977        0.6706        0.8059  0.0000  4.3269\n",
            "     29  0.5058       0.8677    0.3569        0.8977        0.6707        0.8059  0.0000  4.7912\n",
            "     30  0.5059       0.8678    0.3570        0.8977        0.6703        0.8059  0.0000  4.2474\n",
            "[CV 3/3; 3/6] END lr=0.01, module__dropout=0.3, module__linear_size=1000, module__size_emb=60;, score=-1.142 total time= 2.2min\n",
            "[CV 1/3; 4/6] START lr=0.01, module__dropout=0.3, module__linear_size=1000, module__size_emb=120\n",
            "  epoch      f1    precision    recall    rmse_score    train_loss    valid_loss      lr     dur\n",
            "-------  ------  -----------  --------  ------------  ------------  ------------  ------  ------\n",
            "      1  \u001b[36m0.4699\u001b[0m       \u001b[32m0.8266\u001b[0m    \u001b[35m0.3282\u001b[0m        \u001b[31m0.9803\u001b[0m        \u001b[94m1.0504\u001b[0m        \u001b[36m0.9609\u001b[0m  0.0100  4.2665\n",
            "      2  \u001b[36m0.5756\u001b[0m       0.7891    \u001b[35m0.4530\u001b[0m        0.9819        \u001b[94m0.8852\u001b[0m        0.9641  0.0100  4.7150\n",
            "      3  0.3245       \u001b[32m0.8579\u001b[0m    0.2001        \u001b[31m0.9684\u001b[0m        \u001b[94m0.8704\u001b[0m        \u001b[36m0.9378\u001b[0m  0.0100  4.2196\n",
            "      4  0.4045       0.8418    0.2662        \u001b[31m0.9624\u001b[0m        \u001b[94m0.8569\u001b[0m        \u001b[36m0.9261\u001b[0m  0.0100  4.5817\n",
            "      5  0.5255       0.8218    0.3862        \u001b[31m0.9528\u001b[0m        \u001b[94m0.8463\u001b[0m        \u001b[36m0.9078\u001b[0m  0.0100  4.6833\n",
            "      6  0.5335       0.8237    0.3946        \u001b[31m0.9460\u001b[0m        \u001b[94m0.8295\u001b[0m        \u001b[36m0.8950\u001b[0m  0.0100  4.1614\n",
            "      7  \u001b[36m0.6049\u001b[0m       0.8127    \u001b[35m0.4817\u001b[0m        \u001b[31m0.9423\u001b[0m        \u001b[94m0.8165\u001b[0m        \u001b[36m0.8879\u001b[0m  0.0100  4.2566\n",
            "      8  0.5049       0.8453    0.3599        \u001b[31m0.9223\u001b[0m        \u001b[94m0.7464\u001b[0m        \u001b[36m0.8506\u001b[0m  0.0010  4.3569\n",
            "      9  0.5150       0.8437    0.3706        \u001b[31m0.9185\u001b[0m        \u001b[94m0.7243\u001b[0m        \u001b[36m0.8436\u001b[0m  0.0010  4.2304\n",
            "     10  0.5388       0.8434    0.3958        \u001b[31m0.9153\u001b[0m        \u001b[94m0.7139\u001b[0m        \u001b[36m0.8379\u001b[0m  0.0010  5.0225\n",
            "     11  0.5346       0.8402    0.3920        \u001b[31m0.9128\u001b[0m        \u001b[94m0.7035\u001b[0m        \u001b[36m0.8332\u001b[0m  0.0010  4.2929\n",
            "     12  0.5097       0.8517    0.3637        \u001b[31m0.9104\u001b[0m        \u001b[94m0.6961\u001b[0m        \u001b[36m0.8289\u001b[0m  0.0010  4.0339\n",
            "     13  0.5563       0.8419    0.4153        \u001b[31m0.9070\u001b[0m        \u001b[94m0.6896\u001b[0m        \u001b[36m0.8227\u001b[0m  0.0010  4.9303\n",
            "     14  0.5482       0.8463    0.4054        \u001b[31m0.9061\u001b[0m        \u001b[94m0.6797\u001b[0m        \u001b[36m0.8211\u001b[0m  0.0010  3.8416\n",
            "     15  0.5422       0.8465    0.3988        \u001b[31m0.9037\u001b[0m        \u001b[94m0.6690\u001b[0m        \u001b[36m0.8166\u001b[0m  0.0001  4.9256\n",
            "     16  0.5370       0.8482    0.3928        \u001b[31m0.9034\u001b[0m        \u001b[94m0.6664\u001b[0m        \u001b[36m0.8161\u001b[0m  0.0001  4.8782\n",
            "     17  0.5446       0.8469    0.4014        \u001b[31m0.9029\u001b[0m        \u001b[94m0.6644\u001b[0m        \u001b[36m0.8153\u001b[0m  0.0001  4.1550\n",
            "     18  0.5335       0.8500    0.3887        \u001b[31m0.9023\u001b[0m        \u001b[94m0.6613\u001b[0m        \u001b[36m0.8141\u001b[0m  0.0001  4.3614\n",
            "     19  0.5404       0.8479    0.3965        \u001b[31m0.9021\u001b[0m        0.6625        \u001b[36m0.8138\u001b[0m  0.0001  4.8834\n",
            "     20  0.5454       0.8477    0.4020        \u001b[31m0.9017\u001b[0m        0.6621        \u001b[36m0.8131\u001b[0m  0.0001  4.1311\n",
            "     21  0.5429       0.8486    0.3991        \u001b[31m0.9013\u001b[0m        \u001b[94m0.6606\u001b[0m        \u001b[36m0.8124\u001b[0m  0.0001  4.5351\n",
            "     22  0.5411       0.8485    0.3972        \u001b[31m0.9013\u001b[0m        \u001b[94m0.6603\u001b[0m        \u001b[36m0.8123\u001b[0m  0.0000  4.5334\n",
            "     23  0.5408       0.8485    0.3969        \u001b[31m0.9012\u001b[0m        \u001b[94m0.6597\u001b[0m        \u001b[36m0.8122\u001b[0m  0.0000  3.8627\n",
            "     24  0.5408       0.8485    0.3968        \u001b[31m0.9012\u001b[0m        0.6602        \u001b[36m0.8121\u001b[0m  0.0000  4.5479\n",
            "     25  0.5419       0.8486    0.3981        \u001b[31m0.9012\u001b[0m        \u001b[94m0.6586\u001b[0m        \u001b[36m0.8121\u001b[0m  0.0000  4.5742\n",
            "     26  0.5421       0.8487    0.3983        \u001b[31m0.9011\u001b[0m        0.6590        \u001b[36m0.8120\u001b[0m  0.0000  4.1960\n",
            "     27  0.5420       0.8486    0.3982        \u001b[31m0.9011\u001b[0m        0.6590        \u001b[36m0.8120\u001b[0m  0.0000  4.9604\n",
            "     28  0.5420       0.8491    0.3980        \u001b[31m0.9010\u001b[0m        0.6596        \u001b[36m0.8119\u001b[0m  0.0000  4.1964\n",
            "     29  0.5420       0.8491    0.3981        \u001b[31m0.9010\u001b[0m        \u001b[94m0.6581\u001b[0m        \u001b[36m0.8118\u001b[0m  0.0000  4.1451\n",
            "     30  0.5420       0.8491    0.3981        \u001b[31m0.9010\u001b[0m        0.6596        \u001b[36m0.8118\u001b[0m  0.0000  5.1087\n",
            "[CV 1/3; 4/6] END lr=0.01, module__dropout=0.3, module__linear_size=1000, module__size_emb=120;, score=-1.190 total time= 2.3min\n",
            "[CV 2/3; 4/6] START lr=0.01, module__dropout=0.3, module__linear_size=1000, module__size_emb=120\n",
            "  epoch      f1    precision    recall    rmse_score    train_loss    valid_loss      lr     dur\n",
            "-------  ------  -----------  --------  ------------  ------------  ------------  ------  ------\n",
            "      1  \u001b[36m0.6357\u001b[0m       \u001b[32m0.7800\u001b[0m    \u001b[35m0.5365\u001b[0m        \u001b[31m0.9756\u001b[0m        \u001b[94m1.0672\u001b[0m        \u001b[36m0.9517\u001b[0m  0.0100  4.3683\n",
            "      2  0.4657       \u001b[32m0.8296\u001b[0m    0.3237        \u001b[31m0.9363\u001b[0m        \u001b[94m0.8916\u001b[0m        \u001b[36m0.8766\u001b[0m  0.0100  4.7433\n",
            "      3  0.6130       0.7992    0.4972        \u001b[31m0.9304\u001b[0m        \u001b[94m0.8617\u001b[0m        \u001b[36m0.8656\u001b[0m  0.0100  4.4692\n",
            "      4  0.5255       \u001b[32m0.8346\u001b[0m    0.3835        \u001b[31m0.9188\u001b[0m        \u001b[94m0.8425\u001b[0m        \u001b[36m0.8442\u001b[0m  0.0100  4.2980\n",
            "      5  0.3867       \u001b[32m0.8839\u001b[0m    0.2475        \u001b[31m0.9184\u001b[0m        \u001b[94m0.8236\u001b[0m        \u001b[36m0.8434\u001b[0m  0.0100  4.9416\n",
            "      6  0.3336       \u001b[32m0.8867\u001b[0m    0.2054        0.9264        \u001b[94m0.8073\u001b[0m        0.8582  0.0100  4.1784\n",
            "      7  0.4185       0.8810    0.2744        \u001b[31m0.9039\u001b[0m        \u001b[94m0.7991\u001b[0m        \u001b[36m0.8171\u001b[0m  0.0100  4.0775\n",
            "      8  0.4989       0.8649    0.3506        \u001b[31m0.8865\u001b[0m        \u001b[94m0.7372\u001b[0m        \u001b[36m0.7859\u001b[0m  0.0010  4.9426\n",
            "      9  0.5315       0.8568    0.3852        \u001b[31m0.8809\u001b[0m        \u001b[94m0.7172\u001b[0m        \u001b[36m0.7760\u001b[0m  0.0010  4.2788\n",
            "     10  0.5174       0.8649    0.3691        \u001b[31m0.8780\u001b[0m        \u001b[94m0.7036\u001b[0m        \u001b[36m0.7708\u001b[0m  0.0010  4.2465\n",
            "     11  0.5080       0.8680    0.3590        \u001b[31m0.8753\u001b[0m        \u001b[94m0.6955\u001b[0m        \u001b[36m0.7662\u001b[0m  0.0010  5.0149\n",
            "     12  0.5211       0.8651    0.3728        \u001b[31m0.8722\u001b[0m        \u001b[94m0.6879\u001b[0m        \u001b[36m0.7607\u001b[0m  0.0010  4.2382\n",
            "     13  0.5116       0.8689    0.3625        \u001b[31m0.8705\u001b[0m        \u001b[94m0.6789\u001b[0m        \u001b[36m0.7577\u001b[0m  0.0010  3.9126\n",
            "     14  0.5302       0.8679    0.3817        \u001b[31m0.8661\u001b[0m        \u001b[94m0.6740\u001b[0m        \u001b[36m0.7502\u001b[0m  0.0010  5.0432\n",
            "     15  0.5113       0.8737    0.3614        0.8664        \u001b[94m0.6616\u001b[0m        0.7506  0.0001  4.2292\n",
            "     16  0.5128       0.8738    0.3629        \u001b[31m0.8661\u001b[0m        \u001b[94m0.6582\u001b[0m        \u001b[36m0.7502\u001b[0m  0.0001  4.4614\n",
            "     17  0.5078       0.8755    0.3576        \u001b[31m0.8659\u001b[0m        0.6598        \u001b[36m0.7498\u001b[0m  0.0001  4.6364\n",
            "     18  0.5148       0.8727    0.3650        \u001b[31m0.8653\u001b[0m        \u001b[94m0.6572\u001b[0m        \u001b[36m0.7488\u001b[0m  0.0001  4.2191\n",
            "     19  0.5143       0.8726    0.3646        \u001b[31m0.8648\u001b[0m        \u001b[94m0.6558\u001b[0m        \u001b[36m0.7480\u001b[0m  0.0001  4.7558\n",
            "     20  0.5240       0.8719    0.3746        \u001b[31m0.8641\u001b[0m        \u001b[94m0.6529\u001b[0m        \u001b[36m0.7467\u001b[0m  0.0001  4.4044\n",
            "     21  0.5139       0.8730    0.3641        0.8644        0.6558        0.7472  0.0001  4.1730\n",
            "     22  0.5165       0.8732    0.3667        0.8643        \u001b[94m0.6517\u001b[0m        0.7470  0.0000  5.0062\n",
            "     23  0.5160       0.8731    0.3662        0.8643        0.6530        0.7470  0.0000  4.2262\n",
            "     24  0.5159       0.8731    0.3661        0.8642        0.6531        0.7469  0.0000  4.2214\n",
            "     25  0.5170       0.8732    0.3672        0.8641        0.6522        0.7467  0.0000  4.8138\n",
            "     26  0.5167       0.8729    0.3669        \u001b[31m0.8641\u001b[0m        \u001b[94m0.6503\u001b[0m        \u001b[36m0.7467\u001b[0m  0.0000  4.2058\n",
            "     27  0.5175       0.8732    0.3678        \u001b[31m0.8640\u001b[0m        0.6521        \u001b[36m0.7466\u001b[0m  0.0000  4.1304\n",
            "     28  0.5184       0.8727    0.3687        \u001b[31m0.8640\u001b[0m        0.6509        \u001b[36m0.7464\u001b[0m  0.0000  5.1044\n",
            "     29  0.5182       0.8728    0.3685        \u001b[31m0.8640\u001b[0m        0.6512        \u001b[36m0.7464\u001b[0m  0.0000  4.2515\n",
            "Stopping since valid_loss has not improved in the last 10 epochs.\n",
            "[CV 2/3; 4/6] END lr=0.01, module__dropout=0.3, module__linear_size=1000, module__size_emb=120;, score=-1.025 total time= 2.3min\n",
            "[CV 3/3; 4/6] START lr=0.01, module__dropout=0.3, module__linear_size=1000, module__size_emb=120\n",
            "  epoch      f1    precision    recall    rmse_score    train_loss    valid_loss      lr     dur\n",
            "-------  ------  -----------  --------  ------------  ------------  ------------  ------  ------\n",
            "      1  \u001b[36m0.4397\u001b[0m       \u001b[32m0.8465\u001b[0m    \u001b[35m0.2970\u001b[0m        \u001b[31m0.9590\u001b[0m        \u001b[94m1.0513\u001b[0m        \u001b[36m0.9197\u001b[0m  0.0100  3.8578\n",
            "      2  \u001b[36m0.5915\u001b[0m       0.8081    \u001b[35m0.4665\u001b[0m        \u001b[31m0.9500\u001b[0m        \u001b[94m0.8787\u001b[0m        \u001b[36m0.9025\u001b[0m  0.0100  4.4232\n",
            "      3  0.5133       0.8353    0.3705        \u001b[31m0.9360\u001b[0m        \u001b[94m0.8445\u001b[0m        \u001b[36m0.8761\u001b[0m  0.0100  4.8360\n",
            "      4  0.5154       0.8396    0.3718        \u001b[31m0.9314\u001b[0m        \u001b[94m0.8264\u001b[0m        \u001b[36m0.8675\u001b[0m  0.0100  4.2833\n",
            "      5  0.5359       0.8396    0.3936        \u001b[31m0.9256\u001b[0m        \u001b[94m0.8090\u001b[0m        \u001b[36m0.8567\u001b[0m  0.0100  4.1786\n",
            "      6  0.4916       \u001b[32m0.8605\u001b[0m    0.3441        \u001b[31m0.9168\u001b[0m        \u001b[94m0.7911\u001b[0m        \u001b[36m0.8405\u001b[0m  0.0100  4.9971\n",
            "      7  0.2810       \u001b[32m0.9145\u001b[0m    0.1660        0.9791        \u001b[94m0.7813\u001b[0m        0.9585  0.0100  4.2617\n",
            "      8  0.4913       0.8737    0.3418        \u001b[31m0.8994\u001b[0m        \u001b[94m0.7302\u001b[0m        \u001b[36m0.8089\u001b[0m  0.0010  4.2953\n",
            "      9  0.4784       0.8825    0.3282        \u001b[31m0.8952\u001b[0m        \u001b[94m0.6996\u001b[0m        \u001b[36m0.8014\u001b[0m  0.0010  5.0161\n",
            "     10  0.5015       0.8795    0.3508        \u001b[31m0.8921\u001b[0m        \u001b[94m0.6870\u001b[0m        \u001b[36m0.7958\u001b[0m  0.0010  4.9728\n",
            "     11  0.4642       0.8914    0.3138        \u001b[31m0.8910\u001b[0m        \u001b[94m0.6764\u001b[0m        \u001b[36m0.7940\u001b[0m  0.0010  4.9726\n",
            "     12  0.4907       0.8869    0.3391        \u001b[31m0.8884\u001b[0m        \u001b[94m0.6708\u001b[0m        \u001b[36m0.7893\u001b[0m  0.0010  4.1760\n",
            "     13  0.5132       0.8803    0.3621        \u001b[31m0.8822\u001b[0m        \u001b[94m0.6658\u001b[0m        \u001b[36m0.7783\u001b[0m  0.0010  4.2908\n",
            "     14  0.5122       0.8836    0.3606        \u001b[31m0.8803\u001b[0m        \u001b[94m0.6571\u001b[0m        \u001b[36m0.7750\u001b[0m  0.0010  4.7203\n",
            "     15  0.5044       0.8853    0.3527        \u001b[31m0.8796\u001b[0m        \u001b[94m0.6445\u001b[0m        \u001b[36m0.7738\u001b[0m  0.0001  4.2625\n",
            "     16  0.4976       0.8888    0.3455        0.8798        \u001b[94m0.6422\u001b[0m        0.7740  0.0001  4.2781\n",
            "     17  0.4929       0.8910    0.3407        \u001b[31m0.8795\u001b[0m        0.6424        \u001b[36m0.7736\u001b[0m  0.0001  5.0710\n",
            "     18  0.5079       0.8849    0.3561        \u001b[31m0.8784\u001b[0m        \u001b[94m0.6421\u001b[0m        \u001b[36m0.7717\u001b[0m  0.0001  4.2380\n",
            "     19  0.5003       0.8895    0.3480        0.8787        \u001b[94m0.6388\u001b[0m        0.7721  0.0001  4.2130\n",
            "     20  0.5060       0.8879    0.3539        \u001b[31m0.8780\u001b[0m        0.6401        \u001b[36m0.7708\u001b[0m  0.0001  5.0582\n",
            "     21  0.4932       0.8927    0.3407        0.8786        \u001b[94m0.6373\u001b[0m        0.7720  0.0001  3.9312\n",
            "     22  0.4954       0.8908    0.3431        0.8785        \u001b[94m0.6366\u001b[0m        0.7717  0.0000  4.5559\n",
            "     23  0.4981       0.8903    0.3458        0.8782        \u001b[94m0.6354\u001b[0m        0.7713  0.0000  4.7383\n",
            "     24  0.5006       0.8900    0.3482        0.8780        0.6360        0.7709  0.0000  4.2381\n",
            "     25  0.5006       0.8896    0.3483        0.8780        \u001b[94m0.6349\u001b[0m        0.7708  0.0000  4.8688\n",
            "     26  0.5025       0.8891    0.3502        \u001b[31m0.8778\u001b[0m        0.6360        \u001b[36m0.7706\u001b[0m  0.0000  4.3421\n",
            "     27  0.5026       0.8895    0.3502        \u001b[31m0.8778\u001b[0m        0.6361        \u001b[36m0.7705\u001b[0m  0.0000  4.1166\n",
            "     28  0.5008       0.8898    0.3484        0.8779        \u001b[94m0.6342\u001b[0m        0.7706  0.0000  5.1567\n",
            "     29  0.5008       0.8898    0.3484        0.8779        0.6364        0.7706  0.0000  4.3171\n",
            "Stopping since valid_loss has not improved in the last 10 epochs.\n",
            "[CV 3/3; 4/6] END lr=0.01, module__dropout=0.3, module__linear_size=1000, module__size_emb=120;, score=-1.109 total time= 2.3min\n",
            "[CV 1/3; 5/6] START lr=0.01, module__dropout=0.3, module__linear_size=1500, module__size_emb=60\n",
            "  epoch      f1    precision    recall    rmse_score    train_loss    valid_loss      lr     dur\n",
            "-------  ------  -----------  --------  ------------  ------------  ------------  ------  ------\n",
            "      1  \u001b[36m0.7101\u001b[0m       \u001b[32m0.5505\u001b[0m    \u001b[35m1.0000\u001b[0m        \u001b[31m1.8532\u001b[0m        \u001b[94m3.1567\u001b[0m        \u001b[36m3.4343\u001b[0m  0.0100  5.1524\n",
            "      2  0.7101       0.5505    1.0000        1.8532        3.1860        3.4343  0.0100  4.6893\n",
            "      3  0.7101       0.5505    1.0000        1.8532        3.1860        3.4343  0.0100  5.4619\n",
            "      4  0.7101       0.5505    1.0000        1.8532        3.1860        3.4343  0.0100  4.7418\n",
            "      5  0.7101       0.5505    1.0000        1.8532        3.1860        3.4343  0.0100  5.0294\n",
            "      6  0.7101       0.5505    1.0000        1.8532        3.1860        3.4343  0.0100  5.1966\n",
            "      7  0.7101       0.5505    1.0000        1.8532        3.1860        3.4343  0.0100  4.8249\n",
            "      8  0.7101       0.5505    1.0000        1.8532        3.1860        3.4343  0.0010  5.4253\n",
            "      9  0.7101       0.5505    1.0000        1.8532        3.1860        3.4343  0.0010  4.7158\n",
            "     10  0.7101       0.5505    1.0000        1.8532        3.1860        3.4343  0.0010  4.9156\n",
            "Stopping since valid_loss has not improved in the last 10 epochs.\n",
            "[CV 1/3; 5/6] END lr=0.01, module__dropout=0.3, module__linear_size=1500, module__size_emb=60;, score=-3.913 total time=  57.6s\n",
            "[CV 2/3; 5/6] START lr=0.01, module__dropout=0.3, module__linear_size=1500, module__size_emb=60\n",
            "  epoch      f1    precision    recall    rmse_score    train_loss    valid_loss      lr     dur\n",
            "-------  ------  -----------  --------  ------------  ------------  ------------  ------  ------\n",
            "      1  \u001b[36m0.7101\u001b[0m       \u001b[32m0.5505\u001b[0m    \u001b[35m1.0000\u001b[0m        \u001b[31m1.8532\u001b[0m        \u001b[94m3.5116\u001b[0m        \u001b[36m3.4343\u001b[0m  0.0100  4.7498\n",
            "      2  0.7101       0.5505    1.0000        1.8532        3.5382        3.4343  0.0100  5.4708\n",
            "      3  0.7101       0.5505    1.0000        1.8532        3.5382        3.4343  0.0100  4.7423\n",
            "      4  0.7101       0.5505    1.0000        1.8532        3.5382        3.4343  0.0100  5.4562\n",
            "      5  0.7101       0.5505    1.0000        1.8532        3.5382        3.4343  0.0100  4.8487\n",
            "      6  0.7101       0.5505    1.0000        1.8532        3.5382        3.4343  0.0100  4.7290\n",
            "      7  0.7101       0.5505    1.0000        1.8532        3.5382        3.4343  0.0100  5.4391\n",
            "      8  0.7101       0.5505    1.0000        1.8532        3.5382        3.4343  0.0010  4.7313\n",
            "      9  0.7101       0.5505    1.0000        1.8532        3.5382        3.4343  0.0010  5.5247\n",
            "     10  0.7101       0.5505    1.0000        1.8532        3.5382        3.4343  0.0010  4.7669\n",
            "Stopping since valid_loss has not improved in the last 10 epochs.\n",
            "[CV 2/3; 5/6] END lr=0.01, module__dropout=0.3, module__linear_size=1500, module__size_emb=60;, score=-3.209 total time=  58.4s\n",
            "[CV 3/3; 5/6] START lr=0.01, module__dropout=0.3, module__linear_size=1500, module__size_emb=60\n",
            "  epoch      f1    precision    recall    rmse_score    train_loss    valid_loss      lr     dur\n",
            "-------  ------  -----------  --------  ------------  ------------  ------------  ------  ------\n",
            "      1  \u001b[36m0.7101\u001b[0m       \u001b[32m0.5505\u001b[0m    \u001b[35m1.0000\u001b[0m        \u001b[31m1.8532\u001b[0m        \u001b[94m3.5292\u001b[0m        \u001b[36m3.4343\u001b[0m  0.0100  4.8173\n",
            "      2  0.7101       0.5505    1.0000        1.8532        3.5611        3.4343  0.0100  4.7212\n",
            "      3  0.7101       0.5505    1.0000        1.8532        3.5611        3.4343  0.0100  5.2682\n",
            "      4  0.7101       0.5505    1.0000        1.8532        3.5611        3.4343  0.0100  4.6982\n",
            "      5  0.7101       0.5505    1.0000        1.8532        3.5611        3.4343  0.0100  5.3141\n",
            "      6  0.7101       0.5505    1.0000        1.8532        3.5611        3.4343  0.0100  4.7858\n",
            "      7  0.7101       0.5505    1.0000        1.8532        3.5611        3.4343  0.0100  4.7787\n",
            "      8  0.7101       0.5505    1.0000        1.8532        3.5611        3.4343  0.0010  5.9668\n",
            "      9  0.7101       0.5505    1.0000        1.8532        3.5611        3.4343  0.0010  5.1387\n",
            "     10  0.7101       0.5505    1.0000        1.8532        3.5611        3.4343  0.0010  5.3907\n",
            "Stopping since valid_loss has not improved in the last 10 epochs.\n",
            "[CV 3/3; 5/6] END lr=0.01, module__dropout=0.3, module__linear_size=1500, module__size_emb=60;, score=-3.163 total time=  58.0s\n",
            "[CV 1/3; 6/6] START lr=0.01, module__dropout=0.3, module__linear_size=1500, module__size_emb=120\n",
            "  epoch      f1    precision    recall    rmse_score    train_loss    valid_loss      lr     dur\n",
            "-------  ------  -----------  --------  ------------  ------------  ------------  ------  ------\n",
            "      1  \u001b[36m0.7101\u001b[0m       \u001b[32m0.5505\u001b[0m    \u001b[35m1.0000\u001b[0m        \u001b[31m1.8532\u001b[0m        \u001b[94m3.1644\u001b[0m        \u001b[36m3.4343\u001b[0m  0.0100  5.5771\n",
            "      2  0.7101       0.5505    1.0000        1.8532        3.1860        3.4343  0.0100  4.5924\n",
            "      3  0.7101       0.5505    1.0000        1.8532        3.1860        3.4343  0.0100  4.8741\n",
            "      4  0.7101       0.5505    1.0000        1.8532        3.1860        3.4343  0.0100  5.5486\n",
            "      5  0.7101       0.5505    1.0000        1.8532        3.1860        3.4343  0.0100  4.9617\n",
            "      6  0.7101       0.5505    1.0000        1.8532        3.1860        3.4343  0.0100  5.7137\n",
            "      7  0.7101       0.5505    1.0000        1.8532        3.1860        3.4343  0.0100  4.9030\n",
            "      8  0.7101       0.5505    1.0000        1.8532        3.1860        3.4343  0.0010  5.0454\n",
            "      9  0.7101       0.5505    1.0000        1.8532        3.1860        3.4343  0.0010  5.4280\n",
            "     10  0.7101       0.5505    1.0000        1.8532        3.1860        3.4343  0.0010  4.7953\n",
            "Stopping since valid_loss has not improved in the last 10 epochs.\n",
            "[CV 1/3; 6/6] END lr=0.01, module__dropout=0.3, module__linear_size=1500, module__size_emb=120;, score=-3.913 total time=  59.5s\n",
            "[CV 2/3; 6/6] START lr=0.01, module__dropout=0.3, module__linear_size=1500, module__size_emb=120\n",
            "  epoch      f1    precision    recall    rmse_score    train_loss    valid_loss      lr     dur\n",
            "-------  ------  -----------  --------  ------------  ------------  ------------  ------  ------\n",
            "      1  \u001b[36m0.7101\u001b[0m       \u001b[32m0.5505\u001b[0m    \u001b[35m1.0000\u001b[0m        \u001b[31m1.8532\u001b[0m        \u001b[94m3.5041\u001b[0m        \u001b[36m3.4343\u001b[0m  0.0100  4.5406\n",
            "      2  0.7101       0.5505    1.0000        1.8532        3.5382        3.4343  0.0100  5.5498\n",
            "      3  0.7101       0.5505    1.0000        1.8532        3.5382        3.4343  0.0100  4.9168\n",
            "      4  0.7101       0.5505    1.0000        1.8532        3.5382        3.4343  0.0100  4.9107\n",
            "      5  0.7101       0.5505    1.0000        1.8532        3.5382        3.4343  0.0100  5.4509\n",
            "      6  0.7101       0.5505    1.0000        1.8532        3.5382        3.4343  0.0100  4.8818\n",
            "      7  0.7101       0.5505    1.0000        1.8532        3.5382        3.4343  0.0100  5.2840\n",
            "      8  0.7101       0.5505    1.0000        1.8532        3.5382        3.4343  0.0010  4.7291\n",
            "      9  0.7101       0.5505    1.0000        1.8532        3.5382        3.4343  0.0010  4.9680\n",
            "     10  0.7101       0.5505    1.0000        1.8532        3.5382        3.4343  0.0010  5.3954\n",
            "Stopping since valid_loss has not improved in the last 10 epochs.\n",
            "[CV 2/3; 6/6] END lr=0.01, module__dropout=0.3, module__linear_size=1500, module__size_emb=120;, score=-3.209 total time=  58.0s\n",
            "[CV 3/3; 6/6] START lr=0.01, module__dropout=0.3, module__linear_size=1500, module__size_emb=120\n",
            "  epoch      f1    precision    recall    rmse_score    train_loss    valid_loss      lr     dur\n",
            "-------  ------  -----------  --------  ------------  ------------  ------------  ------  ------\n",
            "      1  \u001b[36m0.7101\u001b[0m       \u001b[32m0.5505\u001b[0m    \u001b[35m1.0000\u001b[0m        \u001b[31m1.8532\u001b[0m        \u001b[94m3.5331\u001b[0m        \u001b[36m3.4343\u001b[0m  0.0100  5.4677\n",
            "      2  0.7101       0.5505    1.0000        1.8532        3.5611        3.4343  0.0100  4.7579\n",
            "      3  0.7101       0.5505    1.0000        1.8532        3.5611        3.4343  0.0100  5.3522\n",
            "      4  0.7101       0.5505    1.0000        1.8532        3.5611        3.4343  0.0100  4.7627\n",
            "      5  0.7101       0.5505    1.0000        1.8532        3.5611        3.4343  0.0100  4.8661\n",
            "      6  0.7101       0.5505    1.0000        1.8532        3.5611        3.4343  0.0100  5.4543\n",
            "      7  0.7101       0.5505    1.0000        1.8532        3.5611        3.4343  0.0100  4.8338\n",
            "      8  0.7101       0.5505    1.0000        1.8532        3.5611        3.4343  0.0010  5.5467\n",
            "      9  0.7101       0.5505    1.0000        1.8532        3.5611        3.4343  0.0010  4.7921\n",
            "     10  0.7101       0.5505    1.0000        1.8532        3.5611        3.4343  0.0010  4.6014\n",
            "Stopping since valid_loss has not improved in the last 10 epochs.\n",
            "[CV 3/3; 6/6] END lr=0.01, module__dropout=0.3, module__linear_size=1500, module__size_emb=120;, score=-3.163 total time=  58.4s\n",
            "  epoch      f1    precision    recall    rmse_score    train_loss    valid_loss      lr     dur\n",
            "-------  ------  -----------  --------  ------------  ------------  ------------  ------  ------\n",
            "      1  \u001b[36m0.6164\u001b[0m       \u001b[32m0.8228\u001b[0m    \u001b[35m0.4927\u001b[0m        \u001b[31m0.9139\u001b[0m        \u001b[94m1.0207\u001b[0m        \u001b[36m0.8352\u001b[0m  0.0100  6.5427\n",
            "      2  0.4258       \u001b[32m0.8749\u001b[0m    0.2814        \u001b[31m0.9047\u001b[0m        \u001b[94m0.8856\u001b[0m        \u001b[36m0.8185\u001b[0m  0.0100  6.3949\n",
            "      3  0.4908       0.8687    0.3421        \u001b[31m0.8939\u001b[0m        \u001b[94m0.8662\u001b[0m        \u001b[36m0.7990\u001b[0m  0.0100  6.7630\n",
            "      4  0.5711       0.8555    0.4286        \u001b[31m0.8823\u001b[0m        \u001b[94m0.8496\u001b[0m        \u001b[36m0.7785\u001b[0m  0.0100  6.2400\n",
            "      5  0.4926       \u001b[32m0.8817\u001b[0m    0.3418        \u001b[31m0.8779\u001b[0m        \u001b[94m0.8413\u001b[0m        \u001b[36m0.7707\u001b[0m  0.0100  6.7112\n",
            "      6  0.4923       \u001b[32m0.8836\u001b[0m    0.3412        0.8822        \u001b[94m0.8303\u001b[0m        0.7783  0.0100  6.0945\n",
            "      7  0.5862       0.8705    0.4419        \u001b[31m0.8660\u001b[0m        \u001b[94m0.8208\u001b[0m        \u001b[36m0.7500\u001b[0m  0.0100  6.7921\n",
            "      8  0.5224       \u001b[32m0.8939\u001b[0m    0.3690        \u001b[31m0.8452\u001b[0m        \u001b[94m0.7630\u001b[0m        \u001b[36m0.7143\u001b[0m  0.0010  5.8552\n",
            "      9  0.5181       \u001b[32m0.9014\u001b[0m    0.3635        \u001b[31m0.8422\u001b[0m        \u001b[94m0.7440\u001b[0m        \u001b[36m0.7093\u001b[0m  0.0010  7.5471\n",
            "     10  0.5449       0.8964    0.3914        \u001b[31m0.8350\u001b[0m        \u001b[94m0.7339\u001b[0m        \u001b[36m0.6973\u001b[0m  0.0010  6.0344\n",
            "     11  0.5339       \u001b[32m0.9023\u001b[0m    0.3791        \u001b[31m0.8297\u001b[0m        \u001b[94m0.7274\u001b[0m        \u001b[36m0.6883\u001b[0m  0.0010  6.8471\n",
            "     12  0.5403       0.9006    0.3859        \u001b[31m0.8253\u001b[0m        \u001b[94m0.7185\u001b[0m        \u001b[36m0.6810\u001b[0m  0.0010  5.9938\n",
            "     13  0.5633       0.8984    0.4103        \u001b[31m0.8207\u001b[0m        \u001b[94m0.7136\u001b[0m        \u001b[36m0.6736\u001b[0m  0.0010  6.8469\n",
            "     14  0.5647       0.9007    0.4113        \u001b[31m0.8176\u001b[0m        \u001b[94m0.7060\u001b[0m        \u001b[36m0.6685\u001b[0m  0.0010  6.0213\n",
            "     15  0.5390       \u001b[32m0.9081\u001b[0m    0.3832        \u001b[31m0.8163\u001b[0m        \u001b[94m0.6942\u001b[0m        \u001b[36m0.6663\u001b[0m  0.0001  6.7904\n",
            "     16  0.5385       0.9071    0.3829        \u001b[31m0.8161\u001b[0m        \u001b[94m0.6909\u001b[0m        \u001b[36m0.6661\u001b[0m  0.0001  5.7971\n",
            "     17  0.5319       0.9077    0.3762        0.8163        0.6923        0.6663  0.0001  6.8169\n",
            "     18  0.5471       0.9061    0.3918        \u001b[31m0.8137\u001b[0m        \u001b[94m0.6903\u001b[0m        \u001b[36m0.6621\u001b[0m  0.0001  5.9760\n",
            "     19  0.5439       0.9067    0.3885        0.8143        \u001b[94m0.6889\u001b[0m        0.6631  0.0001  6.8449\n",
            "     20  0.5365       \u001b[32m0.9083\u001b[0m    0.3807        0.8143        \u001b[94m0.6882\u001b[0m        0.6632  0.0001  5.9969\n",
            "     21  0.5367       0.9080    0.3809        \u001b[31m0.8136\u001b[0m        \u001b[94m0.6876\u001b[0m        \u001b[36m0.6619\u001b[0m  0.0001  6.8246\n",
            "     22  0.5361       \u001b[32m0.9084\u001b[0m    0.3803        0.8137        \u001b[94m0.6870\u001b[0m        0.6620  0.0000  6.1628\n",
            "     23  0.5372       0.9081    0.3814        \u001b[31m0.8135\u001b[0m        \u001b[94m0.6861\u001b[0m        \u001b[36m0.6618\u001b[0m  0.0000  6.5320\n",
            "     24  0.5372       0.9083    0.3814        \u001b[31m0.8135\u001b[0m        0.6868        \u001b[36m0.6617\u001b[0m  0.0000  5.9586\n",
            "     25  0.5370       0.9084    0.3811        \u001b[31m0.8133\u001b[0m        \u001b[94m0.6843\u001b[0m        \u001b[36m0.6615\u001b[0m  0.0000  6.8302\n",
            "     26  0.5373       0.9083    0.3815        \u001b[31m0.8132\u001b[0m        0.6854        \u001b[36m0.6613\u001b[0m  0.0000  6.0940\n",
            "     27  0.5373       0.9081    0.3816        0.8132        0.6855        0.6613  0.0000  6.8820\n",
            "     28  0.5378       0.9080    0.3820        \u001b[31m0.8130\u001b[0m        \u001b[94m0.6842\u001b[0m        \u001b[36m0.6610\u001b[0m  0.0000  6.1133\n",
            "     29  0.5377       0.9080    0.3819        0.8130        0.6860        0.6610  0.0000  6.8903\n",
            "     30  0.5378       0.9079    0.3821        0.8130        0.6844        0.6610  0.0000  6.1153\n",
            "-1.108027497927348 {'lr': 0.01, 'module__dropout': 0.3, 'module__linear_size': 1000, 'module__size_emb': 120}\n"
          ]
        }
      ],
      "source": [
        "# params = {\n",
        "#     'lr': [0.001, 0.01],\n",
        "#     'module__size_emb': [30, 60, 120],\n",
        "#     'module__dropout': [0.5],\n",
        "#     'module__linear_size': [400, 500, 600]\n",
        "# }\n",
        "params = {\n",
        "    'lr': [0.01],\n",
        "    'module__size_emb': [60, 120],\n",
        "    'module__dropout': [0.3],\n",
        "    'module__linear_size': [500, 1000, 1500]\n",
        "}\n",
        "gs = GridSearchCV(deepnwidenet,\n",
        "                  params,\n",
        "                  verbose=50,\n",
        "                  refit=True,\n",
        "                  #pre_dispatch=8,\n",
        "                  n_jobs=1,\n",
        "                  cv=3,\n",
        "                  scoring='neg_mean_squared_error')\n",
        "\n",
        "X_ds = SliceDataset(train, idx=0)\n",
        "y_ds = SliceDataset(train, idx=1)\n",
        "gs.fit(X_ds, y_ds)\n",
        "\n",
        "print(gs.best_score_, gs.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ar3nvK6no1Z3",
        "outputId": "12539366-88da-4649-a4b0-e858c4cca4ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Re-initializing module because the following parameters were re-set: dropout, interact, linear_size, movies_emb, movies_ohe, size_emb, users_emb, users_ohe, y_range.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch      f1    precision    recall    rmse_score    train_loss    valid_loss      lr     dur\n",
            "-------  ------  -----------  --------  ------------  ------------  ------------  ------  ------\n",
            "      1  \u001b[36m0.5195\u001b[0m       \u001b[32m0.8302\u001b[0m    \u001b[35m0.3780\u001b[0m        \u001b[31m0.9388\u001b[0m        \u001b[94m1.0714\u001b[0m        \u001b[36m0.8814\u001b[0m  0.0100  4.1835\n",
            "      2  \u001b[36m0.6028\u001b[0m       0.8075    \u001b[35m0.4809\u001b[0m        0.9449        \u001b[94m0.8874\u001b[0m        0.8929  0.0100  4.2092\n",
            "      3  0.5556       0.8149    0.4215        \u001b[31m0.9366\u001b[0m        \u001b[94m0.8700\u001b[0m        \u001b[36m0.8773\u001b[0m  0.0100  3.6634\n",
            "      4  0.4168       \u001b[32m0.8626\u001b[0m    0.2748        \u001b[31m0.9334\u001b[0m        \u001b[94m0.8507\u001b[0m        \u001b[36m0.8712\u001b[0m  0.0100  3.8046\n",
            "      5  0.5149       0.8460    0.3701        \u001b[31m0.9274\u001b[0m        \u001b[94m0.8373\u001b[0m        \u001b[36m0.8601\u001b[0m  0.0100  4.1308\n",
            "      6  0.5223       0.8401    0.3789        0.9294        \u001b[94m0.8246\u001b[0m        0.8638  0.0100  3.8217\n",
            "      7  0.3150       \u001b[32m0.8847\u001b[0m    0.1916        0.9389        \u001b[94m0.8084\u001b[0m        0.8816  0.0100  3.6062\n",
            "      8  0.5431       0.8376    0.4018        \u001b[31m0.9213\u001b[0m        \u001b[94m0.7395\u001b[0m        \u001b[36m0.8488\u001b[0m  0.0010  4.3300\n",
            "      9  0.5370       0.8365    0.3955        0.9219        \u001b[94m0.7148\u001b[0m        0.8500  0.0010  3.6146\n",
            "     10  0.5470       0.8371    0.4062        0.9227        \u001b[94m0.7025\u001b[0m        0.8514  0.0010  4.5268\n",
            "     11  0.5638       0.8348    0.4256        0.9271        \u001b[94m0.6917\u001b[0m        0.8596  0.0010  4.2591\n",
            "     12  0.5326       0.8401    0.3899        0.9244        \u001b[94m0.6824\u001b[0m        0.8546  0.0010  3.5933\n",
            "     13  0.5529       0.8363    0.4130        0.9243        \u001b[94m0.6728\u001b[0m        0.8543  0.0010  3.7930\n",
            "     14  0.5421       0.8369    0.4009        0.9270        \u001b[94m0.6648\u001b[0m        0.8593  0.0010  4.3011\n",
            "     15  0.5474       0.8360    0.4069        0.9278        \u001b[94m0.6500\u001b[0m        0.8608  0.0001  3.7772\n",
            "     16  0.5485       0.8362    0.4081        0.9289        \u001b[94m0.6447\u001b[0m        0.8629  0.0001  3.8407\n",
            "     17  0.5446       0.8374    0.4035        0.9286        0.6464        0.8622  0.0001  4.1543\n",
            "Stopping since valid_loss has not improved in the last 10 epochs.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<class 'skorch.net.NeuralNet'>[initialized](\n",
              "  module_=deepnwide(\n",
              "    (emb_UserID): Embedding(943, 120)\n",
              "    (emb_Gender): Embedding(2, 120)\n",
              "    (emb_Age): Embedding(7, 120)\n",
              "    (emb_Occupation): Embedding(21, 120)\n",
              "    (emb_MovieID): Embedding(1682, 120)\n",
              "    (h1): Linear(in_features=600, out_features=1000, bias=True)\n",
              "    (h2): Linear(in_features=1000, out_features=1000, bias=True)\n",
              "    (h3): Linear(in_features=1000, out_features=1000, bias=True)\n",
              "    (dropout1): Dropout(p=0.3, inplace=False)\n",
              "    (dropout2): Dropout(p=0.3, inplace=False)\n",
              "    (dropout3): Dropout(p=0.3, inplace=False)\n",
              "    (last_layer): Linear(in_features=1345, out_features=1, bias=True)\n",
              "  ),\n",
              ")"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model = gs.best_estimator_\n",
        "best_model.fit(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LB0zzv5xzDEu"
      },
      "outputs": [],
      "source": [
        "#rating_predict = best_model.predict(valid_dataset)\n",
        "rating_predict = deepnwidenet.predict(valid_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "wg-1LVUHzHgS"
      },
      "outputs": [],
      "source": [
        "valid_users = valid_dataset[:][0][0][:,0].numpy()\n",
        "valid_movie = valid_dataset[:][0][0][:,3].numpy()\n",
        "valid_rating = valid_dataset[:][1].numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3ONIgVk0u0f"
      },
      "outputs": [],
      "source": [
        "valid_rating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "xeJKDQwRzMBH"
      },
      "outputs": [],
      "source": [
        "dct= {}\n",
        "for i in range(20000):\n",
        "    if valid_users[i] not in dct.keys():\n",
        "        dct[valid_users[i]]  = [(i, valid_movie[i], rating_predict[i], valid_rating[i])]\n",
        "    else:\n",
        "        dct[valid_users[i]].append((i, valid_movie[i], rating_predict[i], valid_rating[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0BqxiSHA2wH"
      },
      "outputs": [],
      "source": [
        "dct[725][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gqd4lMBCzPdE",
        "outputId": "6f1310f0-d848-43a8-8bb7-e455e2457a9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9144851657940664 0.7691176541141781\n"
          ]
        }
      ],
      "source": [
        "#calculate HR@10\n",
        "from sklearn.metrics import ndcg_score\n",
        "import math\n",
        "cnt_user = 0\n",
        "sum = 0\n",
        "ndcg = 0\n",
        "for key, value in dct.items():\n",
        "    if len(value) >= 10:\n",
        "        cnt_user += 1\n",
        "        cnt_movie = 0\n",
        "        value_rank_by_pred = sorted(value, reverse = True , key=lambda x: x[2]) # sort by pred\n",
        "        value_rank_by_label = sorted(value, reverse = True , key=lambda x: x[3]) # sort by label\n",
        "        ranked_label = [[item[3] for item in value_rank_by_label]]\n",
        "        ranked_pred = [[item[3] for item in value_rank_by_pred]]\n",
        "        dcg = 0\n",
        "        idcg = 0\n",
        "        for j in range(10):\n",
        "            if value_rank_by_pred[j][3] == 5:\n",
        "                sum += 1\n",
        "                break\n",
        "        for j in range(10):\n",
        "            dcg += (2**ranked_pred[0][j]-1)/(math.log2(j+2))\n",
        "            idcg += (2**ranked_label[0][j]-1)/(math.log2(j+2))\n",
        "        ndcg += dcg/idcg\n",
        "        #ndcg += ndcg_score(ranked_label, ranked_pred, k=10)\n",
        "        #ndcg += ndcg_at_k(ranked_pred, ranked_label, 10)\n",
        "hr = sum/cnt_user\n",
        "ndcg = ndcg/cnt_user\n",
        "print(hr, ndcg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Y-Z1LF7NgJH"
      },
      "source": [
        "### Two embeddings - Basic matrix factorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgHRNPN3NgJH"
      },
      "source": [
        "#### Manually specify hyperparamers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Y_9-m9v_3q03"
      },
      "outputs": [],
      "source": [
        "twoembedsnet = NeuralNet(\n",
        "    twoembeds,\n",
        "    module__size_emb=500,\n",
        "    module__y_range=train.y_range,\n",
        "    max_epochs=30,\n",
        "    lr=0.01,\n",
        "    optimizer=torch.optim.Adam,\n",
        "    criterion=torch.nn.MSELoss,\n",
        "    device=device,\n",
        "    iterator_train__batch_size=4096,\n",
        "    iterator_train__num_workers=0,\n",
        "    iterator_train__shuffle=True,\n",
        "    iterator_valid__batch_size=4096,\n",
        "    train_split=predefined_split(valid_dataset),\n",
        "    callbacks=[earlystopping,\n",
        "               epoch_rmse,\n",
        "               epoch_precision,\n",
        "               epoch_recall,\n",
        "               epoch_f1,\n",
        "               #checkpoint,\n",
        "               lr_scheduler]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9B_Z4LA6CPL",
        "outputId": "bee95548-8b7d-4ae5-d1b6-b5da052276d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch      f1    precision    recall    rmse_score    train_loss    valid_loss      lr     dur\n",
            "-------  ------  -----------  --------  ------------  ------------  ------------  ------  ------\n",
            "      1  \u001b[36m0.6073\u001b[0m       \u001b[32m0.7948\u001b[0m    \u001b[35m0.4914\u001b[0m        \u001b[31m0.9753\u001b[0m        \u001b[94m1.2419\u001b[0m        \u001b[36m0.9512\u001b[0m  0.0100  4.1760\n",
            "      2  0.4658       \u001b[32m0.8719\u001b[0m    0.3178        \u001b[31m0.9309\u001b[0m        \u001b[94m0.6232\u001b[0m        \u001b[36m0.8665\u001b[0m  0.0100  3.1107\n",
            "      3  0.5314       0.8394    0.3887        0.9445        \u001b[94m0.2534\u001b[0m        0.8921  0.0100  3.1655\n",
            "      4  0.5495       0.8286    0.4111        0.9556        \u001b[94m0.1141\u001b[0m        0.9131  0.0100  3.1317\n",
            "      5  0.5524       0.8302    0.4139        0.9595        \u001b[94m0.0713\u001b[0m        0.9206  0.0100  3.9620\n",
            "      6  0.5625       0.8242    0.4269        0.9623        \u001b[94m0.0561\u001b[0m        0.9261  0.0100  3.2080\n",
            "      7  0.5644       0.8228    0.4295        0.9674        \u001b[94m0.0527\u001b[0m        0.9358  0.0100  2.8956\n",
            "      8  0.5650       0.8234    0.4300        0.9658        \u001b[94m0.0431\u001b[0m        0.9328  0.0010  3.3355\n",
            "      9  0.5652       0.8239    0.4302        0.9644        \u001b[94m0.0296\u001b[0m        0.9301  0.0010  3.7319\n",
            "     10  0.5672       0.8238    0.4325        0.9643        \u001b[94m0.0210\u001b[0m        0.9299  0.0010  3.0904\n",
            "     11  0.5691       0.8237    0.4347        0.9647        \u001b[94m0.0170\u001b[0m        0.9306  0.0010  3.1469\n",
            "Stopping since valid_loss has not improved in the last 10 epochs.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'skorch.net.NeuralNet'>[initialized](\n",
              "  module_=twoembeds(\n",
              "    (emb_UserID): Embedding(943, 500)\n",
              "    (emb_MovieID): Embedding(1682, 500)\n",
              "    (emb_UserID_b): Embedding(943, 1)\n",
              "    (emb_MovieID_b): Embedding(1682, 1)\n",
              "  ),\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "twoembedsnet.fit(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYKYPBLLBVxN"
      },
      "outputs": [],
      "source": [
        "torch.save(twoembedsnet.module_.state_dict(), 'GMF.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhyfVP2lNgJI"
      },
      "source": [
        "#### GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2QlpxyRTx7b",
        "outputId": "dbdc6fbf-f265-430a-b63f-da6018f44c7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[CV 1/3; 1/1] START lr=0.01, module__size_emb=500...............................\n",
            "  epoch      f1    precision    recall    rmse_score    train_loss    valid_loss      lr     dur\n",
            "-------  ------  -----------  --------  ------------  ------------  ------------  ------  ------\n",
            "      1  \u001b[36m0.5349\u001b[0m       \u001b[32m0.8186\u001b[0m    \u001b[35m0.3972\u001b[0m        \u001b[31m0.9922\u001b[0m        \u001b[94m1.2497\u001b[0m        \u001b[36m0.9846\u001b[0m  0.0100  3.9989\n",
            "      2  0.4981       \u001b[32m0.9545\u001b[0m    0.3370        \u001b[31m0.8469\u001b[0m        \u001b[94m0.6804\u001b[0m        \u001b[36m0.7173\u001b[0m  0.0100  4.1132\n",
            "      3  \u001b[36m0.6667\u001b[0m       \u001b[32m0.9865\u001b[0m    \u001b[35m0.5035\u001b[0m        \u001b[31m0.7497\u001b[0m        \u001b[94m0.3272\u001b[0m        \u001b[36m0.5621\u001b[0m  0.0100  4.7773\n",
            "      4  \u001b[36m0.7077\u001b[0m       \u001b[32m0.9964\u001b[0m    \u001b[35m0.5488\u001b[0m        \u001b[31m0.7136\u001b[0m        \u001b[94m0.1508\u001b[0m        \u001b[36m0.5092\u001b[0m  0.0100  4.2700\n",
            "      5  0.7063       \u001b[32m0.9978\u001b[0m    0.5466        \u001b[31m0.6989\u001b[0m        \u001b[94m0.0878\u001b[0m        \u001b[36m0.4885\u001b[0m  0.0100  4.2813\n",
            "      6  0.7001       \u001b[32m0.9988\u001b[0m    0.5389        \u001b[31m0.6915\u001b[0m        \u001b[94m0.0615\u001b[0m        \u001b[36m0.4782\u001b[0m  0.0100  4.5627\n",
            "      7  0.6831       \u001b[32m0.9990\u001b[0m    0.5190        \u001b[31m0.6885\u001b[0m        \u001b[94m0.0493\u001b[0m        \u001b[36m0.4740\u001b[0m  0.0100  4.0036\n",
            "      8  0.6890       \u001b[32m0.9990\u001b[0m    0.5258        \u001b[31m0.6861\u001b[0m        \u001b[94m0.0349\u001b[0m        \u001b[36m0.4707\u001b[0m  0.0010  4.4684\n",
            "      9  0.7004       \u001b[32m0.9992\u001b[0m    0.5392        \u001b[31m0.6833\u001b[0m        \u001b[94m0.0281\u001b[0m        \u001b[36m0.4669\u001b[0m  0.0010  4.6202\n",
            "     10  0.7074       \u001b[32m0.9993\u001b[0m    0.5474        \u001b[31m0.6818\u001b[0m        \u001b[94m0.0232\u001b[0m        \u001b[36m0.4649\u001b[0m  0.0010  3.9528\n",
            "     11  \u001b[36m0.7119\u001b[0m       \u001b[32m0.9997\u001b[0m    \u001b[35m0.5528\u001b[0m        \u001b[31m0.6809\u001b[0m        \u001b[94m0.0204\u001b[0m        \u001b[36m0.4636\u001b[0m  0.0010  4.6811\n",
            "     12  \u001b[36m0.7168\u001b[0m       \u001b[32m0.9997\u001b[0m    \u001b[35m0.5587\u001b[0m        \u001b[31m0.6802\u001b[0m        \u001b[94m0.0186\u001b[0m        \u001b[36m0.4627\u001b[0m  0.0010  4.1799\n",
            "     13  \u001b[36m0.7190\u001b[0m       \u001b[32m0.9997\u001b[0m    \u001b[35m0.5614\u001b[0m        \u001b[31m0.6797\u001b[0m        \u001b[94m0.0173\u001b[0m        \u001b[36m0.4619\u001b[0m  0.0010  4.3425\n",
            "     14  \u001b[36m0.7223\u001b[0m       \u001b[32m0.9997\u001b[0m    \u001b[35m0.5654\u001b[0m        \u001b[31m0.6792\u001b[0m        \u001b[94m0.0162\u001b[0m        \u001b[36m0.4613\u001b[0m  0.0010  4.8650\n",
            "     15  0.7221       0.9997    0.5652        \u001b[31m0.6791\u001b[0m        \u001b[94m0.0154\u001b[0m        \u001b[36m0.4612\u001b[0m  0.0001  4.1144\n",
            "     16  \u001b[36m0.7224\u001b[0m       \u001b[32m0.9997\u001b[0m    \u001b[35m0.5656\u001b[0m        \u001b[31m0.6791\u001b[0m        \u001b[94m0.0153\u001b[0m        \u001b[36m0.4612\u001b[0m  0.0001  4.1145\n",
            "     17  \u001b[36m0.7225\u001b[0m       \u001b[32m0.9997\u001b[0m    \u001b[35m0.5657\u001b[0m        \u001b[31m0.6790\u001b[0m        \u001b[94m0.0152\u001b[0m        \u001b[36m0.4611\u001b[0m  0.0001  5.2351\n",
            "     18  \u001b[36m0.7235\u001b[0m       \u001b[32m0.9997\u001b[0m    \u001b[35m0.5669\u001b[0m        \u001b[31m0.6790\u001b[0m        \u001b[94m0.0151\u001b[0m        \u001b[36m0.4610\u001b[0m  0.0001  4.1700\n",
            "     19  \u001b[36m0.7245\u001b[0m       \u001b[32m0.9997\u001b[0m    \u001b[35m0.5681\u001b[0m        \u001b[31m0.6789\u001b[0m        \u001b[94m0.0150\u001b[0m        \u001b[36m0.4610\u001b[0m  0.0001  4.0579\n",
            "     20  \u001b[36m0.7249\u001b[0m       \u001b[32m0.9997\u001b[0m    \u001b[35m0.5686\u001b[0m        \u001b[31m0.6789\u001b[0m        \u001b[94m0.0149\u001b[0m        \u001b[36m0.4609\u001b[0m  0.0001  4.8937\n",
            "     21  \u001b[36m0.7252\u001b[0m       \u001b[32m0.9997\u001b[0m    \u001b[35m0.5690\u001b[0m        \u001b[31m0.6788\u001b[0m        \u001b[94m0.0148\u001b[0m        \u001b[36m0.4608\u001b[0m  0.0001  4.3178\n",
            "     22  \u001b[36m0.7253\u001b[0m       \u001b[32m0.9997\u001b[0m    \u001b[35m0.5691\u001b[0m        \u001b[31m0.6788\u001b[0m        \u001b[94m0.0147\u001b[0m        \u001b[36m0.4608\u001b[0m  0.0000  4.1744\n",
            "     23  \u001b[36m0.7255\u001b[0m       \u001b[32m0.9997\u001b[0m    \u001b[35m0.5694\u001b[0m        \u001b[31m0.6788\u001b[0m        \u001b[94m0.0147\u001b[0m        \u001b[36m0.4608\u001b[0m  0.0000  4.7909\n",
            "Stopping since valid_loss has not improved in the last 10 epochs.\n",
            "[CV 1/3; 1/1] END lr=0.01, module__size_emb=500;, score=-1.386 total time= 1.8min\n",
            "[CV 2/3; 1/1] START lr=0.01, module__size_emb=500...............................\n",
            "  epoch      f1    precision    recall    rmse_score    train_loss    valid_loss      lr     dur\n",
            "-------  ------  -----------  --------  ------------  ------------  ------------  ------  ------\n",
            "      1  \u001b[36m0.4976\u001b[0m       \u001b[32m0.8315\u001b[0m    \u001b[35m0.3550\u001b[0m        \u001b[31m0.9875\u001b[0m        \u001b[94m1.2856\u001b[0m        \u001b[36m0.9751\u001b[0m  0.0100  5.0544\n",
            "      2  0.4935       \u001b[32m0.9596\u001b[0m    0.3322        \u001b[31m0.8338\u001b[0m        \u001b[94m0.6728\u001b[0m        \u001b[36m0.6953\u001b[0m  0.0100  3.9288\n",
            "      3  \u001b[36m0.6415\u001b[0m       \u001b[32m0.9862\u001b[0m    \u001b[35m0.4754\u001b[0m        \u001b[31m0.7429\u001b[0m        \u001b[94m0.3108\u001b[0m        \u001b[36m0.5519\u001b[0m  0.0100  4.0406\n",
            "      4  \u001b[36m0.6798\u001b[0m       \u001b[32m0.9956\u001b[0m    \u001b[35m0.5161\u001b[0m        \u001b[31m0.7093\u001b[0m        \u001b[94m0.1434\u001b[0m        \u001b[36m0.5031\u001b[0m  0.0100  5.0643\n",
            "      5  0.6757       \u001b[32m0.9963\u001b[0m    0.5112        \u001b[31m0.6964\u001b[0m        \u001b[94m0.0846\u001b[0m        \u001b[36m0.4850\u001b[0m  0.0100  4.0408\n",
            "      6  0.6681       \u001b[32m0.9978\u001b[0m    0.5022        \u001b[31m0.6889\u001b[0m        \u001b[94m0.0604\u001b[0m        \u001b[36m0.4746\u001b[0m  0.0100  3.9853\n",
            "      7  0.6614       0.9978    0.4946        \u001b[31m0.6859\u001b[0m        \u001b[94m0.0485\u001b[0m        \u001b[36m0.4704\u001b[0m  0.0100  5.0008\n",
            "      8  0.6664       \u001b[32m0.9982\u001b[0m    0.5002        \u001b[31m0.6835\u001b[0m        \u001b[94m0.0347\u001b[0m        \u001b[36m0.4672\u001b[0m  0.0010  4.0438\n",
            "      9  0.6731       \u001b[32m0.9986\u001b[0m    0.5076        \u001b[31m0.6806\u001b[0m        \u001b[94m0.0278\u001b[0m        \u001b[36m0.4632\u001b[0m  0.0010  3.9873\n",
            "     10  \u001b[36m0.6806\u001b[0m       \u001b[32m0.9991\u001b[0m    0.5161        \u001b[31m0.6789\u001b[0m        \u001b[94m0.0227\u001b[0m        \u001b[36m0.4609\u001b[0m  0.0010  5.1369\n",
            "     11  \u001b[36m0.6849\u001b[0m       \u001b[32m0.9991\u001b[0m    \u001b[35m0.5211\u001b[0m        \u001b[31m0.6779\u001b[0m        \u001b[94m0.0198\u001b[0m        \u001b[36m0.4595\u001b[0m  0.0010  4.0181\n",
            "     12  \u001b[36m0.6878\u001b[0m       \u001b[32m0.9993\u001b[0m    \u001b[35m0.5243\u001b[0m        \u001b[31m0.6772\u001b[0m        \u001b[94m0.0180\u001b[0m        \u001b[36m0.4586\u001b[0m  0.0010  4.2198\n",
            "     13  \u001b[36m0.6925\u001b[0m       \u001b[32m0.9997\u001b[0m    \u001b[35m0.5297\u001b[0m        \u001b[31m0.6766\u001b[0m        \u001b[94m0.0166\u001b[0m        \u001b[36m0.4578\u001b[0m  0.0010  4.6832\n",
            "     14  \u001b[36m0.6946\u001b[0m       \u001b[32m0.9997\u001b[0m    \u001b[35m0.5322\u001b[0m        \u001b[31m0.6761\u001b[0m        \u001b[94m0.0155\u001b[0m        \u001b[36m0.4571\u001b[0m  0.0010  4.0690\n",
            "     15  \u001b[36m0.6948\u001b[0m       \u001b[32m0.9997\u001b[0m    \u001b[35m0.5324\u001b[0m        \u001b[31m0.6761\u001b[0m        \u001b[94m0.0147\u001b[0m        \u001b[36m0.4571\u001b[0m  0.0001  4.8690\n",
            "     16  \u001b[36m0.6958\u001b[0m       \u001b[32m0.9997\u001b[0m    \u001b[35m0.5336\u001b[0m        \u001b[31m0.6760\u001b[0m        \u001b[94m0.0146\u001b[0m        \u001b[36m0.4570\u001b[0m  0.0001  5.3271\n",
            "     17  \u001b[36m0.6967\u001b[0m       \u001b[32m0.9997\u001b[0m    \u001b[35m0.5347\u001b[0m        \u001b[31m0.6760\u001b[0m        \u001b[94m0.0145\u001b[0m        \u001b[36m0.4569\u001b[0m  0.0001  3.9644\n",
            "     18  \u001b[36m0.6970\u001b[0m       \u001b[32m0.9997\u001b[0m    \u001b[35m0.5351\u001b[0m        \u001b[31m0.6759\u001b[0m        \u001b[94m0.0144\u001b[0m        \u001b[36m0.4569\u001b[0m  0.0001  3.9419\n",
            "     19  \u001b[36m0.6979\u001b[0m       \u001b[32m0.9997\u001b[0m    \u001b[35m0.5361\u001b[0m        \u001b[31m0.6759\u001b[0m        \u001b[94m0.0143\u001b[0m        \u001b[36m0.4568\u001b[0m  0.0001  4.8355\n",
            "     20  \u001b[36m0.6983\u001b[0m       \u001b[32m0.9997\u001b[0m    \u001b[35m0.5366\u001b[0m        \u001b[31m0.6758\u001b[0m        \u001b[94m0.0142\u001b[0m        \u001b[36m0.4568\u001b[0m  0.0001  4.3386\n",
            "     21  \u001b[36m0.6985\u001b[0m       \u001b[32m0.9997\u001b[0m    \u001b[35m0.5368\u001b[0m        \u001b[31m0.6758\u001b[0m        \u001b[94m0.0141\u001b[0m        \u001b[36m0.4567\u001b[0m  0.0001  4.5292\n",
            "     22  \u001b[36m0.6986\u001b[0m       \u001b[32m0.9997\u001b[0m    \u001b[35m0.5369\u001b[0m        \u001b[31m0.6758\u001b[0m        \u001b[94m0.0141\u001b[0m        \u001b[36m0.4567\u001b[0m  0.0000  4.5442\n",
            "     23  \u001b[36m0.6987\u001b[0m       \u001b[32m0.9997\u001b[0m    \u001b[35m0.5370\u001b[0m        \u001b[31m0.6758\u001b[0m        \u001b[94m0.0141\u001b[0m        \u001b[36m0.4567\u001b[0m  0.0000  4.0990\n",
            "     24  0.6987       0.9997    0.5370        \u001b[31m0.6758\u001b[0m        \u001b[94m0.0140\u001b[0m        \u001b[36m0.4567\u001b[0m  0.0000  4.5878\n",
            "     25  \u001b[36m0.6987\u001b[0m       \u001b[32m0.9997\u001b[0m    \u001b[35m0.5371\u001b[0m        \u001b[31m0.6758\u001b[0m        \u001b[94m0.0140\u001b[0m        \u001b[36m0.4567\u001b[0m  0.0000  4.4562\n",
            "     26  \u001b[36m0.6990\u001b[0m       \u001b[32m0.9997\u001b[0m    \u001b[35m0.5373\u001b[0m        \u001b[31m0.6758\u001b[0m        \u001b[94m0.0140\u001b[0m        \u001b[36m0.4567\u001b[0m  0.0000  3.9373\n",
            "     27  0.6989       0.9997    0.5372        \u001b[31m0.6758\u001b[0m        \u001b[94m0.0140\u001b[0m        \u001b[36m0.4566\u001b[0m  0.0000  4.8042\n",
            "     28  0.6989       0.9997    0.5372        \u001b[31m0.6758\u001b[0m        \u001b[94m0.0140\u001b[0m        \u001b[36m0.4566\u001b[0m  0.0000  4.1717\n",
            "     29  0.6989       0.9997    0.5372        \u001b[31m0.6757\u001b[0m        \u001b[94m0.0140\u001b[0m        \u001b[36m0.4566\u001b[0m  0.0000  4.3106\n",
            "     30  0.6990       0.9997    0.5373        \u001b[31m0.6757\u001b[0m        \u001b[94m0.0140\u001b[0m        \u001b[36m0.4566\u001b[0m  0.0000  4.7830\n",
            "[CV 2/3; 1/1] END lr=0.01, module__size_emb=500;, score=-1.330 total time= 2.3min\n",
            "[CV 3/3; 1/1] START lr=0.01, module__size_emb=500...............................\n",
            "  epoch      f1    precision    recall    rmse_score    train_loss    valid_loss      lr     dur\n",
            "-------  ------  -----------  --------  ------------  ------------  ------------  ------  ------\n",
            "      1  \u001b[36m0.5151\u001b[0m       \u001b[32m0.8211\u001b[0m    \u001b[35m0.3753\u001b[0m        \u001b[31m0.9970\u001b[0m        \u001b[94m1.2504\u001b[0m        \u001b[36m0.9941\u001b[0m  0.0100  4.0776\n",
            "      2  0.4728       \u001b[32m0.9514\u001b[0m    0.3145        \u001b[31m0.8469\u001b[0m        \u001b[94m0.6659\u001b[0m        \u001b[36m0.7172\u001b[0m  0.0100  4.6066\n",
            "      3  \u001b[36m0.6326\u001b[0m       \u001b[32m0.9839\u001b[0m    \u001b[35m0.4661\u001b[0m        \u001b[31m0.7540\u001b[0m        \u001b[94m0.3222\u001b[0m        \u001b[36m0.5685\u001b[0m  0.0100  4.4813\n",
            "      4  \u001b[36m0.6663\u001b[0m       \u001b[32m0.9949\u001b[0m    \u001b[35m0.5009\u001b[0m        \u001b[31m0.7172\u001b[0m        \u001b[94m0.1540\u001b[0m        \u001b[36m0.5144\u001b[0m  0.0100  4.1759\n",
            "      5  \u001b[36m0.6736\u001b[0m       \u001b[32m0.9980\u001b[0m    \u001b[35m0.5084\u001b[0m        \u001b[31m0.7024\u001b[0m        \u001b[94m0.0908\u001b[0m        \u001b[36m0.4934\u001b[0m  0.0100  4.5707\n",
            "      6  0.6648       0.9975    0.4985        \u001b[31m0.6953\u001b[0m        \u001b[94m0.0640\u001b[0m        \u001b[36m0.4834\u001b[0m  0.0100  4.6479\n",
            "      7  0.6545       0.9968    0.4872        \u001b[31m0.6922\u001b[0m        \u001b[94m0.0506\u001b[0m        \u001b[36m0.4791\u001b[0m  0.0100  4.1505\n",
            "      8  0.6611       0.9978    0.4943        \u001b[31m0.6895\u001b[0m        \u001b[94m0.0365\u001b[0m        \u001b[36m0.4754\u001b[0m  0.0010  4.8303\n",
            "      9  0.6713       \u001b[32m0.9984\u001b[0m    0.5056        \u001b[31m0.6865\u001b[0m        \u001b[94m0.0294\u001b[0m        \u001b[36m0.4712\u001b[0m  0.0010  3.9972\n",
            "     10  \u001b[36m0.6752\u001b[0m       \u001b[32m0.9984\u001b[0m    \u001b[35m0.5101\u001b[0m        \u001b[31m0.6848\u001b[0m        \u001b[94m0.0245\u001b[0m        \u001b[36m0.4689\u001b[0m  0.0010  4.2914\n",
            "     11  \u001b[36m0.6789\u001b[0m       \u001b[32m0.9984\u001b[0m    \u001b[35m0.5143\u001b[0m        \u001b[31m0.6838\u001b[0m        \u001b[94m0.0217\u001b[0m        \u001b[36m0.4675\u001b[0m  0.0010  4.8237\n",
            "     12  \u001b[36m0.6815\u001b[0m       \u001b[32m0.9986\u001b[0m    \u001b[35m0.5173\u001b[0m        \u001b[31m0.6830\u001b[0m        \u001b[94m0.0198\u001b[0m        \u001b[36m0.4664\u001b[0m  0.0010  4.0034\n",
            "     13  \u001b[36m0.6850\u001b[0m       \u001b[32m0.9990\u001b[0m    \u001b[35m0.5212\u001b[0m        \u001b[31m0.6823\u001b[0m        \u001b[94m0.0184\u001b[0m        \u001b[36m0.4655\u001b[0m  0.0010  3.9398\n",
            "     14  \u001b[36m0.6878\u001b[0m       \u001b[32m0.9990\u001b[0m    \u001b[35m0.5244\u001b[0m        \u001b[31m0.6817\u001b[0m        \u001b[94m0.0172\u001b[0m        \u001b[36m0.4647\u001b[0m  0.0010  5.1195\n",
            "     15  \u001b[36m0.6879\u001b[0m       \u001b[32m0.9990\u001b[0m    \u001b[35m0.5245\u001b[0m        \u001b[31m0.6816\u001b[0m        \u001b[94m0.0163\u001b[0m        \u001b[36m0.4646\u001b[0m  0.0001  4.0848\n",
            "     16  \u001b[36m0.6881\u001b[0m       \u001b[32m0.9991\u001b[0m    \u001b[35m0.5248\u001b[0m        \u001b[31m0.6816\u001b[0m        \u001b[94m0.0162\u001b[0m        \u001b[36m0.4646\u001b[0m  0.0001  3.9599\n",
            "     17  \u001b[36m0.6884\u001b[0m       \u001b[32m0.9993\u001b[0m    \u001b[35m0.5251\u001b[0m        \u001b[31m0.6815\u001b[0m        \u001b[94m0.0161\u001b[0m        \u001b[36m0.4645\u001b[0m  0.0001  4.7949\n",
            "     18  \u001b[36m0.6892\u001b[0m       \u001b[32m0.9993\u001b[0m    \u001b[35m0.5260\u001b[0m        \u001b[31m0.6815\u001b[0m        \u001b[94m0.0160\u001b[0m        \u001b[36m0.4644\u001b[0m  0.0001  4.4210\n",
            "     19  \u001b[36m0.6894\u001b[0m       \u001b[32m0.9993\u001b[0m    \u001b[35m0.5262\u001b[0m        \u001b[31m0.6814\u001b[0m        \u001b[94m0.0159\u001b[0m        \u001b[36m0.4644\u001b[0m  0.0001  3.9933\n",
            "     20  \u001b[36m0.6897\u001b[0m       \u001b[32m0.9993\u001b[0m    \u001b[35m0.5265\u001b[0m        \u001b[31m0.6814\u001b[0m        \u001b[94m0.0157\u001b[0m        \u001b[36m0.4643\u001b[0m  0.0001  4.8077\n",
            "     21  \u001b[36m0.6903\u001b[0m       \u001b[32m0.9993\u001b[0m    \u001b[35m0.5272\u001b[0m        \u001b[31m0.6813\u001b[0m        \u001b[94m0.0156\u001b[0m        \u001b[36m0.4642\u001b[0m  0.0001  4.1737\n",
            "     22  0.6903       0.9993    0.5272        \u001b[31m0.6813\u001b[0m        \u001b[94m0.0155\u001b[0m        \u001b[36m0.4642\u001b[0m  0.0000  4.5626\n",
            "     23  \u001b[36m0.6904\u001b[0m       \u001b[32m0.9993\u001b[0m    \u001b[35m0.5273\u001b[0m        \u001b[31m0.6813\u001b[0m        \u001b[94m0.0155\u001b[0m        \u001b[36m0.4642\u001b[0m  0.0000  4.5527\n",
            "     24  0.6904       0.9993    0.5273        \u001b[31m0.6813\u001b[0m        \u001b[94m0.0155\u001b[0m        \u001b[36m0.4642\u001b[0m  0.0000  4.0561\n",
            "     25  0.6904       0.9993    0.5273        \u001b[31m0.6813\u001b[0m        \u001b[94m0.0155\u001b[0m        \u001b[36m0.4642\u001b[0m  0.0000  4.6455\n",
            "     26  0.6904       0.9993    0.5273        \u001b[31m0.6813\u001b[0m        \u001b[94m0.0155\u001b[0m        \u001b[36m0.4642\u001b[0m  0.0000  4.4705\n",
            "     27  \u001b[36m0.6905\u001b[0m       \u001b[32m0.9993\u001b[0m    \u001b[35m0.5275\u001b[0m        \u001b[31m0.6813\u001b[0m        \u001b[94m0.0155\u001b[0m        \u001b[36m0.4641\u001b[0m  0.0000  4.1331\n",
            "     28  0.6904       0.9993    0.5274        \u001b[31m0.6813\u001b[0m        \u001b[94m0.0155\u001b[0m        \u001b[36m0.4641\u001b[0m  0.0000  4.5978\n",
            "     29  0.6904       0.9993    0.5274        \u001b[31m0.6813\u001b[0m        \u001b[94m0.0155\u001b[0m        \u001b[36m0.4641\u001b[0m  0.0000  4.3493\n",
            "     30  0.6904       0.9993    0.5274        \u001b[31m0.6813\u001b[0m        \u001b[94m0.0155\u001b[0m        \u001b[36m0.4641\u001b[0m  0.0000  4.0221\n",
            "[CV 3/3; 1/1] END lr=0.01, module__size_emb=500;, score=-1.384 total time= 2.2min\n",
            "  epoch      f1    precision    recall    rmse_score    train_loss    valid_loss      lr     dur\n",
            "-------  ------  -----------  --------  ------------  ------------  ------------  ------  ------\n",
            "      1  \u001b[36m0.6637\u001b[0m       \u001b[32m0.8612\u001b[0m    \u001b[35m0.5399\u001b[0m        \u001b[31m0.8278\u001b[0m        \u001b[94m1.1850\u001b[0m        \u001b[36m0.6853\u001b[0m  0.0100  6.7259\n",
            "      2  \u001b[36m0.7536\u001b[0m       \u001b[32m0.9678\u001b[0m    \u001b[35m0.6170\u001b[0m        \u001b[31m0.5201\u001b[0m        \u001b[94m0.5739\u001b[0m        \u001b[36m0.2706\u001b[0m  0.0100  6.3596\n",
            "      3  \u001b[36m0.8637\u001b[0m       \u001b[32m0.9921\u001b[0m    \u001b[35m0.7648\u001b[0m        \u001b[31m0.3363\u001b[0m        \u001b[94m0.2363\u001b[0m        \u001b[36m0.1131\u001b[0m  0.0100  6.7090\n",
            "      4  \u001b[36m0.8775\u001b[0m       \u001b[32m0.9962\u001b[0m    \u001b[35m0.7841\u001b[0m        \u001b[31m0.2662\u001b[0m        \u001b[94m0.1132\u001b[0m        \u001b[36m0.0709\u001b[0m  0.0100  6.2076\n",
            "      5  0.8671       0.9953    0.7681        \u001b[31m0.2412\u001b[0m        \u001b[94m0.0776\u001b[0m        \u001b[36m0.0582\u001b[0m  0.0100  6.6544\n",
            "      6  0.8571       0.9951    0.7528        \u001b[31m0.2378\u001b[0m        \u001b[94m0.0680\u001b[0m        \u001b[36m0.0565\u001b[0m  0.0100  6.6325\n",
            "      7  0.8388       0.9928    0.7262        0.2449        0.0687        0.0600  0.0100  6.6545\n",
            "      8  0.8497       \u001b[32m0.9966\u001b[0m    0.7405        \u001b[31m0.2106\u001b[0m        \u001b[94m0.0585\u001b[0m        \u001b[36m0.0443\u001b[0m  0.0010  6.2606\n",
            "      9  0.8594       \u001b[32m0.9984\u001b[0m    0.7543        \u001b[31m0.1723\u001b[0m        \u001b[94m0.0391\u001b[0m        \u001b[36m0.0297\u001b[0m  0.0010  6.4311\n",
            "     10  0.8674       \u001b[32m0.9994\u001b[0m    0.7661        \u001b[31m0.1499\u001b[0m        \u001b[94m0.0273\u001b[0m        \u001b[36m0.0225\u001b[0m  0.0010  6.2563\n",
            "     11  0.8712       \u001b[32m0.9995\u001b[0m    0.7720        \u001b[31m0.1364\u001b[0m        \u001b[94m0.0213\u001b[0m        \u001b[36m0.0186\u001b[0m  0.0010  6.3720\n",
            "     12  0.8774       \u001b[32m0.9997\u001b[0m    0.7818        \u001b[31m0.1275\u001b[0m        \u001b[94m0.0180\u001b[0m        \u001b[36m0.0162\u001b[0m  0.0010  6.1883\n",
            "     13  \u001b[36m0.8837\u001b[0m       \u001b[32m0.9997\u001b[0m    \u001b[35m0.7919\u001b[0m        \u001b[31m0.1211\u001b[0m        \u001b[94m0.0160\u001b[0m        \u001b[36m0.0147\u001b[0m  0.0010  6.3884\n",
            "     14  \u001b[36m0.8898\u001b[0m       \u001b[32m0.9997\u001b[0m    \u001b[35m0.8017\u001b[0m        \u001b[31m0.1161\u001b[0m        \u001b[94m0.0145\u001b[0m        \u001b[36m0.0135\u001b[0m  0.0010  6.2235\n",
            "     15  \u001b[36m0.8907\u001b[0m       \u001b[32m0.9997\u001b[0m    \u001b[35m0.8031\u001b[0m        \u001b[31m0.1156\u001b[0m        \u001b[94m0.0136\u001b[0m        \u001b[36m0.0134\u001b[0m  0.0001  6.5474\n",
            "     16  \u001b[36m0.8912\u001b[0m       \u001b[32m0.9997\u001b[0m    \u001b[35m0.8039\u001b[0m        \u001b[31m0.1152\u001b[0m        \u001b[94m0.0135\u001b[0m        \u001b[36m0.0133\u001b[0m  0.0001  6.2960\n",
            "     17  \u001b[36m0.8923\u001b[0m       \u001b[32m0.9997\u001b[0m    \u001b[35m0.8057\u001b[0m        \u001b[31m0.1147\u001b[0m        \u001b[94m0.0134\u001b[0m        \u001b[36m0.0132\u001b[0m  0.0001  6.4286\n",
            "     18  \u001b[36m0.8941\u001b[0m       \u001b[32m0.9997\u001b[0m    \u001b[35m0.8087\u001b[0m        \u001b[31m0.1142\u001b[0m        \u001b[94m0.0133\u001b[0m        \u001b[36m0.0131\u001b[0m  0.0001  6.2925\n",
            "     19  \u001b[36m0.8949\u001b[0m       \u001b[32m0.9997\u001b[0m    \u001b[35m0.8101\u001b[0m        \u001b[31m0.1137\u001b[0m        \u001b[94m0.0132\u001b[0m        \u001b[36m0.0129\u001b[0m  0.0001  6.5213\n",
            "     20  \u001b[36m0.8959\u001b[0m       \u001b[32m0.9998\u001b[0m    \u001b[35m0.8116\u001b[0m        \u001b[31m0.1133\u001b[0m        \u001b[94m0.0131\u001b[0m        \u001b[36m0.0128\u001b[0m  0.0001  6.4337\n",
            "     21  \u001b[36m0.8970\u001b[0m       \u001b[32m0.9999\u001b[0m    \u001b[35m0.8133\u001b[0m        \u001b[31m0.1128\u001b[0m        \u001b[94m0.0129\u001b[0m        \u001b[36m0.0127\u001b[0m  0.0001  6.3429\n",
            "     22  \u001b[36m0.8971\u001b[0m       \u001b[32m0.9999\u001b[0m    \u001b[35m0.8134\u001b[0m        \u001b[31m0.1127\u001b[0m        \u001b[94m0.0129\u001b[0m        \u001b[36m0.0127\u001b[0m  0.0000  6.3255\n",
            "     23  0.8971       0.9999    0.8134        \u001b[31m0.1127\u001b[0m        \u001b[94m0.0128\u001b[0m        \u001b[36m0.0127\u001b[0m  0.0000  6.7826\n",
            "     24  0.8970       0.9999    0.8134        \u001b[31m0.1126\u001b[0m        \u001b[94m0.0128\u001b[0m        \u001b[36m0.0127\u001b[0m  0.0000  6.0442\n",
            "     25  0.8971       0.9999    0.8134        \u001b[31m0.1126\u001b[0m        \u001b[94m0.0128\u001b[0m        \u001b[36m0.0127\u001b[0m  0.0000  6.6849\n",
            "     26  0.8971       0.9999    0.8134        \u001b[31m0.1125\u001b[0m        \u001b[94m0.0128\u001b[0m        \u001b[36m0.0127\u001b[0m  0.0000  6.1308\n",
            "     27  \u001b[36m0.8972\u001b[0m       \u001b[32m0.9999\u001b[0m    \u001b[35m0.8136\u001b[0m        \u001b[31m0.1125\u001b[0m        \u001b[94m0.0128\u001b[0m        \u001b[36m0.0127\u001b[0m  0.0000  6.2248\n",
            "     28  \u001b[36m0.8972\u001b[0m       \u001b[32m0.9999\u001b[0m    \u001b[35m0.8137\u001b[0m        \u001b[31m0.1124\u001b[0m        \u001b[94m0.0128\u001b[0m        \u001b[36m0.0126\u001b[0m  0.0000  6.4020\n",
            "     29  \u001b[36m0.8973\u001b[0m       \u001b[32m0.9999\u001b[0m    \u001b[35m0.8138\u001b[0m        \u001b[31m0.1124\u001b[0m        \u001b[94m0.0128\u001b[0m        \u001b[36m0.0126\u001b[0m  0.0000  6.2929\n",
            "     30  \u001b[36m0.8974\u001b[0m       \u001b[32m0.9999\u001b[0m    \u001b[35m0.8139\u001b[0m        \u001b[31m0.1124\u001b[0m        \u001b[94m0.0128\u001b[0m        \u001b[36m0.0126\u001b[0m  0.0000  6.4513\n",
            "-1.366639494895935 {'lr': 0.01, 'module__size_emb': 500}\n"
          ]
        }
      ],
      "source": [
        "params = {\n",
        "    'lr': [0.01],\n",
        "    'module__size_emb': [500]\n",
        "}\n",
        "gs = GridSearchCV(twoembedsnet,\n",
        "                  params,\n",
        "                  verbose=50,\n",
        "                  refit=True,\n",
        "                  #pre_dispatch=8,\n",
        "                  #n_jobs=8,\n",
        "                  cv=3,\n",
        "                  scoring='neg_mean_squared_error')\n",
        "\n",
        "X_ds = SliceDataset(train, idx=0)\n",
        "y_ds = SliceDataset(train, idx=1)\n",
        "gs.fit(X_ds, y_ds)\n",
        "print(gs.best_score_, gs.best_params_)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiCOOzNlJsEt",
        "outputId": "8c709d35-4bd7-4eaf-b0e1-1e721de3c0d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Re-initializing module because the following parameters were re-set: size_emb, y_range.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch      f1    precision    recall    rmse_score    train_loss    valid_loss      lr     dur\n",
            "-------  ------  -----------  --------  ------------  ------------  ------------  ------  ------\n",
            "      1  \u001b[36m0.6109\u001b[0m       \u001b[32m0.7961\u001b[0m    \u001b[35m0.4956\u001b[0m        \u001b[31m0.9753\u001b[0m        \u001b[94m1.2464\u001b[0m        \u001b[36m0.9513\u001b[0m  0.0100  3.8133\n",
            "      2  0.4767       \u001b[32m0.8682\u001b[0m    0.3285        \u001b[31m0.9236\u001b[0m        \u001b[94m0.6205\u001b[0m        \u001b[36m0.8530\u001b[0m  0.0100  3.5169\n",
            "      3  0.5336       0.8474    0.3894        0.9374        \u001b[94m0.2516\u001b[0m        0.8787  0.0100  3.5038\n",
            "      4  0.5525       0.8289    0.4144        0.9485        \u001b[94m0.1132\u001b[0m        0.8996  0.0100  4.3620\n",
            "      5  0.5533       0.8289    0.4153        0.9534        \u001b[94m0.0728\u001b[0m        0.9090  0.0100  3.5139\n",
            "      6  0.5630       0.8238    0.4276        0.9551        \u001b[94m0.0576\u001b[0m        0.9122  0.0100  3.5021\n",
            "      7  0.5660       0.8182    0.4326        0.9606        \u001b[94m0.0539\u001b[0m        0.9227  0.0100  4.2399\n",
            "      8  0.5679       0.8206    0.4342        0.9588        \u001b[94m0.0429\u001b[0m        0.9194  0.0010  3.6277\n",
            "      9  0.5697       0.8218    0.4360        0.9573        \u001b[94m0.0296\u001b[0m        0.9164  0.0010  3.4726\n",
            "     10  0.5701       0.8219    0.4364        0.9570        \u001b[94m0.0212\u001b[0m        0.9159  0.0010  3.6872\n",
            "     11  0.5716       0.8218    0.4382        0.9573        \u001b[94m0.0172\u001b[0m        0.9164  0.0010  4.2004\n",
            "Stopping since valid_loss has not improved in the last 10 epochs.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<class 'skorch.net.NeuralNet'>[initialized](\n",
              "  module_=twoembeds(\n",
              "    (emb_UserID): Embedding(943, 500)\n",
              "    (emb_MovieID): Embedding(1682, 500)\n",
              "    (emb_UserID_b): Embedding(943, 1)\n",
              "    (emb_MovieID_b): Embedding(1682, 1)\n",
              "  ),\n",
              ")"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model = gs.best_estimator_\n",
        "best_model.fit(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "zOtkq3j_JzMe"
      },
      "outputs": [],
      "source": [
        "#rating_predict = best_model.predict(valid_dataset)\n",
        "rating_predict = twoembedsnet.predict(valid_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "UoPCrhZLJ2vT"
      },
      "outputs": [],
      "source": [
        "valid_users = valid_dataset[:][0][0][:,0].numpy()\n",
        "valid_movie = valid_dataset[:][0][0][:,3].numpy()\n",
        "valid_rating = valid_dataset[:][1].numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "L4LSVBmOJ6uX"
      },
      "outputs": [],
      "source": [
        "dct= {}\n",
        "for i in range(20000):\n",
        "    if valid_users[i] not in dct.keys():\n",
        "        dct[valid_users[i]]  = [(i, valid_movie[i], rating_predict[i], valid_rating[i])]\n",
        "    else:\n",
        "        dct[valid_users[i]].append((i, valid_movie[i], rating_predict[i], valid_rating[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "II9BA9w0J-ub",
        "outputId": "f595d026-7f2f-4381-8f37-673b24a09f2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9057591623036649 0.7721473278004224 573\n"
          ]
        }
      ],
      "source": [
        "#calculate HR@10\n",
        "from sklearn.metrics import ndcg_score\n",
        "import math\n",
        "cnt_user = 0\n",
        "sum = 0\n",
        "ndcg = 0\n",
        "for key, value in dct.items():\n",
        "    if len(value) >= 10:\n",
        "        cnt_user += 1\n",
        "        cnt_movie = 0\n",
        "        value_rank_by_pred = sorted(value, reverse = True , key=lambda x: x[2]) # sort by pred\n",
        "        value_rank_by_label = sorted(value, reverse = True , key=lambda x: x[3]) # sort by label\n",
        "        ranked_label = [[item[3] for item in value_rank_by_label]]\n",
        "        ranked_pred = [[item[3] for item in value_rank_by_pred]]\n",
        "        dcg = 0\n",
        "        idcg = 0\n",
        "        for j in range(10):\n",
        "            if value_rank_by_pred[j][3] == 5:\n",
        "                sum += 1\n",
        "                break\n",
        "        for j in range(10):\n",
        "            dcg += (2**ranked_pred[0][j]-1)/(math.log2(j+2))\n",
        "            idcg += (2**ranked_label[0][j]-1)/(math.log2(j+2))\n",
        "        ndcg += dcg/idcg\n",
        "        #ndcg += ndcg_score(ranked_label, ranked_pred, k=10)\n",
        "        #ndcg += ndcg_at_k(ranked_pred, ranked_label, 10)\n",
        "hr = sum/cnt_user\n",
        "ndcg = ndcg/cnt_user\n",
        "print(hr, ndcg, cnt_user)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_WP8cIqZQWN"
      },
      "source": [
        "### Benchmark with scikit-surprise SVD algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pjhfBV6ZRUH"
      },
      "outputs": [],
      "source": [
        "!pip install surprise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WsJ69IyMZTcZ"
      },
      "outputs": [],
      "source": [
        "from surprise import NormalPredictor\n",
        "from surprise import SVD\n",
        "from surprise import Dataset\n",
        "from surprise import Reader\n",
        "from surprise import accuracy\n",
        "from surprise.model_selection import cross_validate, train_test_split, KFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k34DMC7XNgJI"
      },
      "outputs": [],
      "source": [
        "train[dataloaders['train'].dataset.indices][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UG7J_vXTZjcf"
      },
      "outputs": [],
      "source": [
        "from surprise import SVD\n",
        "from surprise import Dataset\n",
        "from surprise.model_selection import cross_validate\n",
        "\n",
        "# Load the movielens-100k dataset (download it if needed).\n",
        "data = Dataset.load_builtin('ml-100k')\n",
        "\n",
        "# Use the famous SVD algorithm.\n",
        "algo = SVD()\n",
        "\n",
        "# Run 5-fold cross-validation and print results.\n",
        "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=3, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cksyG1wgef6"
      },
      "source": [
        "#Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Df2Ubf7mgiL2"
      },
      "outputs": [],
      "source": [
        "movies = pd.read_csv('/content/ml-100k/u.item', sep='|', names=['MovieID', 'Title', 'date', 'video_rl_date', 'link']+genre_cols, engine='python', encoding='latin-1')\n",
        "users = pd.read_csv('/content/ml-100k/u.user', sep='|', names=['UserID', 'Age', 'Gender', 'Occupation', 'Zipcode'], engine='python', encoding='latin-1')\n",
        "ratings = pd.read_csv('/content/ml-100k/u.data', sep='\\t', names=['UserID', 'MovieID', 'Rating', 'Timestamp'], engine='python', encoding='latin-1')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Vk_Q2mHb8K9"
      },
      "outputs": [],
      "source": [
        "ratings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRF0gpsAca3E"
      },
      "outputs": [],
      "source": [
        "filtered_rating = ratings[(ratings['UserID'] == 0) & (ratings['MovieID'] == 168)]['Rating'].values[0]\n",
        "filtered_rating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4-bM70jG-G5"
      },
      "outputs": [],
      "source": [
        "bins = [0, 18, 25, 35, 45, 50, 56, 100]\n",
        "labels = [1, 18, 25, 35, 45, 50, 56]\n",
        "users['Age'] = pd.cut(users['Age'], bins=bins, labels=labels, right=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYLqQEamg5A0"
      },
      "outputs": [],
      "source": [
        "movies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtXnlBFuhBU4"
      },
      "outputs": [],
      "source": [
        "# Label Encode users\n",
        "columns = ['UserID', 'Gender', 'Age', 'Occupation']\n",
        "users[columns] = users[columns].apply(preprocessing.LabelEncoder().fit_transform)\n",
        "#users_emb_columns = train.users_emb_columns + columns\n",
        "users = users.drop(['Zipcode'], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8VCRFuzjCvY"
      },
      "outputs": [],
      "source": [
        "# One Hot Encode users\n",
        "users_ohe_columns = []\n",
        "columns = ['Gender', 'Age', 'Occupation']\n",
        "ohe = preprocessing.OneHotEncoder(categories='auto', sparse=False, dtype='uint8')\n",
        "ohe.fit(train.ratings[columns])\n",
        "users = pd.concat([users, pd.DataFrame(data=ohe.transform(train.ratings[columns]), columns=ohe.get_feature_names_out(columns))], axis=1)\n",
        "users_ohe_columns = ohe.get_feature_names_out(columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSyMlZLSrI5h"
      },
      "outputs": [],
      "source": [
        "# Label Encode movies\n",
        "columns = ['MovieID']\n",
        "movies[columns] = movies[columns].apply(preprocessing.LabelEncoder().fit_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3F1X7LRrwcU"
      },
      "outputs": [],
      "source": [
        "df2 = movies[genre_cols]\n",
        "df2['Genre'] = df2.apply(lambda row: ', '.join(row.index[row == 1]), axis=1)\n",
        "movies['Genre'] = df2['Genre']\n",
        "movies = movies.drop(genre_cols, axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Wa5UpGGrS1I"
      },
      "outputs": [],
      "source": [
        "# One Hot Encode movies\n",
        "movies_ohe_columns = []\n",
        "genres = [\"genre_unknown\", \"Action\", \"Adventure\", \"Animation\", \"Children\", \"Comedy\",\n",
        "    \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\", \"FilmNoir\", \"Horror\",\n",
        "    \"Musical\", \"Mystery\", \"Romance\", \"SciFi\", \"Thriller\", \"War\", \"Western\"]\n",
        "\n",
        "for genre in genres:\n",
        "    genre = genre.replace('-', '')\n",
        "    column = str(genre)\n",
        "    movies[column] = movies['Genre'].apply(lambda x: 1 if genre in x else 0)\n",
        "    movies_ohe_columns.append(column)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKhVsEgMrd-L"
      },
      "outputs": [],
      "source": [
        "users_emb = torch.from_numpy(users[['UserID', 'Gender', 'Age', 'Occupation']].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAuENRw8too_"
      },
      "outputs": [],
      "source": [
        "movies_emb = torch.from_numpy(movies['MovieID'].values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RxT5yGQmDe6T"
      },
      "outputs": [],
      "source": [
        "movies_emb[0].unsqueeze(0).unsqueeze(0)[:, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fdAt5uuuZlc"
      },
      "outputs": [],
      "source": [
        "movies_ohe = torch.tensor(movies[movies_ohe_columns].values, dtype=torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NqmOi00tDz6k"
      },
      "outputs": [],
      "source": [
        "movies_ohe[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9KUpbClETYi"
      },
      "outputs": [],
      "source": [
        "users_emb[2].long()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83NF_gUzvJjz"
      },
      "outputs": [],
      "source": [
        "users_ohe = torch.tensor(users[users_ohe_columns].values, dtype=torch.float)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rbXtrtiwgQj"
      },
      "outputs": [],
      "source": [
        "def predict(i, model):\n",
        "    lst_movie = []\n",
        "    for j in range(len(movies)):\n",
        "        X = (users_emb[i].long().unsqueeze(0), users_ohe[i].unsqueeze(0), movies_emb[j].long().unsqueeze(0).unsqueeze(0), movies_ohe[j].unsqueeze(0))\n",
        "\n",
        "        y = model(X)\n",
        "        if y > 4:\n",
        "            lst_movie.append((movies_emb[j].long(), y.item()))\n",
        "        lst_movie = sorted(lst_movie, key=lambda x: x[1], reverse = True)\n",
        "    return lst_movie[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xoxr_zqCKdaa"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = ncf(train.users_emb, train.movies_emb, train.users_ohe, train.movies_ohe, train.interact, 120, 0.5, 400, train.y_range)\n",
        "model.to(device)\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/best_model.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzDMH7wZK_5T"
      },
      "outputs": [],
      "source": [
        "dictt = torch.load('/content/params.pt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JshL8rg0H8z"
      },
      "outputs": [],
      "source": [
        "#input is a user, return top 5 movies\n",
        "predict(0, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOp-DbJDacMc"
      },
      "outputs": [],
      "source": [
        "train_dataset[507][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KGQYqUk3Bev"
      },
      "outputs": [],
      "source": [
        "cnt = 0\n",
        "for i in range(943):\n",
        "    predict_ = predict(i, model)\n",
        "    print(predict_)\n",
        "    for j in range(len(predict_)):\n",
        "        if (ratings[(ratings['UserID'] == i) & (ratings['MovieID'] == predict_[j][0].item())]['Rating'].values[0] == 5):\n",
        "            cnt+= 1\n",
        "cnt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwbL1tsWEhDJ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sjbjp25E-odw"
      },
      "outputs": [],
      "source": [
        "print(cnt/9430)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}